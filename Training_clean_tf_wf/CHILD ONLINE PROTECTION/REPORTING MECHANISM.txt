                 Inquiry into Cyber Safety Issues  Affecting Children and Young People            Submission to the Joint Select Committee  on Cyber Safety             July 2010                     GPO Box 5218 SYDNEY NSW 2001 • Enquiries Line 1300363992 • www.privacy.gov.au   Office of the Privacy Commissioner   Key recommendations   The Office of the Privacy Commissioner (the Office) welcomes the opportunity to  provide comments to the Joint Select Committee on Cyber Safety about cyber safety  issues affecting children and young people.
We believe privacy awareness is an important element of improving cyber safety for  children and young people.
The Office’s main suggestions for improving cyber safety for children and young  people are:    1.
Education is the key to empowering individuals to protect their privacy online   and, more broadly, to establishing good cyber safety behaviours.
Cyber safety is a national problem and requires a coordinated approach across   portfolios and jurisdictions.
Ensuring that various education and awareness  programs are complementary and co-ordinated is important to promoting a  cyber safe community.
The Office supports Australia’s continuing involvement in initiatives of   international forums.
The Office considers that privacy should be treated as a separate topic within   broader cyber safety education activities and not bundled with other concepts.
Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     2   Office of the Privacy Commissioner   Office of the Privacy Commissioner     1.
The Office,  established under the Privacy Act 1988 (Cth) (the Privacy Act), has responsibilities  for the protection of individuals' personal information that is handled by  Australian and ACT Government agencies, and personal information held by all  large private sector organisations, health service providers and some small  businesses.
The Privacy Act generally covers the protection of people's personal information.
‘Personal information’ is defined in section 6 (1) of the Act as information or an  opinion, whether true or not, about an individual whose identity is apparent or  can be reasonably ascertained from that information.
Under the Privacy Act,  personal information can exist in a number of different forms, including in  images such as photographs.
The Privacy Act is also intended to be principle based and technology neutral.
What this means is that the Privacy Act does set out prescriptive rules about how  information should be handled in particular situations, such as online  environments.
Instead it offers principles about the way in which personal  information should be handled according to the particular situation.
The Office of the Privacy Commissioner (the Office) welcomes the opportunity to   comment on the Australian Parliament’s Joint Select Committee inquiry into the  safety of children and young people on the internet.
The Office notes the terms of reference that have been provided for this review of   cyber safety.1 Cyber safety is a broad concept that concerns minimising the risks  to children online from a range of negative influences including inappropriate  social behaviours, abuse, identity theft and breaches of privacy.
These negative  cyber incidents can potentially have broader long term effects for both children  and their families.
1 The terms of reference for this inquiry are available at:  http://www.aph.gov.au/house/committee/jscc/tor.htm (as at 1 June 2010)      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     3   Office of the Privacy Commissioner   6.
As cyber activity very often involves personal information there is a strong   connection between privacy and cyber safety issues.
Personal information is  increasingly becoming digitised and transmitted online increasing the risk of  privacy breaches and identity theft.
Privacy and security of personal information  in online environments are therefore important elements of cyber safety.
The Office considers that educating young people about privacy could assist in  improving cyber safety outcomes.
Our submission focuses on issues related to  privacy as an important component of cyber safety.
Throughout this submission  the Office provides examples of cyber safety initiatives currently in place and  comments on future initiatives.
This submission draws on previous comments we have made about the   important role privacy protections can play in minimising risks online including  our comments to the Australian Law Reform Commission’s (ALRC) review of  privacy law in Australia.2    Children and young people’s privacy     9.
Children are particularly vulnerable due to their limited capacity to make   decisions about their own information and their reliance on others to ensure that  their interests and rights are protected.
The potential consequences on a child or  young person of a breach of their privacy rights at this developmental stage of  their lives include the risk of trauma, embarrassment or stigmatisation and even  the possibility of identity theft.
In practice however, a child’s primary care  giver will usually be responsible for exercising the child’s rights under the  Privacy Act until the child reaches a level of maturity and understanding to make  independent decisions.
The Office considers that this approach to the privacy of young people is   appropriate, as it accommodates different rates of development.
Mature young  people are entitled wherever possible, to make decisions about their personal  information as soon as they are able, rather than on reaching a prescribed age.
2ALRC, For Your Information: Australian Privacy Law and Practice, ALRC 108  (http://www.austlii.edu.au/au/other/alrc/publications/reports/108/)      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     4   Office of the Privacy Commissioner   Level of understanding    12.
However, initiatives such as recent  conference in Victoria3 and the work of the New Zealand Youth Advisory Group4  have sought to gain further insight into what privacy means to children and  young people today and how it affects them.
In particular, the conference hosted  by Privacy Victoria also considered the potential risks associated with the use of  information technologies and what educators, policy makers, parents and even  young people themselves can do to educate young people about privacy  protection.
The survey also showed that 50% of  respondents were more concerned about providing information over the internet  than they were two years earlier.
However, a higher proportion of respondents  aged 18-24 claimed to be less concerned than other age groups.
The survey also indicated that young people were less concerned about   disclosing their financial information and are much more likely to disclose their  personal information in order to receive a discount or to win a prize.
These types  of behaviours, and being less informed about privacy issues could put young  people at risk of identity theft.
Another recent survey by Galaxy Research6 has  also shown that young people (in this case, aged 18-24) were most at risk of  identity fraud and were more complacent about checking for enhanced security  features before providing sensitive information online.
The Office believes that identity theft constitutes a serious interference with                                                    3 See http://www.privacy.vic.gov.au/privacy/web.nsf/content/conferences   4 See http://www.privacy.org.nz/youth/   5 Wallis Consulting Group, Community Attitudes Towards Privacy 2007 [prepared for the  Office of the Privacy Commissioner] (2007) available at  http://www.privacy.gov.au/publications/rcommunity07.pdf    6 VeriSign Online Fraud Barometer, compiled by Galaxy Research as at 6 July 2010  available at http://www.verisign.com.au/press/2010/20100706.html      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     5   Office of the Privacy Commissioner   individuals’ privacy and is becoming an increasingly important issue.
Identity  theft occurs where an individual obtains personal information (e.g.
credit card,  drivers licence, passport or other personal identification documents) and uses  that information to fraudulently obtain a benefit or service for themselves.
Whilst  identity theft is often associated with the financial loss of adults, identity theft  can also have serious consequences for young people when their identity is stolen  for the purposes of fabricating fake documents such as passports or to commit  further cyber crime.
Based on the available evidence, it is our view that young users are at risk of   inadvertently becoming victims of cyber incidents as a result of inadequate cyber  safety skills.
The proliferation of online activities and associated privacy risks,  coupled with the fact that young users are less aware of the risks, suggests that  there is a particular need for educational activities aimed at raising privacy  awareness among this group.
Such measures will assist in building a sound  foundation for children and young people to make informed decisions about  protecting their own privacy and respecting the privacy of others.
We consider this also extends to cyber safety.
People of all  ages need to be equipped with the necessary cyber safety skills to safely navigate  the online environment.
For example, the Office promotes secure and safe online behaviour and secure   information exchange by advising on social networking, online privacy tools and  internet privacy.8   Much of this advice for individuals is provided in a series of  ‘frequently asked questions’ and is designed to be easily accessible.
In the Office’s view, a range of measures are required to empower individuals to   protect themselves in online environments and are essential to promoting  effective privacy and cyber safety.
These measures can include promoting  education and awareness of the:                                                     7 See section 27(1)(m) of the Privacy Act   8 For more information see following links to the Office’s website in regards to: FAQs on  social networking  http://www.privacy.gov.au/faq/individuals#social_networking, Online  Privacy Tools http://www.privacy.gov.au/topics/technologies/security, and Protecting  your privacy on the internet http://www.privacy.gov.au/topics/technologies/privacy      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     6   Office of the Privacy Commissioner   ?
measures that can be taken to mitigate risk, whether through technology   or individual behaviour   ?
In particular, we have developed a Youth Portal, released during Privacy   Awareness Week 2009 which allows young people to learn about current privacy  issues.
The portal includes Private i- Your Ultimate Privacy Survival Guide and a  short animated video, Think Before You Upload (a joint initiative of the Asia Pacific  Privacy Authorities).
These publications highlight the possible risks of using online technologies such   as social networking and gaming sites and suggest how young people may  protect their personal information when accessing these technologies.9 Further,  they seek to build awareness of the Office and its website as a resource for young  people, including material that sets out their privacy rights and how to exercise  them10.
In our view, whilst regulatory approaches can help to control  inappropriate online behaviours, legislative mechanisms are not always an  effective response to regulating online risks.
We consider that education is key to  helping children and young people gain lifelong cyber safety skills and develop  respect for privacy.
Cyber safety is a national problem and an important way to minimise cyber   safety risks is to adopt a coordinated approach across portfolios and jurisdictions.
Cross-portfolio co-operation enables agencies specialised in particular areas to  collectively consider different aspects of information communications technology  initiatives and their associated privacy and security risks, and to develop an  appropriate responses.
9 See http://www.privacyawarenessweek.org/topics/youth/index.html    10 See http://www.privacy.gov.au/privacy_rights/complaints/index.html      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     7   Office of the Privacy Commissioner   25.
In particular, to encourage Australians to  think about privacy and cyber security when using mobile phones a pocket-sized  quick reference guide titled Mobilise Your Mobile Phone Privacy11 was produced.
The guide gives mobile users ten simple, easy to understand tips for protecting  their privacy and security when using their mobile phones.
In our view, a range of initiatives and channels are required to ensure an effective  response to cyber safety issues.
For this reason, the Office has been supportive of  the cyber safety and e-security activities undertaken by Government agencies.
For example, the e-security education and training materials developed by the  DBCDE,12 as well work done by NetAlert,13 and resources such as  www.staysmartonline.gov.au and www.cybersmartkids.com.au (provided by the  Australian Communications and Media Association).
A further example is the  National Cyber Security Awareness Week, an initiative of DBCDE’s ‘Stay Smart  Online’ program.
This event is a collaborative effort between government,  industry and community groups, which urges both organisations and  individuals to be aware of e-security risks and how to interact securely online.14   27.
The Office believes that there is also a need to ensure a consistent and   collaborative approach to cyber safety across different levels of government.
This collaborative  forum, which meets biannually, discusses issues of common interest, including  privacy law reform and technology advances and their impacts on privacy and  discusses on co-ordinated approaches to issues affecting individuals’ personal  information.
Currently, the privacy protections afforded to  personal information may vary significantly as it is exchanged between  jurisdictions.
11 Copies of the pocket guide are available from the Office of the Privacy Commissioner   12 More information on this initiative is available at  http://www.dbcde.gov.au/communications_for_consumers/security/e-security   13 See http://www.netalert.gov.au/    14 See http://www.privacy.gov.au/materials/a-z?fullsummary=7090      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     8   Office of the Privacy Commissioner   29.
The Office supports achieving national uniformity in privacy regulation, as   recommended by the ALRC in its review of privacy law and supported by the  Australian Government in its first stage response.15 The Office considers that  greater consistency in privacy regulation would enhance security for information  flowing across State and Territory boundaries which in turn can aid improved  cyber safety outcomes.
International co-operation   30.
In the Office’s view, an important component to promoting effective online  privacy and cyber safety is to recognise the international cross-jurisdictional  nature of many modern information flows.
In turn, this requires international co- operation to foster good privacy outcomes and the promotion of cyber safety.
Forums such as the Asia Pacific Privacy Authorities, the Organisation for   Economic Cooperation and Development  Working Party of Information Security  and Privacy (WPISP) and work done by Asia Pacific Economic Cooperation  (APEC) economies on developing an APEC privacy framework all provide  tangible examples of how such an objective can be progressed.
The Office supports Australia’s continuing involvement in the privacy initiatives   of the following international fora.
WPISP develops policy options to encourage privacy protection in a networked   society.16 Some of WPISP’s work has included looking at the future of the internet  economy from a privacy and security perspective and policy approaches for the  protection of children online.
The Office continues to provide input into the work  of WPISP.
APEC has a number of initiatives aimed at protecting information privacy and  maintaining information flows among APEC economies.
The Privacy Framework contains nine  high level Privacy Principles that represent a minimum standard.
The Privacy  Frame work aims to promote a consistent approach to information privacy  protection across APEC member economies, while avoiding the creation of  unnecessary barriers to information flows.
15 ALRC, For Your Information: Australian Privacy Law and Practice, recommendation 3- 4, recommendation 3-5, recommendation 3-6   16 For information on OECD WPISP, see  www.oecd.org/department/0,3355,en_2649_34255_1_1_1_1_1,00.html       Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     9   Office of the Privacy Commissioner   APPA membership includes similar regulators from other Australian  jurisdictions, as well as New Zealand, Hong Kong, South Korea and Canada,  including both the Federal Office and the province of British Columbia.17  APPA  is the principal forum for privacy authorities in the Asia Pacific Region to form  partnerships and exchange ideas about privacy regulation, new technologies and  the management of privacy enquiries and complaints.
Specifically for young people, a short animated video and accompanying teacher  resources warning of the dangers of social networking websites was released by  APPA members in May 2009.
APPA members also developed an online self help identity theft prevention tool   for Privacy Awareness Week 2010.18 It is an interactive quiz-based tool which  helps individuals to work out how likely they are to be a victim of identity theft.
The tool also includes separate ‘read and learn’ pages with practical tips and  ways to improve identity security.
The ALRC in its review of privacy recommended that the Office, in consultation   with ACMA, should ensure that specific guidance on the privacy aspects of using  social networking sites is developed and incorporated into publicly available  education material.19 The ALRC also recommended that State and Territory  education departments should incorporate education about privacy and, in  particular privacy in the online environment, into school curricula.20    40.
The Office agrees with these proposals in principle, and welcomes and   encourages initiatives which bring the research community together with other  key education stakeholders to deepen understanding of key and emerging issues                                                     17 See http://www.privacy.gov.au/aboutus/international/appa   18 Available at http://www.privacyawarenessweek.org  19 ALRC, For Your Information: Australian Privacy Law and Practice, recommendation 67- 3   20 Ibid, recommendation 67-4      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     10   Office of the Privacy Commissioner   and educational needs facing young people.
The Office considers that privacy should be treated as a separate topic within   broader cyber safety education modules and not bundled with other concepts.
Education activities should help children to start thinking about themselves as  individuals with an identity that is linked to their personal information such as  their name, address, telephone number, birth date and school.
Children should  be made aware of the reasons why they need to protect their personal  information, and that of others, especially online, along with practical steps they  can take to protect their privacy.
Education activities should also include advice  about how, where and when to get help if they are unsure about providing or  protecting their personal information online.
The use of mobile phones to connect to the internet and facilitate  online services is ever increasing along with the increased use and dependence  on mobile phones by children and young people.
This is particularly  important as mobile phones can store large amounts of personal information and  are easily lost or stolen.
The Office has recently partnered with other Government  agencies to raise community awareness about privacy and security when using  mobile phones.21                                                     21 Mobilise Your Mobile Phone Privacy a pocket-sized quick reference guide available from  the Office of the Privacy Commissioner      Submission to the Joint Select Committee on Cyber Safety – Inquiry into Cyber Safety     11                               The Protection of  Children Online   Recommendation of the OECD Council      Report on risks faced by children online and   policies to protect them                           2012                 THE PROTECTION OF CHILDREN ONLINE   RECOMMENDATION OF THE OECD COUNCIL    REPORT ON RISKS FACED BY CHILDREN ONLINE           AND POLICIES TO PROTECT THEM                         ORGANISATION FOR ECONOMIC CO-OPERATION   AND DEVELOPMENT      The OECD is a unique forum where governments work together to address the  economic,  social  and  environmental  challenges  of  globalisation.
The  OECD  is  also at the forefront of efforts to understand and to help governments respond  to  new  developments  and  concerns,  such  as  corporate  governance,  the  information  economy  and  the  challenges  of  an  ageing  population.
The  Organisation  provides  a  setting  where  governments  can  compare  policy  experiences,  seek  answers  to  common  problems,  identify  good  practice  and  work to co-ordinate domestic and international policies.
The Commission of the European Communities takes part in the  work of the OECD.
Applications should be sent to OECD Publishing:   rights@oecd.org            3   Table of contents         RECOMMENDATION OF THE OECD COUNCIL ON THE PROTECTION OF CHILDREN  ONLINE .................................................................................................................................................................... 5  THE PROTECTION OF CHILDREN ONLINE: RISKS FACED BY CHILDREN ONLINE AND  POLICIES TO PROTECT THEM ...................................................................................................................... 11  Summary .................................................................................................................................................................. 12  Introduction .............................................................................................................................................................. 15  Part I. Online risks for children ................................................................................................................................ 24  Typologies of risks ............................................................................................................................................... 24  Overview of risks ................................................................................................................................................. 24  Risks pertaining to children as Internet users ................................................................................................... 25  Children targeted as consumers on the internet ................................................................................................ 33  Information privacy and security risks ............................................................................................................. 34  Conclusion ....................................................................................................................................................... 38  Part II.
Policy measures to protect children online................................................................................................... 40  The three dimensions of policies to protect children online ................................................................................. 40  Multi-layered policies ...................................................................................................................................... 40  Multi-stakeholder effort ................................................................................................................................... 45  Multi-level policies .......................................................................................................................................... 47  Comparative policy analysis ................................................................................................................................ 49  Part III.
Key Findings ............................................................................................................................................... 53  Policy coherence .................................................................................................................................................. 54  Evidence-based policy ......................................................................................................................................... 55  International co-operation .................................................................................................................................... 57  Annex I. Descriptive overview of policies to protect children online ...................................................................... 59  Annex II.
Tables and figures .................................................................................................................................... 84  Notes ........................................................................................................................................................................ 87  Bibliography ............................................................................................................................................................ 98      THE PROTECTION OF CHILDREN ONLINE - © OECD         5            RECOMMENDATION OF THE OECD COUNCIL ON THE PROTECTION   OF CHILDREN ONLINE      As the Internet permeates every aspect of the economy and society, it is also becoming an essential  element  of  our  children’s  lives.
While  it  can  bring  considerable  benefits  for  their  education  and  development,  it  also  exposes  them  to  online  risks  such  as  access  to  inappropriate  content,  harmful  interactions  with  other  children  or  with  adults,  and  exposure  to  aggressive  marketing  practices.
While many of these risks may be simply considered as the digital extension of existing offline threats to  children, the measures that protect them against these risks are not always easy to effectively migrate  to  a  virtual  and  global  digital  environment.
For  example,  the  inherent  openness  at  the  core  of  Internet’s design places all users on an equal footing and enables them to enjoy the benefits of global  connectivity regardless of their identity or age.
Such openness enabled the transformation of a network  of computer networks mainly used by researchers into a global platform for innovation supporting key  economic and social activities as well as critical infrastructures.
How can the physical barriers and  norms that societies erect to protect the young people offline be translated online without undermining  the openness of the Internet and fundamental values?
However,  Internet  technologies and uses evolve rapidly as compared with the time that societies need to understand new  risks and make adjustments.
Parents and educators often face difficulties in keeping abreast of Internet  technologies, while their “digital native” children have a natural appetite for online media, driving the  widespread adoption of instant messaging, blogs and social networks.
On  the  Internet  there  is  always  a  doubt  regarding who is a friend and who is a stranger, since there is generally no visual interaction and few  mechanisms to validate identity.
Enforcing advice, such as telling children not to talk to strangers, is as  difficult  online  as  it  is  offline,  as  children  often  use  the  Internet  alone  in  front  of  a  screen,  with  a  smartphone  or  game  console,  easily  able  to  install  software  and  click  on  links.
Conversely,  the  possibility  to  communicate  with  strangers  who  share  common  interests,  for  example  through  social  networks, is precisely one of the main benefits of the Internet.
At the Seoul Ministerial Meeting on the Future of the Internet Economy held in June 2008, Ministers  called  for  a  collaborative  effort  by  governments,  the  private  sector,  civil  society  and  the  Internet  technical  community  to  build  an  understanding  of  the  impact  of  the  Internet  on  minors  in  order  to  enhance their protection and support when using the Internet.1 They also called for cross-border co- operation by governments and enforcement authorities with respect to the protection of minors.
THE PROTECTION OF CHILDREN ONLINE - © OECD   6          Following up on the Seoul Declaration, the OECD organised a joint Symposium with the Asia-Pacific  Economic  Co-operation  Telecommunications  and  Information  Working  Group  (APEC  TEL)  on  Initiatives Among Member Economies Promoting a Safer Internet for Children (Singapore, 15 April  2009).2 In 2010, the OECD Committee for Information, Computer and Communications Policy (ICCP)  Working Party on Information Security and Privacy (WPISP) carried out an analysis of risks faced by  children on the Internet and existing policies to protect them, releasing a report in May 2011.
3  This  Recommendation  is  based  on  the  findings  of  this  report  and  has  been  developed  with  the  participation of business, civil society and the Internet technical community.4 Consistent with the 1989  United  Nations  Convention  on  the  Rights  of  the  Child,  it  includes  principles  for  all  stakeholders  involved in making the Internet a safer environment for children and educating them towards becoming  responsible  digital  citizens.
It  also  focuses  on  three  main  challenges  faced  by  governments  which  underline the emerging nature of the protection of children online as a public policy area: the need for  an evidence-based policy making approach, for managing policy complexity through enhanced policy  co-ordination, consistency and coherence as well as for taking advantage of international co-operation  to improve the efficiency of national policy frameworks and foster capacity building.
OECD (2008), “The Seoul Declaration for the Future of the Internet Economy”, available at www.oecd.org/futureinternet.
OECD (2009), “Report on the APEC-OECD Joint Symposium on Initiatives among Member Economies Promoting a Safer  Internet Environment for Children”, available at www.oecd.org/dataoecd/46/46/44120262.pdf.
This participation was channeled through the Business and Industry Advisory Committee to the OECD (BIAC), the Civil  Society Internet Society Advisory Council (CSISAC) and the Internet Technical Advisory Committee  (ITAC).
THE PROTECTION OF CHILDREN ONLINE © OECD         7   Recommendation of the OECD Council on the Protection of Children Online   16 February 2012 - C(2011)155   THE COUNCIL,  HAVING REGARD to Article 5 b) of the Convention on the Organisation for Economic Co-operation and  Development of 14 December 1960;  HAVING REGARD to the Recommendation of the Council concerning Guidelines Governing the Protection  of Privacy and Transborder Flows of Personal Data [C(80)58/FINAL], the Recommendation of the Council  concerning Guidelines for Consumer Protection in the Context of Electronic Commerce [C(99)184/FINAL],  the  Recommendation  of  the  Council  Concerning  Guidelines  for  the  Security  of  Information  Systems  and  Networks - Towards a Culture of Security [C(2002)131], the Seoul Declaration for the Future of the Internet  Economy  [C(2008)99],  and  the  Recommendation  of  the  Council  on  Principles  for  Internet  Policy  Making  [C(2011)154];   RECOGNISING that a growing number of children are spending increasing time online, starting at younger  ages, and that Internet technologies and access devices are evolving rapidly, facilitating the access of children  to the Internet and changing their online usage patterns;  RECOGNISING  that  while  the  Internet  brings  major  benefits  to  children  in  terms  of  education,  self- expression,  and  social  development,  its  use  also  carries  a  spectrum  of  risks  to  which  children  are  more  vulnerable than adults;  RECOGNISING  the  importance  of  co-operation  and  information  sharing  by  all  stakeholders  in  the  development, implementation and assessment of policy approaches to the protection of children online;   RECOGNISING that the protection of children online requires policies which both reduce online threats to  foster a safer Internet for children and enable children to protect themselves from threats that remain;  RECOGNISING that even if regional and local cultural differences impact the evaluation of online risks to  children,  international  dialogue  and  co-operation  has  proven  valuable  to  establish  more  effective  policy  approaches for an inherently global medium like the Internet:  On the proposal of the Committee for Information, Computer and Communications Policy:  I.
AGREES that, for the purpose of this Recommendation:    i) Children” encompass every human being below the age of eighteen years, recognising that a lower  age  threshold  might  be  appropriate  in  providing  certain  legal  protections;  “parents”  encompass  children’s parents and carers;   ii) The “protection of children online” encompasses content risks, contact risks, risks related to children  as consumers as well as information security and privacy risks faced by children on the Internet;  iii) “Stakeholders” encompass governments, businesses, civil society and the Internet community and  other entities involved in maintaining a safe Internet and educating children.
AGREES that this Recommendation does not cover risks related to child sexual abuse images online and  the sexual exploitation of children which are matters addressed by other international instruments;  III.
RECOMMENDS that in formulating policies for the protection of children online, governments and all  other stakeholders take into account the following principles:        THE PROTECTION OF CHILDREN ONLINE - © OECD   8      a. Empowerment   i) Policies to protect children online should recognise that all stakeholders share responsibility both to  make a safer online environment for children by reducing online threats to children, and to support the  primary role of parents in evaluating and minimising risks of harm to their children online as well as  offline;   ii) Policies to protect children online should empower children and parents to evaluate and minimise  risks and engage online in a secure, safe and responsible manner.
They  should  maximise  the  protection  against  online  risks  faced  by  children  without  restricting  the  opportunities and benefits of the Internet for children as well as for other users.
ii) Policies to protect children online should not undermine the framework conditions that enable the  Internet  to  operate  as  a  global  open  platform  for  communication,  innovation,  economic  growth,  and  social progress.
The consistency of policies designed to protect children online with other economic  and social Internet policies should be carefully assessed prior to adoption and implementation.
iii) Policies  to  protect  children  online  should  be  consistent  with  fundamental  values  of  democratic  societies as they apply to all individuals including children.
In particular, they should support freedom  of expression, privacy protection and the free flow of information.
ii) Policies to protect children online should be technology neutral to ensure their  sustainability in  a  dynamic environment characterised by rapidly evolving technologies and patterns of usage.
Demonstrate leadership and commitment to protect children online by:   i) Adopting clear policy objectives at the highest level of government;  ii) Identifying  government  bodies  with  responsibility  and  authority  to  implement  these  policy  objectives and to co-operate across borders;  iii) Developing policies that are inclusive of all stakeholders and rely on a mix of public and private,  voluntary and legal, awareness raising, educational and technical measures to protect children online.
Support a co-ordinated response from all stakeholders by facilitating and, as appropriate, establishing:   i) An open dialogue in order to foster synergies, benefit from the expertise of all stakeholders including  parents, educators and the children themselves and take into account their perspectives;  ii) Partnerships  to  develop  self-  and  co-regulatory  programmes  characterised  by  transparency  and  accountability.
This could include:   i) Ensuring the enforcement of existing protection measures;  ii) Clarifying the categories of risks and harmonising the terminology used to inform the public;   THE PROTECTION OF CHILDREN ONLINE © OECD        iii) Promoting mutually reinforcing policy measures rather than accumulating isolated or stand-alone,  and potentially inconsistent, initiatives.
9   d. Foster  awareness  raising  and  education  as  essential  tools  for  empowering  parents  and  children  by,  for  example:   i)  Integrating  Internet  literacy  and  skills  in  school  curricula  with  a  focus  on  risks  and  appropriate  online behaviour;  ii) Training educators and encouraging other stakeholders to educate and raise awareness of children  and parents;   iii) Regularly measuring the evolution of their Internet literacy.
e. Support evidence-based policies for the protection of children online by:   i) Facilitating the further development of a robust empirical and analytical basis, including undertaking  longitudinal  surveys,  with  a  view  to  support  policy  development  and  implementation  through  better  understanding Internet usage by children, risk evolution and awareness;   ii) Conducting regular impact assessments of policies, including of co- and self-regulatory initiatives.
f. Encourage the development and adoption of technologies for the protection of children online that respect  the rights of children and the freedom of other Internet users.
This could include:    i) Fostering further research on privacy protective, interoperable and user friendly technical measures,  including parental controls and age verification systems;  ii) Promoting the use of technologies which enable children to protect themselves against online risks;   iii) Fostering  the  assessment  of  the  potential  impact  of  such  technical  measures  in  relation  to  fundamental values such as freedom of expression, privacy protection and the free flow of information,  as well as the implementation of appropriate safeguards;  iv) Promoting  labelling  schemes  attesting  the  trustworthiness,  quality  and  user  friendliness  of  such  technical measures.
V. RECOMMENDS that, at the international level, governments:   a.
Strengthen international networks of national organisations dedicated to the protection of children online  such as networks of hotlines and awareness centres and, where appropriate, facilitate an expansion of their  role.
Share information about national policy approaches to protect children online and in particular develop the  empirical  foundations  for  quantitative  and  qualitative  international  comparative  policy  analysis.
This  could  include:    i) The adoption of a shared statistical framework enabling international comparability of indicators on  children use of the Internet, risk prevalence, awareness by children and parents of these risks and of  how to respond to them, as well as policy impact and efficiency;   ii) The  harmonisation  of  the  statistical  definition  of  risks  and  related  policy  responses  as  well  as  children’s age groups used for statistical purposes;   iii) A shared commitment to regularly update official quantitative data within a timeframe that takes  into account the dynamic development of the Internet and of its uses by children.
c. Support regional and international capacity building efforts to improve policy and operational measures to  protect  children  on  the  Internet,  including  the  pooling  and  sharing  of  successful  education  and  awareness  raising tools.
THE PROTECTION OF CHILDREN ONLINE © OECD   10      d. Better co-ordinate work by the  various international and regional organisations and bodies which play a  role  to  support  government  efforts  in  this  area,  including  OECD,  Asia-Pacific  Economic  Co-operation,  Council of Europe, European Union, Internet Governance Forum, ITU, Organisation of American States, and  involve non-governmental stakeholders where appropriate.
INVITES:    - Members and the Secretary-General to disseminate this Recommendation to all stakeholders and other  international organisations;   - Non-Members to adhere to this Recommendation and collaborate with Members in its implementation.
INSTRUCTS  the  Committee  for  Information,  Computer  and  Communications  Policy  to  review  this  Recommendation  and  its  implementation  and  to  report  to  Council  within  five  years  of  its  adoption  and  thereafter as appropriate.
THE PROTECTION OF CHILDREN ONLINE © OECD         11   THE PROTECTION OF CHILDREN ONLINE:   RISKS FACED BY CHILDREN ONLINE AND POLICIES          TO PROTECT THEM    THE PROTECTION OF CHILDREN ONLINE - © OECD            12      Foreword   This report follows up on the 2008 Seoul Ministerial Declaration on the Future of the Internet  Economy.
It will feed related OECD activities such as work by the Working Party on Information  Security and Privacy (WPISP) on the evolving privacy landscape and on identity management, by  the Committee on Consumer Policy (CCP) in relation to the review of the 1999 Guidelines for  Consumer  Protection  in  the  Context  of  Electronic  Commerce  and  by  the  Committee  for  Information, Computer and Communications Policy (ICCP) on Internet Intermediaries.
It  was  prepared  by  Kristina  Irion  (Central  European  University),  consultant  to  the  OECD,  under the supervision of the OECD Secretariat (Laurent Bernat, Directorate for Science, Techno- logy and Industry).
Information related to quantitative data was added by Elodie Prosser.
In  addition  to  OECD  member  countries,  observers,  and  delegations  from  the  Business  and  Industry  Advisory  Committee  (BIAC)  and  Civil  Society  Internet  Society  Advisory  Council  (CSISAC), the Secretariat wishes to thank the group of experts who provided input and advice  during  the  drafting  process  including  Sonia  Livingstone  (London  School  of  Economics),  John  Carr  (eNasco),  Cristina  Schulman  and  Alexander  Seger  (Council  of  Europe),  Liz  Butterfield  (Hector’s  World),  Andrea  Millwood-Hargrave  (International  Institute  of  Communications),  Ruben Rodriguez (Inhope), Jules Cohen, Peter Cullen and Julie Inman-Grant (Microsoft), John  Palfrey, Urs Gasser, and danah boyd (Berkman Center for Internet and Society), Cristina Bueti  and Susan Teltscher (ITU), and Maxime Zabaloueff.
The report was declassified at the 61st session of the Committee for Information, Computer   and Communications Policy (ICCP) on 16-17 March 2011.    www.oecd.org/sti/ict/children                    THE PROTECTION OF CHILDREN ONLINE - © OECD        Summary    13   An increasing number of children are now using the Internet.
They are starting at a younger age,  using a variety of devices and spending more time online.
The Internet can be a major channel for their  education, creativity and self-expression.
How  to  prevent  risks  while  preserving  fundamental  values  for  all  Internet  users,  including  the  children  themselves?
How  to  ensure  that  policies  are  proportionate  to  the  problem  and  do  not  unsettle  the  framework  conditions  that  have  enabled  the  Internet economy to flourish?
Parents, caregivers, educators, business and civil  society  can also help children  to benefit from  the  Internet.
At  the  Seoul  Ministerial  Meeting  on  the  Future  of  the  Internet  Economy in June 2008, Ministers called for a collaborative effort by governments, the private sector,  civil society and the Internet technical community to build a common understanding of the impact of  the Internet on minors and to enhance their protection and support when using the Internet.
This report focuses on online risks for children and policies to protect them as Internet users.
It  examines direct and indirect policy measures available to OECD member and non-member countries  to help mitigate risks for children online in order to:   ?
Explore how international co-operation can enhance the protection of minors on the Internet.
Three  broad  categories  of  online  risks  for  children  are  considered  in  this  report:  i) content  and  contact  risks,  including  exposure  to  pornography,  cybergrooming  and  cyberbullying;  ii) consumer  risks related, for example, to online marketing and fraudulent transactions; and iii) privacy and security  risks,  including  the  use  of  social  networks  without  sufficient  understanding  of  potential  long-term  consequences.
Statistical data about children’s use of the Internet and the prevalence of risks are limited.
Addressing  them  requires  a  blend  of  approaches  that  include  legislative,  self-  and  co-regulatory,  technical,  awareness  and  educational  measures,  as  well  as  positive  content  provision  and  child  safety  zones.
In  practice,  each  country  operates its own policy mix of characteristics and priorities, which reflects its perception of priorities as  well as its culture and style of government.
Moreover, policy measures that address different risks and   THE PROTECTION OF CHILDREN ONLINE - © OECD   14       initiatives  from  various  stakeholders  at  different  levels  co-exist.
To enhance their efficiency and   catch up with the rapid adoption of the Internet by children, governments face three main challenges:    ?
Managing  policy  complexity  through  enhanced  policy  co-ordination,  consistency  and   coherence;    ?
Taking  advantage  of  international  co-operation  to  improve  the  efficiency  of  national  policy   frameworks and foster capacity-building.
For policy to protect children online to operate effectively as the sum of its parts, governments  should enhance the coherence of their policy measures and tools in collaboration with all stakeholders.
Policies to protect children online would benefit from efforts to ensure consistency with  other important policy objectives, such as the preservation of fundamental rights and maintenance of  the  framework  conditions  which  have  enabled  the  Internet  to  become  a  global  open  platform  for  innovation, economic growth and social progress.
With some notable exceptions, the impact of national policy frameworks and individual policy  measures for the protection of children online is not regularly assessed and performance evaluations  are only exceptionally built into policy.
The  policy-making process would benefit from official statistics on children’s use of the Internet and the  prevalence of risk.
This would require a more consistent approach to definitions, methodologies and  indicators.
International and regional co-operation is another area for improvement.
While international and  regional  intergovernmental  organisations  (including,  in  addition  to  the  OECD,  the  Asia-Pacific  Economic  Co-operation,  the  Council  of  Europe,  the  International  Telecommunication  Union,  the  Internet  Governance  Forum  and  the  European  Commission)  are  already  involved,  co-ordinated  international  work  by  governments  and  other  stakeholders  to  protect  children  online  would  also  support efforts by governments at national level.
Successful  international  co-operation  relies  on  the  involvement  of  all  relevant  international  stakeholders.
The report provides examples of international co-operation at the policy and operational  levels.
These include international strategic partnerships, capacity building and joint events (e.g.
Safer  Internet  Day)  as  well  as  the  sharing  of  successful  educational  and  awareness  raising  campaigns.
However, the organisation of a regular joint international event on child protection online, with the  participation of national and international players, would be an effective way to co-ordinate efforts and  take advantage of potential synergies.
It would offer a way to share best practices among governments,  business  and  civil  society,  including  the  research  community,  with  a  view  to  making  the  lessons  learned from field experience available to policy makers.
It would also help bridge communities such  as policy makers and practitioners in the area of Internet policy, education, development and capacity  building, law enforcement, and statistics.
Another avenue for international co-operation is the development of more comparable statistics to  enable  comparisons  across  countries  and  to  help  governments  better  assess  the  efficiency  of  their  frameworks.
OECD model surveys could, for example, include a module on children’s access to and  use of the Internet and on risk prevalence.
Significant work would be needed to harmonise age ranges  and  define  risks  to  determine  data  collection  methodologies  (e.g.
THE PROTECTION OF CHILDREN ONLINE © OECD            Introduction    15   The Internet is an essential infrastructure for economic and social interaction.
Children can benefit greatly from the  Internet.
It is a significant tool for their education, creativity and self-expression as well as for the  development of their identity and social skills.
Governments,  parents,  caregivers,  educators,  business  and  civil  society  can  help  children to benefit from the Internet, but they also have a responsibility to protect them against  risks online.
As  the  number  of  children  using  the  Internet  increases  and  the  age  at  which  they  begin  decreases, identifying and addressing these risks becomes an important public policy objective.
Governments  face  many  challenges  when  developing  and  implementing  policies  to  protect  children  online:  How  to  mitigate  risks  without  reducing  children’s  opportunities  and  benefits?
How  to  prevent  risks  while  preserving  fundamental  values  such  as  freedom  of  speech  and  the  right to privacy for all Internet users, including children themselves?
Some of these issues were raised at the OECD in the early days of the expansion of the World  Wide Web.1 Since then, the diffusion of broadband access and the exponential growth of available  online content and applications over the last decade have significantly modified the landscape.
At  the  Seoul  Ministerial  Meeting  on  the  Future  of  the  Internet  Economy  in  June  2008,  Ministers  called for a collaborative effort by governments, the private sector, civil society and the Internet  technical community to build a common understanding of the impact of the Internet on minors  and  to  enhance  their  protection  and  support  when  using  the  Internet.
This  report  builds  on  a  Joint  APEC-OECD  Symposium  on  Initiatives  among  Member  Economies  Promoting  Safer  Internet  Environment  for  Children  held  in  Singapore  on  15  April  2009  (OECD,  2009a)2  and  on  APEC  and  OECD  members’  responses  to  a  questionnaire  on  protection of children online.
It is expected to contribute to work on the 30th anniversary review of  the  OECD  1980  Privacy  Guidelines.
Explore how international co-operation can enhance the protection of minors on the Internet.
After  a  presentation  of  the  scope  of  this  report,  of  statistics  on  the  use  of  the  Internet  by  children, and of considerations regarding quantitative data on risks faced by children online, Parts  I and II provide an overview of these risks and of policy approaches to addressing them.
Annex  I  includes  a  detailed  overview  of  current  policy  approaches.
THE PROTECTION OF CHILDREN ONLINE © OECD   16       Scope    The report focuses on OECD members, but also includes information on non-members.
For example, under German media  law, children are persons below the age of 14 and adolescents are persons as of age 14 but below  the  age  of  18.4  Protection  often  applies  up  to  a  specific  age,  sometimes  less  than  18  years,  as  under the US Children’s Online Privacy Protection Act (COPPA) which protects personal data of  children under 13.5 National measures on child protection can also apply to minors at a higher  age, as in Korea, where measures to protect children against harmful content apply to those under  age 19.6    Risk mitigation strategies have to take account of the many factors that influence children’s  experience  and  activities  on  the  Internet:  the  diffusion  of  Internet  technologies  or  the  socio- economic  situation  of  a  given  country’s  households  (Hasebrink  et  al.,  2009,  p.  21,  57f.
),  the  locations at which children most often access the Internet (e.g.
and  the  devices  they  use  (e.g.
For  example,  with  the  diffusion  of  smartphones  and  other  means  to  access  the  Internet  (e.g.
Internet  dongles  and  3G  USB keys), ubiquitous Internet access may be on the rise among children as for adults.
A brief  overview of Internet use by children is provided below.
However, online  solicitation of children for sexual purposes – cybergrooming – where the risk starts online and  then moves offline, is included.
Ongoing work by the Council of Europe on criminal law issues  related to online child sexual abuse and sexual exploitation will complement this OECD report by  covering  this  other  aspect  of  the  subject  matter.
Arguing  that  full  implementation of  the  Convention on the Protection of Children against Sexual Exploitation and Sexual Abuse (CETS  201)  and  of  the  Budapest  Convention  on  Cybercrime  (CETS  185)  provides  countries  with  adequate  tools  and  mechanisms  to  deal  with  this  issue,  this  work  will  be  based  on  these  legal  instruments as benchmarks to assess how countries criminalise sexual violence against children.8   Although the report covers conduct by children that can create risks to themselves (or their  parents), such as actively searching for explicit online content (Byron, 2008, p. 53), it does not  cover online activities by children that can create risks for other children.
Finally,  pathological  risks  related  to  children’s  excessive  use  and  over- consumption of Internet content or services are not within the scope of this report.
The report examines direct and indirect policy measures and  other means used by government to promote self- and co-regulation as well as private measures.
It  highlights  commonalities  and  differences  across  countries  with  respect to policy measures and challenges.
Statistics on the use of the Internet by children     he following provides a quick overview of the use of the Internet by children, a topic that has  been widely researched.
For example, in 2009, an inventory  found  441 empirical  studies  from  the  European  Union  on  children’s  access  to  and  use  of  the  Internet.10 The fact that some countries are not covered in this section may reflect a lack of data  on  these  countries  and/or  a  bias  in  the  selection  of  sources  (e.g.
Children’s  access  to  the  Internet  is  likely  to  be  correlated  with  their  country’s  Internet  diffusion.
It  is  important to note that children, like all Internet users, are affected by the digital divide.
When they  lack the opportunity to access the Internet, they cannot be affected by online risks; however, they  also miss out on the opportunities and benefits the Internet offers.
A review of the main studies available reveals several trends:  A  high  percentage  of  older  children  have  Internet  access:  93%  of  American  children  had  access to the Internet in 2007 (Pew Internet & American Life Project, 2007, p. 48).
In 2006 in  Japan, this was the case of 65% of children aged 10-14 and 90% of teenagers aged 15-19.11 In the  European Union, 75% of 6-17 year-olds were reported by their parents in 2008 to use the Internet;  the percentage ranged from 93-94% in Finland, Iceland and the Netherlands to 50% in Greece and  45% in Italy (Livingstone and Haddon, 2009, p. 111).. Ofcom’s research shows that 99% of UK  children aged 12-15 use the Internet, 93% of 8-11 and 75% of 5-7 (Ofcom, 2010, p 3).
Internet access is on the rise: An increasing number of children have access to the Internet,  mostly  owing  to  the  multiplication  of  computers  in  households  and  in  schools.
In  the  United  States,  35%  of  public  schools  had  access  to  the  Internet  in  1994  and  100%  nine  years  later  (Schmidt and Vandewater, 2008, p. 76); home Internet access for 8-18 year-olds nearly doubled  over the last ten years (from 47% in 1999 to 84% in 2009) (Kaiser Family Foundation, 2010).
The  percentage of children using the Internet in the European Union increased from 70% to 75% over  three years (2005-08) (EC, 2006, 2008c).
Internet use increases with age: In 2008 in the European Union, the Internet was used by 50%  of 6-7 year-olds and 86% of 15-17 year-olds (EC, 2008c) (Figure 1).
In Australia, a recent study  showed that children aged 8 to 11 used the Internet on average 4.1 days per week for 1.3 hours per  day, and that 12 to 17 year-olds used the Internet on average 6.3 days for an average of 2.9 hours  per day (ACMA, 2009b, p. 8)   Figure 1.
Children's Internet use by age in the European Union   100  80  60  40  20  0  %  2005/06  2008  6-7  8-9  10-11  Age  12-13  14-15  16-17     Source: OECD chart based on Eurobarometer 2005-2006 and 2008 (EU27).
THE PROTECTION OF CHILDREN ONLINE © OECD   18       Children start to use the Internet younger: A 2009 Swedish report points out that the age of  Swedish children’s first use of the Internet dropped from 13 years in 2000 to 4 years in 2009.
The  report  considers  that  at  least  half  of  4  year-olds  use  the  Internet  at  least  occasionally  (Beantin  Webbkommunikation,  2010).
In  2009,  74%  of British  children  aged 5-7  had  access  to  Internet  (Ofcom, 2010, p 16).
Children spend more time on the Internet than before: In 2007, British children aged 12-15  spent on average 13.8 hours a week on the Internet, nearly twice as much time as in 2005 (7.1  hours  a  week)  (Ofcom,  2008c,  p.  2).
commissioned  a  study  indicating  that  Americans  aged  13-24  already  spent  16.7  hours  a  week  on  the  Internet,  i.e.
Children use the Internet mostly at home: 84% of children in the United States (Kaiser Family  Foundation, 2010, p. 3) and 67% in Australia (Dooley et al., 2009) use the Internet at home.
In the  European  Union,  65%  of  8-17  year-olds  access  the  Internet  at  home,  followed  by  school  and  friends’ homes (Figure 2).
European Union: Where does your child use the Internet?
Playing  games was the most popular activity for children aged 8-11 but ranked fourth for children aged  16-17 after general surfing, sending and receiving e-mails and finding/downloading information  for school.
While 53% of 16-17 year-olds used social networking sites only 6% of 8-11 year-olds  did  so  (Figure  3).
Internet  uses  are  extremely  dynamic  and  trends  in  each  type  of  use  change  rapidly.
“Web 2.0” has modified Internet use by children, and the Pew Internet & American Life  Project (2007, p. 47) mentions that use of chatroom decreased from 24% in 2001 to 18% in 2006.
This  likely  reflects  the  fact  that  instant  messaging  functions  are  now  an  integral  part  of  every  social  network  or  online  community.
In  Australia  in  2008,  90%  of  young  people  aged  12–17  reported  using  social  networking  services,  with  51%  of  8–11  year  olds  using  these  services  (ACMA, 2009b, p.8).
According to a recent US study (Kaiser Family Foundation, 2010, p. 21),  visiting social networks has become the most popular activity among children aged 8-18.
THE PROTECTION OF CHILDREN ONLINE © OECD        Devices  to  access  the  Internet  are  diversifying:  More  sophisticated  mobile  phones  increasingly  enable  Internet  access  (see  Annex  II,  Table 1).
Differences  in  Internet-enabled  mobile phone usage by children across countries are important: nearly 60% of Japanese children  use  their  mobile  phone  to  access  the  Internet12  but  only  10.7%  of  European  children  (Eurobarometer, 2008c, annex tables and survey details) (Figure 5).
It is likely that children will  progressively  make  more  use  of  Internet-enabled  mobile  devices  in  most  OECD  countries,  following the Japanese example, depending on countries’ socioeconomic conditions: for example,  14%  of  British  children  aged  12-15  used  their  mobile  phone  to  access  the  Internet  in  2009  (Ofcom,  2010,  p  17).
Moreover,  the  age  at  which  children  acquire  their  first  mobile  phone  is  dropping: the Pew Research Center’s Internet & American Life Project, which tracks adolescent  cell phone use confirms this trend: 58% of those aged 12 owned a mobile phone in 2009 while  only 18% did in 2004  (Pew, 2009, p. 2).
According to another Pew Internet research, 19% of 12- 17 year-olds access the Internet through portable gaming devices (Pew, 2010).
In 2009 in the UK,  12% of 5-15 years-old used their gaming console to access the Internet, rising up to 18% with  children aged 12-15 (Ofcom, 2010, p 17).
Children seem to access the Internet via mobile devices  in addition to fixed computers rather than instead of them (Ofcom, 2010, p 9).
As regards the use of Internet filtering software, trends are not uniform across countries.
However,  in  the  United  Kingdom,  Ofcom  found  a  decrease  in  the  use  of  control  or  filtering  software by parents, from 49% in 2008 to 43% in 2009 (2010, p.4).
Children’s use of the Internet by age group in the United Kingdom (2007)    19      Source: Ofcom, 2007, p. 19.
Children’s main reason for using the Internet by age group in Australia (2009)   Chat to friends Chat to friends  Search for music Search for music  Send/receive emails Send/receive emails  Use MSN Use MSN  Search for information for school homework and projects Search for information for school homework and projects  Search for video clips, cartoons, movies etc Search for video clips, cartoons, movies etc  Use Myspace Use Myspace  Play online games Play online games  Search for information about hobbies and interests Search for information about hobbies and interests  Use Facebook (or Myspace) Use Facebook (or Myspace)  Upload videos/photos taken on your mobile phone Upload videos/photos taken on your mobile phone  Download files using websites or P2P networks Download files using websites or P2P networks  8% 8% 7% 7%  5% 5%  1% 1%  5% 5%  2% 2%  51% 51%  70% 70%  84% 84%  89% 89%  19% 19%  21% 21%  32% 32%  34% 34%  44% 44%  49% 49%  12% 12%  25% 25%  44% 44%  40% 40%  32% 32%  84% 84%  79% 79%  78% 78%  62% 62%  67% 67%  64% 64%  78% 78%  73% 73%  75% 75%  79% 79% 78% 78%  72% 72% 71% 71%  66% 66%  58% 58%  85% 85%  56% 56%  65% 65%  61% 61% 60% 60%  60% 60%  57% 57%  54% 54% 55% 55% 56% 56%  49% 49% 50% 50%  29% 29%  18% 18%  43% 43%  34% 34%  22% 22%  14% 14%  31% 31%  Use eBay/auction sites, internet shopping sites Use eBay/auction sites, internet shopping sites  16% 16%  11% 11% 11% 11%  30% 30%  27% 27%  25% 25%  Use a webcam Use a webcam  Use Bebo Use Bebo  6% 6%  7% 7%  2% 2%  17% 17%  14% 14%  11% 11%  21% 21%  24% 24%  12% 12%  21% 21%  19% 19%  13% 13%  Search for new friends Search for new friends  Use Club penguin Use Club penguin  3% 3% 2% 2% 3% 3%  9% 9%  8% 8%  17% 17% 18% 18%  20% 20%  16% 16%  7% 7%  5% 5% 5% 5% 5% 5%  3% 3%  Work on own website / create own content  Work on own website / create own content   Make a telephone call using VOIP Make a telephone call using VOIP  Source: ACMA,  2009, p. 26.
Percentage of children owning a mobile phone with Internet access in    Japan and the European Union, 2008    21   Mobile with internet  Mobile without internet  No mobile  Doesn't know  0%  10%  20%  30%  40%  50%  60%  70%  Japan  EU      Source: Pew Internet & American Life Project (2010), Social media and mobile internet use among teens and young adults.
In  conclusion,  a  very  high  percentage  of  children  have  access  to  the  Internet  and  general  trends indicate that more children are going online and at an increasingly young age, are using a  multitude  of  devices  and  are  spending  more  time  using  the  Internet.
Understanding  children’s  Internet usage patterns is a prerequisite for public policy-making in this area.
There  are  few  data  on  illegal  interaction,  harmful  advice,  online  marketing  to  children,  fraudulent  transactions,  information  security  risks  and  privacy  risks.
Eurobarometer)  and  analytical  studies are widely available, this is not the case at the international level: quantitative, analytical  and  comparative  studies  are  rare  and  not  necessarily  focused  on  children  (e.g.
Most  research  focuses on teenagers or young adults, and few data are available on younger children, even though  they increasingly access the Internet.
Most studies also focus on computer-based Internet access  and do not take account of mobile Internet, which is increasing steadily and raising new issues.
THE PROTECTION OF CHILDREN ONLINE © OECD   22       Finally, little research seeks to identify groups of children who might be more vulnerable to specific  risks.
Studies  rapidly  become  obsolete  because  of  the  evolution  of  online  usage  patterns  and  the  technology  landscape.
For  example,  over  the  last  12  months,  users  have  switched  from  chat  applications to social networks as the latter implement instant messaging tools.
Furthermore, the  majority of available data are snapshots, and the lack of time series makes it difficult to evaluate  trends.13   Comparability of data   Age:  Age  scale  is  a  major  challenge  in  data  comparisons  as  age  groups  are  not  standard.
Differences are striking when comparing national reports: for example, available data on exposure  to violent content on the Internet in Europe ranges from 90% in Ireland for users aged 10-20, to  25% in Italy for children aged 7-11 (Annex II, Table 2).
Finally, different definitions can lead to  the  use  of  different  measurement  methods  and  thus  affect  prevalence  rates  and  their  comparability.
Conclusion   Empirical  and  analytical  data  on  children’s  Internet  use  and  exposure  to  online  risks  are  widely available but highly fragmentary.
Basic alignments with regard to  the  age  groups  monitored,  the  definitions  of  risk,  and  the  data  sets  on  how  children  use  the  Internet would help to overcome some of these shortcomings.
Data that enable comparative analysis of the prevalence of risk across countries would foster  common understanding of national and regional trends in risks for children online, help develop  effective national policies and facilitate international co-operation.
Concerns about content on the Internet – type of material:    parents vs. children’s perception in the United Kingdom    23     Note: children who expressed concerns about content on the Internet were asked “What sort of things are you worried about?”.
Parents who  expressed concerns about content on the Internet were asked “What sort of things are you worried about for your children?”   Source: Ofcom, 2007, p. 72.
THE PROTECTION OF CHILDREN ONLINE © OECD   24       Typologies of risks         Part I   Online risks for children    Risks to children online reflect the broad spectrum of children's use of the Internet.
Several  classifications  of  risks  have  been  developed  by  the  US  Internet  Safety  Technical  Task  Force  (ISTTF)  and  the  US  Online  Safety  and  Technology  Working  Group  (OSTWG),  the  Australian  Communications and Media Authority (ACMA), EU Kids Online, the European Youth Protection  Roundtable Toolkit (YPRT) and the International Telecommunications Union (ITU) Guidelines  for Policy Makers of Child Online Protection (2009a).
For example, the EU Kids Online report includes a complex risk matrix that takes into account the  role of the child (whether she/he is the initiator of the risky interaction) and the nature of the risk  (commercial,  aggressive,  sexual  and  values-related);  Australia  includes  e-security  risks  such  as  viruses and online fraud which are not covered by the EU Kids Online report.
Several  additional  criteria  can  be  used  to  classify  risks,  including  whether:  i) the  child  is  interacting  with  a  human  (e.g.
illegal downloading); iv) only children are concerned by the risk or it is a general online risk  and children are a particularly vulnerable user group (e.g.
malware, privacy); and v) according to  the  devices  children  use  (e.g.
Finally, risks can be classified according to their  criminal dimension: those that do not have a criminal dimension, those for which the child is a  potential victim of a criminal offence committed by a third party, and those for which the child  commits a criminal offence.15   Overview of risks   Building  on  common  elements  of  existing  classifications  and  focusing  on  OECD  Working  Party on Information Security and Privacy (WPISP) and Committee on Consumer Policy (CCP)  expertise,  this  report  considers  three  broad  categories  of  online  risks  for  children:  i) Internet  technology  risks,  i.e.
when  the  Internet  is  the  medium  through  which  the  child  is  exposed  to  content or where an interaction takes place; ii) consumer-related risks to children online; i.e.
the  child is targeted as a consumer online; and iii) information privacy and security risks, i.e.
risks  every Internet user faces but for which children form a particularly vulnerable user group.
Typology of risks    Based on an overview of the risks (Figure 7), this section provides quantitative information  gleaned from selected studies and reports in order to gauge the current size of the problem.
Given the nature of the literature on online risks faced by children, including quantitative data,  consolidation  of  such  information  is  difficult.
Initiatives  such  as  the  Review  of  Existing  Australian and International Cyber-Safety Research (Dooley et al., 2009) and the EU Kids Online  study provide an in-depth inventory of existing research and have been extensively used here.
Risks pertaining to children as Internet users   Today’s  children  are  often  referred  to  as  “digital  natives”  because  they  grow  up  with  the  Internet.
When they have the opportunity, children are keen Internet users.
Interactivity is  also a fundamental characteristic of the network.
As a consequence, risks pertaining specifically  to children as Internet users comprise content risks (the child passively receives or is exposed to  content available to all Internet users in a one-to-many relationship) and contact risks (the child is  actively involved in a personalised relationship or interaction, whether bilateral or multilateral).
THE PROTECTION OF CHILDREN ONLINE © OECD   26       Age-inappropriate content such as hate, violence or adult pornography, although generally not  illegal, may harm children and their development.
Such content can be  provided commercially but it is also often freely available or can be generated by Internet users.
Internet material available to the general public is often not sensitive to the special situation of  child audiences.
Deliberations on the subject are often informed by traditional television regulation  (Millwood Hargrave, 2009, p. 7) and public concerns tend to focus on pornography and sexually  explicit  content  (De  Haan  and  Livingstone,  2009).
Substantial  reviews  of  the  evidence  on  the  prevalence  of  risk  and  the  consequences  of  children’s  exposure  to  certain  categories  of  age- inappropriate  content,  such  as  pornographic  and  violent  content,  are  available  for  a  number  of  countries (ISTTF, 2008; Dooley et al., 2009; Hasebrink et al., 2009; Media Awareness Network,  2005; Grimm et al., 2008).
On  the  Internet,  children’s accidental  exposure  to pornographic  content  increases when  the  names of problematic websites are modelled after popular children’s websites (for example,  www.teltubbies.com was shut down in 2003 for misleading children).
The National Center for  Missing  &  Exploited  Children’s  CyberTipline  has  maintained  information  on  misleading  domain names since it opened this category in 2000.18   For example, prevalence rates vary depending on the definition of pornography.
Moreover, the notion of pornography is likely to vary not only  across countries but also across communities or groups within a country.
While  it  is  recognised  that  pornographic  material  is  relatively  easy  to  find  on  the  Internet,  some research indicates that younger children are more exposed to pornography offline (e.g.
Unwanted exposure to sexual material by age group (United States)    27   %  50  40  30  20  10  0  10-12  13-15  16-17  Age ranges  All youth  2000     Source: Wolak et al., 2006, p. 8-9.
According  to  a  national  study  (Wolak,  et  al.,  2006),  the  percentage  of  young  American  Internet  users  seeing  unwanted  sexual  material  online  increased  from  25%  in  2000  to 34%  in  2005  (Figure  9)  even  though parents used more filtering, blocking and monitoring software (55% in 2005 compared to  33% in 2000).
However, a survey that measured the impact of exposure to pornography on 10-17  year-olds found that relatively few children were distressed: of the 34% who reported having seen  pornographic content online, only 9% reported being “very or extremely upset”.
The  degree  of  children’s  exposure  to  violent  content  on  the  Internet  is  unclear  and  would  benefit from further research.
Harmful advice can result in suicide, consumption of drugs or alcohol, or the development of  eating disorders (e.g.
As anyone, including minors, can place such content on Web 2.0  platforms, it is particularly difficult to control.
As information on these topics can also be well  intentioned or mix well-intentioned with potentially harmful advice, it is difficult to draw the line  between harmful advice and harmless or even useful advice (Millwood Hargrave et al., 2009).
An American study found over 400 self-harm bulletin  boards which shared information on the most effective self-harm techniques.19 Users were found  to be predominantly female aged between 16 and 23, most of them around 18 years old, and thus  not always children as defined in national law.
An Australian study found that the participants in a  self-harm discussion group were mostly female (mean age of 21.4) and had begun self-harming at  age 13.6 (Murray and Fox, 2006, in Dooley et al., 2009, p. 125).
Cybergrooming, the use of the Internet by an adult to form a trusting relationship with a child  with the intent of having sexual contact, is a criminal offence in several countries.
This is in line  with the provision of the Convention of Council of Europe on the Protection of Children against  Sexual Exploitation (CETS 201) which criminalises sexual solicitation.20    “Stranger  danger”  is  a  term  coined  to  highlight  the  possibility  of  threatening  contact  from  unknown adults, particularly sexual predators, (Byron, 2008, p. 53) not only on the Internet.
However,  quantitative  data  are  limited to a few widely cited studies, such as Wolak’s, which are referred to in most of the relevant  international  literature.
According to Wolak et al., 2006, 25% of  young people interact and share information with strangers online but only 5% have talked to a  stranger online and discussed sexuality (Wolak et al., 2006, and Ybarra et al., 2007, cited in Dooley  et al., 2009, p. 48).
Most  seem  to  be  made  through  chat  rooms  and  instant  messaging;  the  rise  of  social  networks does not seem to have increased the phenomenon.
Out of the 183 case files reported by the Pennsylvania Attorney General between 2005  and 2009, eight incidents (4%) involved teen victims with whom a relationship was formed on the  Internet, 12 (6%) reported predators being deceptive about their age, 166 (90%) were police stings  resulting  in  arrests,  87%  of  which  took  place  in  chatrooms.22  This  last  figure  suggests  that  the  cybergrooming risk does exist but is difficult to measure precisely.
It  can  culminate  in  cyberbullying,  whereby  individuals  or  groups  use  information  and  communication  technologies  deliberately  and  repeatedly to harm others (ENISA, 2007, p. 15; De Haan and Livingstone, 2009, p. 5; Dooley et al.,  2009, p. 61).
Strategies include repeated threats by e-mail, text messages or chat, publication  on the web or circulation of embarrassing pictures, often taking advantage of the relative anonymity  of the online media, although most victims know the identity of the person harassing them (ISTTF,  2008, p. 17; Dooley et al., 2009, p. 11).
There  is  also  a  correlation  with  the  diffusion  of  Internet access and the availability of mobile phones among youth (Hasebrink et al., 2009, p. 91 f.;  Dooley et al., 2009, p. 67 f.).
These range from 4% to 46%, owing to the different definitions in studies or in  countries (Hinduja and Patchin, 2009; Kowalski et al., 2007; Pew Internet & American Life Project,  2007; McQuade and Sampat, 2008; Smith et al., 2008; Williams and Guerra, 2007; Wolak et al.,  2006; Ybarra et al., 2007a, cited in ISTTF, 2008, p.17).
For example, the most common definition  of  cyberbullying  simply  adds  use  of  information  and  communication  technologies  to  bullying,  a  form  of  harassment  generally  involving  aggressiveness,  intent  to  harm,  repetition  and  a  power  imbalance between the bully and the bullied (ISTTF, 2008, p. 17; Finkelhor et al., 2010).
Cyberbullying medium for middle school students in Canada in 2009    41%  23%  35%  via e-mail  via  chatrooms  Via mobile  phones  Source: Li, 2007a, cited in Review of existing Australian and international cyber-safety research (2009), p. 69.
Minors in search of help or assistance can receive harmful advice from incompetent or ill- intentioned advisors on interactive platforms such as social networks or chat rooms.
While the interaction  with a group of like-minded users can normalise and reinforce dangerous practices such as self- harm  or  anorexia  (Dooley  et  al.,  2009,  p.  125, 129),  some  dedicated  online  sites  discuss  these  problems,  and  members  offer  support  rather  than  harmful  advice.
In this category  belong images or videos portraying group or self-inflicted violence and “sexting”, a practice in  which  minors  forward  nude  or  semi-nude  photographs  of  themselves  (ITU  2009a,  p.  33;  Pew  Internet & American Life Project, 2009, p. 4).
This cuts across several  risk categories, as it contributes to the presence of harmful or even  illegal content and once in the public domain poses both a short-term and a long-term threat to the  child’s privacy (Pew Internet & American Life Project, 2009, p.
In an American national survey published in 2007,  4% of youths who use the Internet reported they had received a request for a sexual picture of  themselves  but  only  one  in  1 500  complied  (Mitchell  et  al.,  2007c,  cited  in  ISTTF,  2008,  Appendix C, p. 51).
The  likelihood of sending or receiving such content seems to increase with age: 4% of 12- year-olds  reported having received such images or videos compared to 20% of 16 year-olds and 30% of 17  year-olds (Pew Internet and American Life Project, 2009, p. 2).
For  example, online piracy or sharing copyrighted material can, in some jurisdictions, such as France,  lead to legal proceedings or put the household’s Internet access at risk of being suspended.
Online  gambling by minors, which is illegal in most countries, is a financial threat to parents if minors  have  access  to  a  credit  card  or  other  means  of  payment  such  as  a  mobile  phone.
Children targeted as consumers on the Internet   Children face consumer risks online when i) they receive online marketing messages that are  inappropriate for children (e.g.
For example, an American study in  2006 indicated that over 70% of teenagers who tried to purchase cigarettes online succeeded, and  another from 2002 found that only 2.2% of 1 689 teenagers who smoked bought their cigarettes  online (Dooley et al., 2009, p 133) The promotion and sale of illegal products such as drugs and  doping  substances  on  the  Internet  present  a  risk  primarily  for  adolescents  (US  Department  of  Justice, 2002, p. 1).
For minors,  particularly younger children, commercial content is less distinguishable from other content and  their ability to critically engage with advertising messages is less developed;25 this leaves them  more vulnerable to the influence of online marketing (Fielder et al., 2007, p. 11; De Haan and  Livingston,  2009,  p.  5;  OECD,  2010b,  p.  7).
Children  have  insufficient  understanding  of  how  Internet  content  is  produced  and  financed,  which  is  also  a  reason  why  they  have  difficulty  critically  assessing  advertising  messages  (De  Haan  and  Livingstone,  2009,  p.  5;  Fielder  et  al.,  2007,  p.  12;  UK  Department for Children, Schools and Families, and Department for Culture, Media and Sport,  2009,  p.  88;  Media  Awareness  Network,  2005,  p.  16).
They have also raised the issue of whether or from which age children  should be subjected to full-fledged online marketing practices.
Marketing/advertisement can harm minors by including age-inappropriate content to which  children can be exposed in their daily use of the Internet (e.g.
THE PROTECTION OF CHILDREN ONLINE © OECD   34       A  study  by  the  British  National  Consumer  Council  (now  Consumer  Focus)  and  Childnet  International of commercial activities on websites favoured by children shows that 9% of the ads  are  for  online  gambling  and  4%  for  dating  services  (Fielder  et  al.,  2007,  p.  11).
Internet marketing of food and drink products that are high in fat, sugar and salt (so called  HFSS food) may affect the risk of childhood obesity.
This issue is under public scrutiny in many  countries (Fielder et al., 2007, p. 11).26 Policy makers in some countries have expanded or are  considering expanding existing regulations or self-regulatory measures on the marketing of such  products on television to cover websites targeting children (UK Department for Children, Schools  and Families, and Department for Culture, Media and Sport, 2009, p.105).
For example children can subscribe to fee-based online services or spend  money on online gambling if they have access to means of payment.
Some popular online role- playing  games  require  a  subscription  and  players  can  incur  real  costs  for  virtual  goods  or  advanced virtual characters.
Information privacy and security risks   Information  privacy  and  security  risks  exist  for  all  users.
Children  are  a  particularly  vulnerable group of online users, however, because they often lack the awareness and the capacity  to foresee possible consequences (e.g.
disclosure of personal information online can potentially  make  it  universally  accessible)  while  existing  safeguards  may  be  insufficient  to  protect  their  online privacy and security effectively.
Children’s information privacy   Children  bear  information  privacy  risks  when  their  personal  data  are  collected  online  automatically (e.g.
cookies), upon request by an information service provider (e.g.
when signing  up for a service), or voluntarily, when they fill their personal information in online forms (YPRT,  2009, p. 11).
Like most adults, children tend to skip privacy statements of online services (Fielder  et al., 2007, p. 30; 30th International Conference of Data Protection and Privacy Commissioners,  2008)  when  they  are  written  in  a  language  too  difficult  for  them  to  understand  (Fielder  et  al.,   THE PROTECTION OF CHILDREN ONLINE © OECD    35        2007,  p.  23;  Dooley  et  al.,  2009,  p.  146;  Media  Awareness  Network,  2005,  p.  17),  and  they  readily agree to the use of their data in order to get access to desired websites.
Services popular  with children often fail to implement reliable procedures to ensure that parents are informed and  give their consent on behalf of their children to sign in or create a user account online.27   Personal information as an online commodity   The fact that personal information is becoming an online commodity applies to children as  well as adults.
According to a 2007 study, 95% of British teenagers are concerned that personal  information  is  being  passed  on  to  advertisers  or  other  websites  (Davies,  2007, cited  by  Byron,  2008,  p.  157).
Out  of  40  favourite  children’s  sites,  almost  two-thirds  requested  personal  data,  sometimes  optionally,  in  order  to  access  certain  areas  of  a  site:  name  (70%),  e-mail  address  (53%),  date  of  birth  (43%),  postcode  (40%),  address  (24%)  and  mobile  phone  number  (13%)  (Fielder et al., 2007, p. 25).
Some  marketing  targeting  children  through  surveys,  quizzes  and  contests,  for  example,  collects  personal  information  on  children,  their  family  and  friends,  often  without  regard  to  regulations requiring informed parental consent.
Because  minors  do  not  understand  the  business  model  of  many  Internet  services,  such  as  social network sites and online communities, they tend to underestimate the commercial interest  of their personal data (YPRT, 2009; Fielder et al., 2007, p. 38).
Users are often not aware of the  existence of a two-sided market, whereby online service providers offer services on the one hand  and do business on the basis of users' personal information on the other.
When children use such  services, the challenge is to give adequate information about the purposes and extent of the use of  personal data and to obtain parents’ informed consent.
Children  can  be  subject  to  privacy-invasive  practices  such  as  online  monitoring,  profiling  (YPRT,  2009,  p.  14)  and  behavioural  targeting,  without  their  knowledge  and  without  knowing  what precautions to take (UK Department for Children, Schools and Families, and Department for  Culture, Media and Sport, 2009, p. 14, 84f.
; Council of Europe, 2008c; Children’s Online Privacy  Working Group 2009, p. 8; OECD, 2010b, p. 7).
Personalised advertising to minors also raises  challenges regarding both exposure to commercial content (as noted earlier) and the sharing of  children’s  personal  data  among  service  providers  and  within  advertising  networks.
More  generally,  consumer  groups  warn  about  potential  “negative  impacts  on  children’s  future  self- image and well-being” owing to the use of psychological, behavioural and social techniques in  Internet advertising and marketing (TACD, 2009).
Sharing of personal data   It  is  important  to  take  into  account  the  context  in  which  children  voluntarily  disclose  information,  which  can  range  from  disclosing  personal  data  to  the  entire  Internet  to  sharing  personal information with friends.
Recent research tends to find that children consider offline and  online contexts as part of the same reality: they use the Internet primarily to socialise with people  they already know and perceive the  Internet as a private space for online social activities with  peers.
For  instance, minors have been early adopters of social networks, blogging platforms and other Web  2.0  applications,  and  they  post  information,  images  and  videos  that  reveal  a  great  deal  of  information about themselves, their family and friends.
Children may presume, incorrectly, that  all information they submit remains within the boundaries of their immediate contacts, and they  may fail to anticipate the possible adverse consequences of providing information to “friends of  friends”,  to  people  who  may  subsequently  cease  to  be  friends,  and  to  those  who  may  pass  information on to others.
Children who are keen to create an online identity and to stay in touch with their peers are at  risk of “oversharing”, by divulging more and more personal information, including images.
Peer pressure on social networks can perpetuate this tendency (Dooley et al., 2009, p. 13, 143;  Marwick et al., 2010, p. 5, 20f.).
The extensive use of social networking websites by teenagers is well known.
According to a  2007 Pew Internet Review, 51% of American teens had created a profile on a social networking  website and 21% used it daily.
Girls seem to be more active users of social networks (69% versus  50% of boys aged 15-17), and more likely to use them to communicate (32% versus 17%) and to  post photos online (50% versus 37%).
The use of social networking websites increases as children  get older: 27% of 8-11 year-olds, 55% of 12-15 year-olds and 67% of 16-17 year-olds (Teens and  Social Media, 2007, cited in ACMA, 2009a, p. 21).
Similarly, in Australia, 51% of 8-11 year-olds  use social networking services but 97% of 16-17 year-olds (ACMA, 2009b, p. 30).
Although  young  people  feel  strongly  about  privacy  online,  an  increasing  number  of  them  reveal personal information.
However,  only  5%  to  11% posted more sensitive information, such as their first and last names or phone number (Pew  Internet & American Life Project, 2007; Pierce, 2007b, cited in ISTTF, 2008, Appendix C, p. 40).
A  recent  Australian  survey  indicated  that  74%  of  social  network  users  revealed  personal  information  such  as  e-mail  address,  name  and  date  of  birth  (Model  Criminal  Law  Officers’  Committee, 2008, cited in Dooley et al., 2009, p. 155).
This may be a consequence of the rise of  social networks such as Facebook, where real names and other personal information are given in  order to connect with friends.
Moreover,  although  social  networking  sites  such  as  Facebook,  Bebo  or  MySpace  have  a  minimum  age  of  13  for  registering,  an  increasing  number  of  younger  children  have  created  accounts.
For example, in the United Kingdom in 2009, 22% of Internet users aged 8-11 said they  had  a  social  network  profile,  a  16%  increase  in  2008  (Ofcom,  2010,  p.  5,  74).
However,  the  number  of  young  users  making  their  profile  public  seems  to  decrease:  83%  of  8-12  year-old  Internet  users  said  they  were  making  their  profile  visible  only  to  friends  against  67%  in  2008.
Boys seem to be more likely (21%) to leave their profile open than girls (13%) (Ofcom, 2010, p.  74) but are also more likely (64%) to use fake data on their profiles than girls (50%) (Pew  Internet & American Life Project, 2007, p.iii).
Parents also seem aware that their child visits  social networking sites, as 93% declared that they check what their child is doing on them.
THE PROTECTION OF CHILDREN ONLINE © OECD    37           Young  people  may  not  anticipate  the  long-term  problems  that  may  be  created  by  the  irretrievable, searchable, easy to manipulate and persistent nature of personal information online  (YPRT, 2009, p. 11; Marwick et al., 2010, p. 4).
Personal information can also be posted by someone else.
For example tagging as a means of  linking  individuals  to  their  digital  photos,  locations  and  events  is  now  widely  practiced  and  children do not, and do not need to, ask permission from the persons concerned (ENISA, 2007, p.  21; Grimm, et al., 2008, p. 11).
Some studies note that young people consider sharing their passwords an easy way for their  friends  to  check  e-mail  or  social  networking  sites  on  their  behalf,  or  as  a  mechanism  to  demonstrate  trust  (similar  to  knowing  a  locker  combination)  (Marwick  et  al.,  2010,  p.  13).
Minors’ personal information, when spread online, can be linked to individual profiles and be  used by third parties with malicious intent (e.g.
New possible threats for children’s information privacy are the potential for abuse of location- identifying  information  from  digital  images  (GPS  data)  and  other  location-based  services  (e.g.
There might be a “privacy protection paradox” if children are subject to “friendly” surveillance by  adults  as  a  way  to  protect  them  from  offline  and  online  risks,  including  privacy  risks.
For  example,  certain  parental  control  technologies can provide  detailed  reports  on  online  activities.
THE PROTECTION OF CHILDREN ONLINE © OECD   38       Information security risks   Information  security  poses  a  challenge  for  Internet  users  in  general;  however,  children  are  particularly vulnerable to information security risks stemming from malicious code (e.g.
Commercial  spyware  can  be  picked  up  on  websites  for  children  and  stored  on  the  user’s  device  to  monitor  online  behaviour  (ITU,  2009a,  p.  33;  US  FCC,  2009,  para.
When  the  monitoring goes beyond what is necessary to perform the service, information may be collected  from  children  for  other  purposes  (e.g.
This  use  has  been  questioned  in  the  context of children’s information privacy  (UK Department for Children, Schools and  Families,  and Department for Culture, Media and Sport, 2009, p. 51).
The  heightened  probability  of  information  security  risks  is  correlated  with  the  popularity  among  young  users  of  certain  online  activities  which  are  conducted  without  appropriate  safeguards.
If not detected, it can damage the system or, more  likely, steal sensitive information or take control of the computer and network as part of a broader  cyberattack  system  (OECD,  2009b,  p.  23).
Although  computers  are  the  most  common  targets,  malicious code exists for any electronic communications and online platform, including mobile  devices (OECD, 2006, p. 39, 2009b, p. 23) and even social network sites (ENISA, 2007, p. 12),  where profiles are hijacked in order to distribute spam.
While many children demonstrate advanced computing or digital literacy skills, a lack of risk  awareness can explain negligence regarding information security.
For example, the installation of  file-sharing software and peer-to-peer programmes creates public access to the storage medium of  the  user’s  computer  in  order  to  facilitate  the  exchange,  and  can,  if  not  properly  set  up,  compromise personal files.
Phishing  attacks  represent a common information security risk: users of all ages are lured to a website under a false  pretext and enter personal or financial information (Dooley et al., 2009, p. 149).
Compromised  information can be abused by identity thieves with various consequences even if it does not result  in financial loss.
Conclusion   Risks vary from country to country depending on children’s ability to access the Internet as  well  as  on  a  range  of  social  and  cultural  factors  (Livingstone  and  Haddon,  2009,  p.  17).
Some countries do better  than  others:  typically,  research  has  found  that  in  Denmark  and  Sweden  high  Internet  use  by  children can be associated with medium online risks.
Children’s vulnerability to online risks results from  their lack of experience, awareness and critical capacity to fend off or manage risky situations.
The consequences of the risks vary and the most severe include physical and psychological  harm.
enduring  detrimental  personal  information  online)  should  not  however  be  underestimated.
Information  about  the  actual  prevalence  of  risk  and  about  factors  that  play  a  role  in  the  materialisation  of  risks  is  essential  in  order  to  inform  policy  makers  meaningfully  (ISTTF,  2008,  p.  13),  and  to  avoid  misrepresentation  of  risks  and  misguidance of public policy (Livingstone and Haddon, 2009, p. 22; Powell et al., 2010, p. 6).
Other  factors  that  influence  the  likelihood  of  encountering  online  risks  include  children’s  age  and  gender,  which  partly determine their online activities (Livingstone and Haddon, 2009, p. 16).
This underlines the  need  for  more  research  into  these  variables  to  identify  more  vulnerable  groups  and  tailor  risk  mitigation strategies accordingly.
THE PROTECTION OF CHILDREN ONLINE © OECD         40   Part II   Policy measures to protect children online         This  section  analyses  existing  policies  to  protect  children  online  (for  a  more  detailed  overview, see Annex I), highlights commonalities and differences in approaches, and discusses  possible means to reduce gaps and increase international co-operation.
Countries  generally  agree  that  the  Internet  offers  a  broad  spectrum  of  opportunities  for  children in terms of their identity and self-expression, education and learning,30 and, increasingly,  their creativity, participation and online citizenship.31 They also recognise that children’s use of  the Internet exposes them to various risks.
Countries therefore believe that children should be protected when they use the Internet and  have taken various policy measures to mitigate their online risks.
National  policy  measures  reflect  to  some  extent  the  classification  of  risks  adopted  in  this  report (see Part I), since they often address one of the three main categories of risks but rarely a  combination  of  these.
Conversely,  when  operators  of  websites  adopt  voluntary  measures  to  protect child users from online risks, the approach is more inclusive and tends to reflect a wider  spectrum of online risks for children.
The following discussion covers the various dimensions of child protection policy as they are  implemented  and  pursued  in  most  countries:  i) multi-layered  policies  comprising  direct  and  indirect policy tools; ii) multi-stakeholder policies related to the various roles and responsibilities  of stakeholders; and iii) multi-level policy mechanisms at national and international levels.
Countries  such  as  Japan  and  the  United  States  have  partial  strategies  and  measures  to  protect  children online; policies implemented by various agencies and ministries are not necessarily part  of a single strategic vision.
Both national and partial strategies can help make the Internet a safer  place  for  children.
The EU Safer  Internet  Programme  (SIP)  provides  an  example  of  a  regional  effort that plays a key role in promoting child online safety across a large group of countries.
THE PROTECTION OF CHILDREN ONLINE - © OECD    41           All countries' approaches blend legislative, self- and co-regulatory, technical, awareness, and  educational measures, as well as positive content provision and child safety zones.
It is not at present possible to  compare the effectiveness of high-level policies owing to a lack of comparable evidence to make  a case for best practices.
Legal measures   Most countries would subscribe to the statement that what is illegal offline should be illegal  online and champion a normative approach to child protection online.
It generally applies to content published on the Internet rather than to content passed  on via individual data exchange.
Most  countries  have  updated  content  regulations  to  include  the  Internet  (i.e.
horizontal regulation), some have passed Internet-specific legislation (Japan, Korea, Turkey) and  a few (Canada and the United States) have by and large refrained from issuing new legislation,  not  least  because  of  constitutional  requirements.
harassment  is  extended  to  include  cyber-harassment).
The protection of children against consumer-related online risks is to some extent addressed  through  legal  measures  related  to  regulated  activities.
There is no specific legislation to mitigate information security risks for children.
Countries report unanimously that legal safeguards are under considerable strain for reasons  that are inherent to the Internet as a global and highly dynamic information space.
A number of  countries recognise that the Internet has outpaced legal definitions and normative concepts and  that legal patch-ups can quickly become outdated if they focus too narrowly on a specific use or  technology.
A  number  of  countries  have  moved  towards  regulating  or  otherwise  committing  Internet  intermediaries  to  comply  with  so-called  “notice  and  take  down  procedures”  (mandatory  in  Australia, Italy, Japan, Korea and Turkey) or to introduce mandatory filtering schemes (Turkey,  planned in Australia).
Canada,  European  countries)  general  data  protection  laws  apply  to  the  collection  of  children’s  personal  data;  there  are  no  specific  provisions.33  However,  the United States  provides an  example  of  a  targeted legislative  response, the Children’s Online Privacy Protection Act (COPPA),34 which protects children up to  the age of 13 and requires website operators targeting these children or having actual knowledge  of  child  users  to  collect  verifiable  parental  consent.
Japan has specific guidelines for students’  data protection at school, “Guidelines concerning the measures to be taken by entities to ensure  the proper handling of personal information of students and others at schools”, which is mainly  applied  for  enforcing  of  the  Act  on  the  Protection  of  Personal  Information  to  private  schools  handling students’ personal data.
It concerns the rights of students, and has clauses concerning the  danger of child abuse and domestic violence when statutory agents of children (parents in many  cases) demand the disclosure of retained personal data of children.35   More  specifically,  limits  to  the  consent  requirement,  discussed  elsewhere  by  the  OECD  (2010a), are aggravated by the lack of effective mechanisms for obtaining parental consent.
Other  protections  required  by  privacy  laws,  whether  online  or  offline,  such  as  privacy  notices  or  the  right of access, are unlikely to be more effective for children and their parents than overall.
More- over, in the online context the data controller cannot easily verify the age of the data subject.36  While specific protection measures are probably less difficult to implement for online applications  that obviously target children, applications that target the whole population do not have an easy  and efficient way to distinguish children from other users.
As ever younger children increasingly use the Internet, the actual level of protection afforded  by current legal data protection mechanisms with respect to the collection of their personal data is  low.
The  complexity  of  laws  and  regulations  pertaining  to  the  Internet,  and  more  specifically  aimed to make the Internet a safer place for children, should not mask the fact that legal measures  alone are insufficient to achieve this goal.
Combinations of complementary policy measures, such  as legally twinning prohibitions with technical access restrictions to child-inappropriate content  (e.g.
social  networking  sites)  and  updated  in  order to stay abreast with technological developments and social trends which are the particular  strengths of this model (IT, 2009a, p. 5; ITU, 2009b).
Self- and co-regulation are ways for industry to support efforts to protect children online.
For  example, Internet intermediaries voluntarily commit to give effect to national policies by adhering  to notice and take-down regimes and/or voluntary filtering of certain types of illegal content.
High  traffic websites such as social networking services can promote better cyber-safety practices and  standards, in particular where governments have no jurisdiction.
When markets are concentrated  as a result of substantial network effects – social networks, online communities, search engines –  the largest providers are also best placed to protect the children among their users.
Many countries  therefore  promote  self-  and  co-regulation,  for  example  through  public-private  partnerships,  as  evidenced  by  the  many  voluntary  commitments  of  Internet  service  providers  and  their  national  associations,  on  the  one  hand,  and  of  social  network  site  operators  in  the  EU  and  the  United  States, on the other.37   THE PROTECTION OF CHILDREN ONLINE © OECD    43           Consolidation  of  existing  self-  and  co-regulation  to  protect  children  online,  common  framework principles across industries, and independent evaluations would make this model even  more  effective  (Byron,  2008,  p.  180;  Livingstone  and  Haddon,  2009,  p.  26;  ITU,  2009b).
Government  collaboration  with  other  intermediaries,  such  as  online  advertising  networks,  can  provide  another  avenue  for  protecting children against inappropriate marketing.
Technical measures   Governments also understand that there is no “silver bullet” solution and that each technology  has  its  strengths  and  limitations  and  should  be  used  in  the  most  appropriate  context.
Recent  reviews  of  the  most  advanced  technology  to  protect  children  online  find  significant  progress,  which  yields  “cautious  optimism”  (ISTTF,  2008,  p.  5).
Some  technology-driven  mechanisms,  such as report abuse functions and content labelling frameworks, demonstrate the usefulness of  technical measures to mitigate risks and enhance online safety for children.
Apart from improving  the  performance,  reliability  and  usability  of  technology,  future  efforts  should  strive  to  improve  interoperability across a wider variety of distribution platforms and devices (ISTTF, 2008, p. 28;  US FCC, 2009, para.
National  policies  vary  greatly  in  their  reliance  on  technical  measures.
Overall,  however,  there is no overreliance on technology.
Governments generally promote and sometimes mandate  technical measures at various levels in concert with other risk-mitigation strategies.
For example,  technical  measures  often  complement  legal  obligations,  as  when  national  content  regulations  require that child-inappropriate online content be subject to access controls, e.g.
Essentially,  when  countries  resort  to  mandatory  filtering  of  the  Internet,  the  measures  necessarily apply to the whole population and are therefore used - if at all - to suppress illegal or  criminal online content.
Italy; in Germany it is a legal obligation but  it  is  not  implemented)  and  the  European  Union  and  other  countries  are  exploring  this  policy  option  in  the  interest  of  victims.
In  a  range  of  countries,  filtering  schemes  operate  as  part  of  the  voluntary  commitment  of  Internet service providers to block access to illegal content and in particular to images of sexual  abuse of children.
Outright prohibitions and mandatory filtering at the level of Internet service providers (ISPs)  are generally not used for content that is child-inappropriate or harmful to minors, as this would  make the Internet a child-safe zone for all users.
Public policy can promote voluntary technical options such as parental controls by enhancing  awareness of their availability and confidence in them (e.g.
No countries so  far  require  or  encourage,  as  a  general  policy,  software  settings  to  be  preset  to  protect  children  online (i.e.
Future efforts  should concentrate on making it easier for users, and parents in particular, to manage technologies  and personal settings to protect children.39      THE PROTECTION OF CHILDREN ONLINE © OECD   44       Besides devices designed and configured for children and the possibility to bar or restrict certain  functionalities, for example of mobile phones, for child users, software design plays an important  role in protecting children online.
Private companies that collect a great deal of information about  children need to emphasise software design that makes privacy settings and rules easier to adjust and  to understand for children and their parents (Marwick et al., 2010, p. 66 f.).
The  current  trend  to  integrate  media  and/or  Internet  literacy  in  school  curricula  can  be  an  effective way to equip children with the knowledge and skills necessary to stay safe online and  use the Internet to their benefit.
The content and learning outcomes of Internet literacy courses  vary widely, with many countries emphasising cybersecurity (e.g.
United States) and information  ethics (e.g.
Given  that  policy  can  mitigate  but  not  totally  eliminate  all  online  risks,  Australia,  New  Zealand and the United Kingdom have embarked on a more inclusive concept of Internet literacy.
The  notion  of  digital  citizenship  education  carries  Internet  literacy  forward  to  include  coping  strategies, and trains children to engage responsibly in creative and participatory online activities  (ACMA, 2009a, p. 50; Livingstone and Haddon, 2009, p. 25; YPRT, 2009, p. 32 f.; OSTWG,  2010, p. 5).
Germany for instance is supporting the  creation  of  high-quality  and  innovative  Internet  content  for  children  with  an  annual  budget  of  EUR 1.5 million over a three-year period.
The provision of positive online content for children  can be challenging as it must stand comparison with other Internet services.
Conversely, portals that restrict  access to approved services (“walled gardens”) generally maintain a definition of content which is  suitable and therefore admissible within their service.
Some  countries  have  created  new  bodies  to  co-ordinate  the  activities  of  public  and  private  stakeholders,  such  as  the  United  Kingdom  Council  for  Child  Internet  Safety,  or  to  inform  government policy and advise on research projects, such as the Australian Consultative Working  Group on Cybersafety.
Other authorities involved include law enforcement, media regula- tors  and  classification  bodies,  specialised  public  agencies  (e.g.
the  Turkish  Internet  Regulations  Department),  communications  regulators  (e.g.
A concerted policy approach requires clear responsibilities and co-ordination among all public   bodies involved.
Therefore, it is commonly understood that policies to protect  children online must be tailored to their needs, risks and stages of development.
In  many  countries  certain  educational  approaches  are  adapted  to  specific  age  groups  and  policy makers emphasise that filters such as those deployed in parental controls should therefore  be customisable.
Besides integrating Internet literacy in schools’ curricula, little or no informa- tion is available on effective strategies for identifying and reaching out to categories of children  who are more at risk than others, such as those whose parents cannot play the role expected of  them in a policy model based on shared responsibility.
Australia, United Kingdom) recognise children as  active stakeholders in their formulation of policy and implementation processes (ACMA, 2009,  p. 25).
Children are invited to participate in forums at which they can give their views on online  risks  and  policy  measures.40  Involving  children  more  actively  in  developing  such  policies  can  contribute  to  better  policy  measures.
Children  can  also  be  more  engaged  in  peer  education  strategies and can help relay information about online risks and risk mitigation strategies.41      THE PROTECTION OF CHILDREN ONLINE © OECD   46       Parents and caregivers   All  countries’  policies  rest  to  varying  degrees  on  voluntary  measures  taken  by  parents  and  other caregivers to protect children online.
Where government intervention in Internet  content  control  and  online  activities  is  minimal  (e.g.
Parents have various means to assist their child and mitigate online  risks, such as parental guidance and rules on when and how to use the Internet as well as technical  tools such as parental control software.
However, to act effectively, parents must be provided with information and appropriate tools,  and even then, there are limits to what they can and will shoulder.42 Some countries have started  to gear many policy measures towards parents, with a focus on awareness raising, child safe zones  and online positive content provision, and the promotion of parental controls.
For example, the  United Kingdom Kitemark scheme not only considers whether a technology is efficient but also  whether it is easy to install and to set up for parents.
Given the numerous entry points for parents  willing to protect their children online, countries could consider consolidating advice and promoting  parental control solutions which work across various platforms and technologies.
Educators and public institutions   The  role  of  educators,  social  workers  and  other  trainers  in  children’s  Internet  literacy  is  generally  acknowledged,  as  is  the  need  to  protect  children  when  they  use  online  facilities  of  public institutions such as schools and libraries.
Some countries have introduced Internet safety training for educators and started to include  Internet  literacy  training  in  teachers’  education  (e.g.
The training of teachers and their  access to suitable teaching resources is essential for a successful Internet literacy strategy.
Public  institutions  are  often  required  by  law,  encouraged  or  given  incentives  to  adopt  technical  measures  and  institutional  policies  in  order  to  protect  children.
anti-harass- ment policies, acceptable use policies) and technical measures (e.g.
filters) to help protect children  and enhance responsible use of the Internet.
Many service providers have accepted responsibility for introducing more nuanced safeguards for  children  and  for  self-policing  their  websites  and  implementing  use  policies.
Many  countries  actively  promote  industry  self-  and  co-regulation  in  order  to  implicate  the  private  sector  and  enhance compliance.
Many non-profit private organisations work to make the Internet a safer place for children.
THE PROTECTION OF CHILDREN ONLINE © OECD        Multi-level policies     47   At the national and international level, online child protection policies aim to achieve policy   and operational collaboration.
As this is the aim of a variety of public policy measures and private  initiatives, the role of public leadership extends beyond “command and control” intervention to  co-operation,  co-ordination,  assistance  and  support  to  stakeholders.
It  has  committed  some  EUR 81 million over  four  years,  among  others  to cyber-safety  education  and  awareness-raising  activities,  law  enforcement,  and  the  exploration  of  a  national  content filtering scheme expected to become mandatory for Internet service providers.
In  general,  governments  already  have  in  place  some  child  protection  legislation  and  other  measures.
Stocktaking exercises to provide an overview of the various public and private initia- tives that protect children online might be useful to inform policy makers.
Policy  development,  co-ordination  and  management  need  to  be  sufficiently  resourced,  including in countries that rely heavily on market mechanisms and parental responsibility.
International co-operation   Countries generally consider international co-operation essential for protecting children on an  inherently  global  medium.
Beyond  sharing  best  practices,  international  co-operation  at  the  operational level has produced a number of promising initiatives which can serve as models.
International co-operation at policy level   As  fits  their  mandate,  membership  and  areas  of  expertise,  various  international  bodies  are  involved  in  an  international  dialogue  on  the protection of  children  online, e.g.
the  ITU’s Child  Online  Protection  (COP)  Initiative  and  the  Dynamic  Coalition  for  Child  Online  Safety  in  the  framework  of  the  Internet  Governance  Forum  (IGF).
Policy  frameworks  such  as  that  of  the  Council  of  Europe  on  the  protection  of  minors  against  harmful  content  and  on  developing  children’s media literacy skills have achieved a high degree of policy co-ordination at regional  level.
Table  2  summarises  the  main  initiatives  of  international  organisations  and  advances  in  cross-border co-operation towards the protection of children on the Internet.
Initiatives for international co-operation by intergovernmental organisations   Organisation  APEC   Council of  Europe   ITU   OECD   UNICEF   WSIS/IGF   International co-operation activities   ?
On 15 April 2009, APEC and the OECD held a joint symposium to exchange best practices on the protection of  children online (APEC TEL 39, Singapore).
The Council of Europe addresses cybercrime and the sexual exploitation and abuse of children through information  and communication technologies by:  ?
Setting common standards and policies, i.e.
Preparing a global study (ongoing) on Criminal Law Measures to Protect Children Against Sexual Exploitation  and Abuse.
Providing own resources for educative and preventive measures and to empower children.1   ?
ITU pursues its work on Child Online Protection at policy and operational level:  ?
and policies with regard to user-created content;   Child Online Protection (COP) Initiative is a multi-stakeholder effort of ITU membership to create awareness and  to develop practical tools and resources to help mitigate risks.2   Council Working Group on Child Online Protection3 (CWG-CP) is a platform for member states, sector members  and external experts to exchange views and advance the work on child online protection, in particular by:  o  developing reports on the source of online threats to youth and children and on social networking services  o  devising ITU’s Child Online Protection Statistical Framework and Indicators (ITU, 2010b).
On the 2009 World Telecommunication and Information Society Day (WTISD) ITU announced a year-long call  for action on child online protection.
At the Seoul Ministerial Meeting on the Future of the Internet Economy (June 2008), Ministers encouraged  collaboration between governments, the private sector, civil society and the Internet technical community to  build understanding of the impact of the Internet on minors in order to enhance their protection and support  when using the Internet.
In 2009, the OECD Working Party on Information Security and Privacy launched a project to analyse risks faced  by children online and policies to protect them and, as appropriate, develop policy guidance/principles in this  area.
The outcome documents of the World Summit on the Information Society (WSIS) contain strong commitments on the  protection of children online:  ?
The Geneva Declaration of Principles states that the development of ICT applications and operation of services  respects the rights of children as well as their protection and well-being.
Paragraph 24 of the Tunis Commitment recognises “the role of ICTs in the protection of children and in  enhancing the development of children”.
Its successor, the Internet Governance Forum (IGF), provides an annual international and multi-stakeholder platform  to exchange views on children and young people, among others.
1. www.coe.int/t/dghl/cooperation/economiccrime/cybercrime/Documents/Protecting%20children/Default_en.asp  2. www.itu.int/osg/csd/cybersecurity/gca/cop/  3. www.itu.int/council/groups/wg-cop/   THE PROTECTION OF CHILDREN ONLINE © OECD        International co-operation at operational level     49   Several successful international co-operation initiatives at operational level have already been  carried  out,  in  the  areas  of  law  enforcement,  exchange  of  hotline  reports  about  illegal  online  material  (i.e.
INHOPE)  and  sharing  of  best  practices  for  the  protection  of  children  online  (i.e.
The networking of hotlines and awareness centres is a successful initiative which could  be strengthened and further resourced.
These networks could also inspire similar initiatives with  different goals.
The  development  of  comparable  indicators  to  measure  various  aspects  of  the  protection  of  children online, from access and use of the Internet by children to risk prevalence and the impact  of policies could help improve policy development and implementation.
EU efforts in this area  have helped, for example, to better understand the relationship between Internet use and online  risks and the positive role public policy can play in the mitigation of online risks.
As can be seen  from  the  EU  Kids  Online  project,  countries  benefit  greatly  from  the  availability  of  evidence  reviews, up-to-date surveys and comparative data.43    Awareness  raising  is  another  area  in  which  international  co-operation  can  be  beneficial.
Simple measures such as the use of light intellectual property protection on educational materials  can be of great interest to other countries, who could tailor them to their national context.
Hector’s  World  for  example  was  developed  with  a  view  to  being  made  available  internationally.44  The  Safer Internet Day has proven international appeal and could be supported by more organisations  and in more countries.
Enhanced interoperability of technical measures such as parental controls across distribution  platforms and devices (ISTTF, 2008, p. 20) requires international co-operation for setting standards.
The  Quarto+  project,  for  instance,  develops  an  inclusive  and  open  international  standard  for  interfaces  between  content  classifications  and  filtering  technologies  which  does  not  require  harmonisation of national content rules.
Comparative policy analysis   It is commonly agreed that the main challenge for protecting children online is to combine the  available  direct  and  indirect  policy  measures  described  above.
In  practice,  countries  operate  a  national  policy  mix  with  varying  characteristics  and  priorities  which  correspond  to  their  legal  system and governmental culture.
Besides  these  two  important  dimensions,  countries  can  be  divided  into three groups reflecting how they address other policy tools: i) those in which a combination  of  legal  and  technological  measures  prevails;  ii) those  that  favour  self-  and  co-regulation  and  voluntary measures; iii) those in which no type of measure predominates in the policy mix.
Australia, Japan, Korea and Turkey generally belong to the first group which emphasises the  combination of legal and technological measures, including the voluntary introduction of technical  safeguards.
They  maintain  content  regulation  to  address  content  that  is  illegal  or  harmful  to  minors  (the  classification  can  have  further granularity) and they encourage or require mandatory filtering of illegal content by ISPs.
In  addition,  service  providers  are  sometimes  required  to  deploy  technical  measures  that  help  protect  children,  such  as  filters  on  mobile  phones  of  under-age  users  in  Japan  or  the  use  of  approved  filter  services  in  cybercafés  in  Turkey.
There  also  tends  to  be  a  strong  self-  and  co-  THE PROTECTION OF CHILDREN ONLINE © OECD   50       regulatory component with regard to content- and contact-related risks and public encouragement  to install voluntary technical safeguards such as parental controls.
Canada and the United States are representative of the second group of countries.
They pursue  a “soft law” approach by promoting self- and co-regulation and voluntary measures, including the  voluntary use of parental controls.
Self- and co- regulation  by  popular  social  network  and  community  sites  are  a  source  of  normative  content  provisions  and  voluntary  agreements  to  improve  protection  of  child  users  and  self-police  their  services.
The body of self- and co-regulation in these countries appears to be very diverse, with  little consolidation across industries and service clusters.
Finally,  the  EU  and  European  countries  tend  to  make  use  of  all  policy  measures  with  combinations varying according to risk categories.
These countries commonly adopt legislation  related  to  content-related  risks  and  oblige  service  providers  to  prevent  children  from  accessing  inappropriate  content.
Typically,  the  introduction  of  technical  filters  and  other  safeguards  by  industry  is  based  on  voluntary  commitments  by  ISPs  and  other  Internet  intermediaries and are often the result of co-regulation or brokered in public-private partnerships.
Educational  and  awareness-raising  measures  form  an  integral  part  of  national  policy,  with  variations from north to south and east to west.
Countries not included in one of the three groups are not inactive but do not pursue a clear  policy towards protecting children as Internet users against online risks and may have different  pressing  policy  priorities,  such  as  combating  online  forms  of  sexual  abuse  and  exploitation  of  children, as in Thailand and the Philippines.
Governments and stakeholders could work together to consolidate the age up to  which children should be protected and agree on generic age cohorts (e.g.
As  noted  earlier,  the  lack  of  harmonisation  of  age  cohorts  is  also  a  serious  obstacle  to  international comparisons of the prevalence of risk and of policy efficiency.
A common definition of  children’s age cohorts across countries and among stakeholders would help establish standards at the  regional and international levels.
More consistent age limits would also facilitate the implementation  of protection mechanisms for online services providers operating in several countries.
Combinations of policy measures   An analysis of existing policies to protect children online (US FCC, 2009, p. 61; EC, 2008b,  p.  27)  reveals  that  no  country  relies  solely  on  one  policy  instrument  to  tackle  a  risk  category.
Policy  measures  are  combined  to  reinforce  each  other  (e.g.
promotion  of  parental  controls  and  awareness  raising  among  parents  about  their  availability).
THE PROTECTION OF CHILDREN ONLINE © OECD    51   Combinations  of  complementary  policy  measures  pertaining  to  certain  risks,  such  as  normative and technical measures (e.g.
The  implementation  of  “effective  access  restrictions”  is  often  mandatory  for  certain  websites,  but  the  choice  of  appropriate  measures  it  is  left  to  the  market.
Even  more  complex  combinations  of  policy  instruments  are  emerging,  notably  when  regulation  of  online  content  is  implemented  through labelling and classification schemes combined with  various  modalities of  access  restrictions  on  the  part  of  website  operators  and  the  voluntary  use  of  parental  control  technology.
Examples of complementary policy measures mandated by law   Country   Policy measure   Complementary technical policy measure   Korea   Regulation of child-inappropriate content   Italy, Korea, Turkey   Regulation of prohibited and illegal content   United Kingdom   Online gambling prohibition   Japan   Regulation of child-inappropriate content   United States   Parental consent requirement under COPPA   Access restriction via reliance on national identity verification  systems  Mandatory ISP-level filtering    Online gambling websites are required to put age verification  in place   Mandatory filters on mobile phones of users under 18 unless  parents opt out  E-mail  from  parents’  e-mail  account,    provision  of  parents’  credit card details, written consent form from the parent, or  telephone call from parent.
Use of evidence, policy assessments and performance evaluations   To inform and evaluate public policy to protect children online, some countries increasingly  seek information and evidence on the availability, feasibility and – to a lesser extent – effective- ness of measures.
Expert  reports  and  original  research  are  contributing  significantly  to  understanding  how  children use the Internet and how they are affected by the Internet as well as the prevalence of  risk.45   ?
Feasibility and technical studies provide insight into how technical measures can help mitigate  online  risks  for  children  and  into  the  development,  reliability  and  shortcomings  of  technologies.46   ?
With some notable exceptions, the impact of regional and national policy frameworks for child  protection online is not regularly assessed, and performance evaluations are only exceptionally  built  into  the  policy,  notably  when  third-party  measures  are  publicly  funded.
The  lack  of  assessment  of  the  policy  impacts  of  certain  measures,  notably  on  freedom  of  speech  and  privacy, can be observed at all levels and raises concerns among all categories of stakeholders.
Likewise, awareness raising and Internet literacy, which are at the core of  many national policies, would benefit from better monitoring of their effectiveness.
THE PROTECTION OF CHILDREN ONLINE © OECD   52       Exceptions  include  the  EU’s  Safer  Internet  Programme,  which  incorporates  a  social  and  economic impact assessment of policy formulation and independent evaluations of the measures  adopted,48 and the UK Child Internet Safety Strategy, for which progress will be evaluated on the  basis of pre-defined targets and benchmarks.49    Examples of the evaluation of voluntary commitments include the European Framework for  Safer Mobile Use by Younger Teenagers and Children and the Safer Social Network Principles  (PricewaterhouseCoopers, 2009; Staksrud and Lobe, 2010).
Examples of independent evaluation include the  United  Kingdom’s  Ofcom-funded  evaluation  of  the  delivery  of  the  Know  IT  All  presentation  (Woollard  et  al.,  2007)  and  a  study  assessing  the  effectiveness  of  the  NetSmartz  programme  (Branch Associates, 2002).
The preceding overview of existing policies shows that this is a  relatively new policy area when compared to more traditional Internet issues, but that a variety of  policy tools are available.
the  protection  of  children  online  requires  a  careful  balance  between  the  risks  and  opportunities presented by the Internet;  the dynamic and universally accessible nature of Internet content challenges national  policies;  this  policy  issue  calls  for  a  combination  of  public  and  private,  legal  and  voluntary  measures at various levels;    ?
all stakeholders share responsibility for protecting children online and co-ordination of   their roles is necessary;   international  co-operation  at  policy  and  operational  levels  is  essential  to  protect  children online successfully and to mitigate risk (Muir, 2005, p. 6).
multi-layered measures – legal, self- and co-regulatory, technical, educational as well   as awareness raising;   ?
multi-level  approaches  at  national  and  international  levels,  at  policy  and  operational   levels.
Several  national  and  international  bodies  have  issued  recommendations  on  policies  for  the  protection of children online, including the US Internet Safety Technical Task Force (ISTTF) and  Online  Safety  and  Technology  Working  Group  (OSTWG),  the  reports  of  the  Australian  Communications and Media Authority (ACMA), the EU Kids Online project, the European Youth  Protection  Roundtable  (YPRT)  and  the  International  Telecommunications  Union  (ITU)  Guidelines  for  Policy  Makers  of  Child  Online  Protection  (2009a).
However,  ensuring  the  co-ordination  and  consistency  of  policies  to  protect  children  online  and  their  alignment  with  sectoral  policies  such  as  information  society  policies  is  a  challenge.
The  policy  coherence  framework  (see  Box  1)  can  encompass  government  policies,  including  measures  that  encourage  non-governmental  actions,  notably  initiatives  by  business  (e.g.
Policy  co-ordination  means  getting  the  various  institutional  and  managerial  systems  that   formulate policy to work together.
Policy consistency  means ensuring that individual policies are not internally contradictory   and avoiding policies that conflict with reaching a given policy objective.
Co-ordination   The aim of policy co-ordination is to combine the institutional and managerial processes and  tools  at  governments’  disposal  to  devise,  influence  and  promote  a  variety  of  policy  measures  which  operate  together  so  that  children  are  protected  effectively  online.
Effective  co-ordination  entails  examining  how  different  policy  measures  interact,  whether  interdependent measures work well together, and how to optimise interfaces among the various  policy measures.
Means to this end include steering committees, either government-led or in which  government participates with all stakeholders, which examine various feedback mechanisms, define  national agendas and evaluate and adjust national policies where necessary.
The United Kingdom  provides an interesting example in the Council for Child Internet Safety, an organisation composed  of  150  stakeholders  and  tasked  with  developing  and  implementing  a  Child  Internet  Safety  Strategy.50    Switching  from  an  aggregation  of  fragmented  public  and  private  policy  initiatives  to  a  strategic  vision  with  high-level  leadership  and  long-term  commitment  helps  increase  the  efficiency of existing and future policy efforts.
Consistency   Policy consistency aims to ensure that individual policies are not internally contradictory and  do not conflict with the realisation of a given policy objective.
definition of a child) and by consolidating public information and guidance  (e.g.
use  of  harmonised  expressions  such  as  “parental  controls”).
THE PROTECTION OF CHILDREN ONLINE © OECD    55        The interdependence of online opportunities and risks for children draws attention to the need  for consistency, as some strategies designed to protect  children online may reduce  the benefits  they can obtain from the Internet.
Developing measures that prevent and mitigate risks without  unduly reducing the benefits of the Internet for children requires a thorough understanding of the  relationship between risk incidence and/or harm, the prevalence of online risks, and the impact of  policy measures (Powell et al., 2010, p. 6).
Public policy has to be flexible to accommodate the  various development stages and vulnerabilities of children.
These include the right of children - as for other Internet users - to freely receive and  impart information (i.e.
They also include the right to privacy (UN Convention on the Rights of the Child, Art.
This is a particularly acute issue as regards technical measures to protect children online which  affect all Internet users.
Similarly, policy measures to protect children online should not unsettle  the framework conditions that have enabled the Internet to become an open global platform for  innovation, economic growth and social progress (OECD, 2008, p. 17).
Government policies which rely  on voluntary commitments by Internet intermediaries should ensure that appropriate safeguards  are in place.
Technology- neutral policies which apply across devices and access technologies as well as across comparable  applications  are  more  efficient  and  sustainable  in  a  dynamic  environment.
Where  possible,  interoperability of technologies for protecting children online, such as parental controls, should be  encouraged in order to facilitate adoption and foster innovation.
A prime example is awareness raising and education for children and their parents as well as other  targeted groups such as educators, social workers and other trainers which is assured by various  public and private stakeholders.
The US Online Safety and Technology Working Group maintains  that  more  inter-agency  co-ordination,  public  awareness  raising,  and  public/private  sector  co- operation are needed to improve the effectiveness of online safety education at the federal level  (OSTWG,  2010,  p. 6).
The  challenge  is  to  convey  coherent  information  so  as  to  avoid  contra- dictory advice and to link awareness raising effectively to other policy measures, such as guiding  parents on parental controls.
Evidence-based policy   There is a growing consensus among countries that a systematic approach to evidence-based  policy  making  is  needed  in  order  to  determine  policy  priorities  and  maximise  the  protection  afforded by national policy without unduly reducing the opportunities and benefits of the Internet  for  children.
However,  national  policies  are  rarely  formulated  to  create  a  virtuous  cycle  of  evidence-based policy  making based on the measurement of risks and impact assessment, with  performance evaluation leading to continuous improvement.
THE PROTECTION OF CHILDREN ONLINE © OECD   56       Measurement of risks   The formulation of a policy which corresponds adequately to the reality of threat scenarios for  children51 relies essentially on the effective measurement of risks (Livingstone and Haddon, 2009,  p.  22).
especially  European  countries  assisted  by  the  EU’s  Safer  Internet  Programme,  Australia,  Canada  and New  Zealand)  are  surveying  risks  for  children  and  young  people  online  more  systematically,  both  qualitatively  and  quantitatively.
Indicators  are  essential for developing evidence-based policies for the protection of children online, including  setting priorities.
Where appropriate, international co-operation would benefit from more consistent indicators  of  the  prevalence  of  risk.
This  would  facilitate  international  comparability  and  therefore  help  anticipate  trends  and  identify  best  practices  across  borders.
The  inclusion  of  the  protection  of  children  online  in  existing  OECD  model  surveys  is  a  possible  way  forward,  together  with  the  development of specific indicators that build on existing data collections (such as hotline reports,  statistics or regulators’ complaints).52   The development of a measurement toolkit that would provide policy makers with a list of  indicators and associated methodologies and definitions judged essential for developing policies  for the protection of children online could be a practical international initiative to foster evidence- based policies and support national efforts for the protection of children online.
Policy impact assessments   Impact assessment (IA) is a method of evidence-based policy making (OECD, 2002, p. 44;   2007b,  p. 5)  which  can  systematically  assess  the  problem  of  conflicting  policy  objectives  and  enhance the precision of policy measures.
Such guidelines would  detail the scope, content, accepted methodology and required evidence.
Although the requirement  to conduct such assessments places an upfront burden on public- and private-sector stakeholders,  it  is  an  acknowledged  means  of  enhancing  the  precision  of  policy  making.
While voluntary commitments by the private sector have become a significant pillar of many  countries’ efforts to protect children online, it would be good practice for self- and co-regulation  initiatives  to  include  independent  evaluations  as  a  mechanism  to  monitor  compliance  and  to  enhance the effectiveness, transparency and accountability of private-sector stakeholders.
THE PROTECTION OF CHILDREN ONLINE © OECD       International co-operation    57   There  is  a  common  understanding  across  countries  that  international  and  regional  co- operation is important in order to address the challenges of child protection in an inherently global  medium such as the Internet.
Intergovernmental organisations at international and regional level  (APEC, CoE, ITU, OECD, WSIS/IGF, etc.
), and in particular the European Union, have therefore  initiated  work  within  their  remit  (see  Table  2).
International  efforts  in  this  area  are  relatively  recent and thus relatively uncoordinated.
Ensuring international dialogue and consistency   When intergovernmental organisations are working in parallel, with different perspectives and  sometimes overlapping mandates, they should ensure that their work is not duplicative and that  their outcomes are  mutually reinforcing.
Fostering information exchange and dialogue between  international organisations that play a role in protecting children online is essential.
As they are at the domestic level, inclusiveness and co-ordination are essential to successful  international co-operation.
Finding ways to involve all relevant international stakeholders and to  co-ordinate  the  work  of  different  actors  in  international  organisations  active  in  this  field  is  a  challenge.
There is currently no established international platform dedicated to the protection of  children online that would serve these functions and reflect all international activities.
In order to close this gap, countries, intergovernmental organisations and international stake- holders  could  decide  to  meet  regularly  with  all  relevant  national  stakeholders  and international  bodies.
Such an event could provide a platform to foster consistency among initiatives planned by  international  organisations  and  to  facilitate  the  sharing  of  best  practices  and  experience  across  national stakeholders.
A good example at regional level is the Safer Internet  Forum, an annual  event at the EU level on safer Internet issues, which has become an important reference for the  dissemination of information on research, activities and policy efforts.
Cross-border sharing of information and resources and capacity building   The  sharing  of  experience  and  best  practices  at  the  policy  level  is  a  shared  objective.
International policy guidance, involving governments, business and civil society, is an important  yet underutilised means of conveying evidence-based lessons learned and best practices on a wide  array  of  topics,  such  as  programmes  and  resources  which  have  proven  effective  in  addressing  issues concerning a particular age category.
Another  key  area  for  international  co-operation  is  capacity  building,  whereby  advanced  countries  or  regions  assist  other  countries  in  the  development  of  their  national  policies,  taking  national  specificities  into  account.
Finally, collaboration at the international level and with various stakeholders can help ensure  commitment  and  greater  visibility  (e.g.
Safer  Internet  Day)  and  the  sharing  of  successful  educational  and  awareness-raising  campaigns  where  appropriate  (ACMA,  2009,  p.  95).
THE PROTECTION OF CHILDREN ONLINE © OECD   58       Laying the empirical foundations for international evidence-based policy   Comparable information about national situations and policies is needed to stimulate efforts  within  countries.
Countries  should  harmonise  their  statistical  frameworks  in  order  to  lay  the  empirical foundations for the international comparability of risk prevalence and policy efficiency.
An important starting point would be common definitions of risks and children’s age groups.
As  an input for the effective measurement of risks, this would not require countries to modify their  culture or policy approach to the protection of children online.
ITU  work  to  devise  a  Child  Online  Protection  Statistical  Framework  and  Indicators  (ITU,  2010b)  is  worth  noting.53  The  OECD  could  introduce  the  protection of children online in its work on the measurement of the information society and as a  specific module in its model surveys.
Finally, the creation of a repository of official and semi- official  statistics  or  the  regular  collection  and comparison  of  national  official  and  semi-official  statistics could be a further means of improving the accessibility of available empirical data.
International networks and strategic partnerships at operational level   Existing international networks of hotlines and awareness centres can foster co-operation and  co-ordination at the operational level and create synergies through the sharing of best practice,  information and resources.
Governments should promote and expand the networking of national  organisations,  including  law  enforcement,  dedicated  to  the  protection  of  children  online  and  strengthen effective international networks at policy and operational level.
While  countries  are  unlikely  to  align  their  definitions  of  what  is  illegal  or  inappropriate  content for children, a common baseline of the types of content commonly regarded as off limits  for  children  could  be  developed.
The  incompatibility  of  national  policies  on  illegal  and  child- inappropriate content does not prevent international efforts to collaborate in labelling and content  rating which can be tailored to national views and used as input for parental control technologies.
National  policies  could  benefit  from  effective  international  content  labelling  schemes  which  would provide additional information on the nature of content, such as the presence of violence.
Public-private  partnerships  involving  several  countries  can  develop  policy  responses  which  several countries might more easily be able to monitor and assess jointly than in isolation.
For  example,  two  self-regulatory  initiatives  involving  mobile  network operators and operators of social network sites in the EU have been concluded recently to  the  benefit  of  all  participating  countries.
Working  together  towards  common  standards  with  market  players  such  as  Internet  search  engines,  Internet  advertising  networks  and  other  intermediaries  who  have  proven  their  commitment  to  protect  children  online  could  produce  a  wider  regional  or  even  international  impact  on  the  enhancement  of  the  protection  of  children  online.
Whether  the  creation  of  suitable  content  for  children  is  left  to  the  market  and  private  initiatives  or  supported  by  governments,  a  common  understanding  of  what  is  positive  online  content for children among all stakeholders would help to introduce quality standards and could  be  used  to  encourage  self-assessments  of  websites  for  children.
It  would  facilitate  the  development  of  incentive-based  policies  to  stimulate  supply  and  demand.
Websites that are safe for children could be indexed and linked to create a network of  varied  online  content  for  children  (a  whitelist)  and  provide  a  useful  tool,  especially  for  small  language communities.
THE PROTECTION OF CHILDREN ONLINE © OECD            59   Annex I         Descriptive overview of policies to protect children online   Introduction .......................................................................................................... 60  Regional policy frameworks and national strategies ............................................ 60  Legal measures ..................................................................................................... 62  Self- and co-regulatory approaches ...................................................................... 68  Community and acceptable use policies ............................................................... 71  Technical measures .............................................................................................. 72  Awareness raising and educational measures ....................................................... 79  Positive content provision .................................................................................... 81  International co-operation .................................................................................... 82            THE PROTECTION OF CHILDREN ONLINE © OECD   60      Introduction   This  annex  is  a  descriptive  overview  of  policy  responses  to  address  these  risks,  including  measures taken or planned by governments, business and civil society at domestic, regional and  international levels.
It rather provides an overview of trends across governments and of major efforts  carried  out  by  business  and  civil  society,  highlighting  commonalities  and  differences  across  countries  with  respect  to  policy  measures  and  challenges.
Its  content  is  based  on  available  research  and  on  the  responses  to  the  APEC  Questionnaire  on  Children  Protection  Online  circulated in April 2009 to APEC and OECD members.54    It is structured to first describe regional policy frameworks and national strategies that have  been developed to protect children online in a co-ordinated manner.
It then provides an overview  of the various types of policy initiatives adopted or encouraged across countries: legal measures  and its effectiveness, self- and co-regulatory approaches, community and acceptable use policies,  technical measures, awareness raising and educational measures, positive content provision and  international co-operation.
Regional policy frameworks and national strategies   Regional policy frameworks   Both the Council of Europe and the EU have devised and developed policy frameworks to  protect children online.
The  Council  of  Europe  has  adopted  a  number  of  non-binding  instruments  with  the  aim  to  ensure a coherent level of protection for minors against harmful content and developing children’s  media literacy skills.
Member countries are called on to develop information literacy and training  strategies which effectively empower children and their educators.55 A subsequent Recommenda- tion to  member countries for specific  measures to protect children against harmful  content and  behaviour and to promote their active participation in the new information and communications  environment sets out guidelines on providing safe and secure spaces for children on the Internet,  the development of a pan-European trustmark and labelling systems, and skills and literacy for  children, parents and educators.56 As regards the content created by children on the Internet, the  Council  of  Europe declared  that  there  should  be  “no  lasting or  permanently  accessible  record”  detrimental to their dignity, security and privacy in their future lives.57   The EU introduced harmonized legislation pertaining to child protection online.
Most notably,  the 2007 Audiovisual Media Services Directive expands the protection of minors from inappro- priate content and commercial communication to on-demand audiovisual services delivered over  the Internet.58 For all online services, the 1998 and 2006 Recommendations on the protection of  minors  and  human  dignity  encourage  awareness  raising  and  media  literacy,  identification  of  quality content for children, as well as industry efforts in order to make the Internet a safer place  for children in member states.59    With  the  Safer  Internet  Programme  (SIP),  the  EU  assumes  a  regional  lead  in  stimulating  policy  making  and  implementation  as  well  as  co-operation  between  its  member  states.60  Since  1999,  the  European  Commission  promotes  various  initiatives  under  SIP  to  make  the  Internet  a  safer  place  for  children.
The  programme,  which  entered  in  its  third  phase  in  2009,  has  been  instrumental in funding pan-European networks and national initiatives in the EU and in setting  up  the  international  hotline  network  INHOPE  and  European  network  of  awareness  centers  INSAFE  (see  below,  international  co-operation).
Under  the  same  umbrella,  the  Safer  Internet   THE PROTECTION OF CHILDREN ONLINE © OECD    61        Forum is an annual conference where representatives from law enforcement authorities, industry,  child  welfare  organisations  and  civil  society  as  well  as  policy  makers  discuss  specific  topics  related to child safety online.
SIP 2009-2013  will allow for EUR 55 million to be invested in public awareness measures (48%), fight against  illegal content (34%), addressing illegal conduct online (10%) and establishing a knowledge base  (8%).61   National policy frameworks   Several OECD countries have devised national strategies (e.g.
Australia, Canada, and United  Kingdom)  and  developed  policy  frameworks  (e.g.
Japan)  which  address  child  protection  in  the  light of new challenges raised by the Internet, combine and co-ordinated measures and involve  various stakeholders.
One of the earlier strategies is the 2000 Canadian Cyberwise Strategy to Promote Safe, Wise  and Responsible Internet Use, which is not any longer actively pursued.
The strategy excluded the  adoption of new legislation and placed priorities on awareness, shared responsibilities according  to  the  roles  of  stakeholders,  effective  enforcement  mechanisms  and  consultation  between  the  public and the private sector and their counterparts in other countries.62   With  respect  to  inappropriate  content,  the  US  generally  supports  an  industry-led,  self- regulatory approach reinforced by enhanced consumer awareness and the widespread availability  of  consumer  empowerment  technology  whenever  possible.63  Therefore,  parental  controls  and  public-private  partnerships  that  emphasize  self-regulation  are  often  employed  in  strategies  to  protect  minors  from  online  dangers.
EUR 81.2  million) over four years was committed towards, among other things, cyber safety education and  awareness  raising  activities  (including  the  creation  of  education  resources  and  expansion  of  a  national outreach program under the ACMA’s comprehensive Cybersmart program), law enforce- ment and a content filtering scheme which will become mandatory for Internet Service Providers.
As  part  of  the  Cybersafety  Plan,  a  Consultative  Working  Group  on  Cybersafety,  a  Youth  Advisory Group and research will inform the government on cyber safety issues.
The  Bristish  government  accepted  the  recommendations  of  the  independent  report  “Safer  Children  in  a  Digital  World”66  (“Byron  Review”)  which  led  to  the  establishment  of  the  new  United Kingdom Council for Child Internet Safety (UKCCIS) – an organisation consisting of 150  stakeholders tasked with the development and implementation of a Child Internet Safety Strategy.
Its  first  strategy  was  published  in  the  end  of  2009  and  concentrates  on  creating  a  safer  online  environment  for  children,  empowering  parents,  carers  and  trainers  to  help  children  and  young  people stay safe online, and inspiring safe and responsible use and behaviour.67 The work will be  updated  by  evidence  and  progress  will  be  evaluated  through  research  together  with  an  expert  research panel; UKCCIS provides and updates certain industry guidance68 compliance with which  it will be reviewed.
Japan’s national policy approach has led to the adoption of the “Act on Development of an  Environment that Provides Safe and Secure Internet Use for Young People” in June 2008.
This  law promotes the furtherance of efforts to protect children from illegal and harmful information  on  the  Internet,  for  instance,  by  making  it  obligatory  for  mobile  phone  operators  to  provide  filtering services, and also makes provision for initiatives such as the promotion of improved ICT  literacy for citizens.69   THE PROTECTION OF CHILDREN ONLINE © OECD   62      Legal measures   Legal  measures  to  protect  children  online  vary  according  to  their  degree  of  specificity  with  respect to the Internet (i.e legislation that applies to all media including the Internet versus Internet- specific legislation) and with respect to the targeted population(s) (i.e.
legislation that aims to protect  all citizens, including minors versus legislation that specifically aims at protecting minors).
content-related risks, consumer  risks,  privacy  and  information  security  risks)  and  to  the  type  of  requirements  they  specify  (e.g.
content rating scheme, parental consent requirement, or mandatory filtering).
Some  countries,  such  as  Japan,  Korea  and  Turkey,  have  issued  new  and/or  comprehensive  legislation  addressing  specific  risks  children  often face  online  as  a  reaction  to  local  situations.70  These legislative  measures addressing threats for children are often included within broader laws  that  aim  at  regulating  the  Internet.
New legislation is also used to patch specific areas of concern such as the US law on misleading  domain names71 and the update of  the  French criminal code to  make  the distribution  of “happy  slapping” images and videos a criminal offence.72   Legal approaches to sexual exploitation and abuse of children on the Internet are not examined   in this annex but addressed in the study carried out by the Council of Europe.73    Legislation on content-related risks    Content laws and regulations exist in most of the countries surveyed and commonly there are  categories for illegal content and child inappropriate or unsuitable content.
Legislative measures against illegal or child inappropriate content can take the form of i) general  laws;  ii)  media  content  regulation,  applying  either  to  specific  media  services  or  across  all  media  platforms; and iii) specific legislative measures pertaining to the Internet.
Legislation  pertaining  to  illegal  content  is  often  general  laws,  applying  across  all  media  including  the  Internet,  such  as  for  example,  the  UK  Obscene  Publications  Acts  prohibiting  the  publication of indecent or obscene material without regard to the audience, medium or the format.
The regulation of child inappropriate content often has its origins in television regulation, which  some countries (gradually) expanded in order to capture television-like formats (linear) transmitted  over the Internet and certain on-demand services, with a few countries abolishing any distinction  between old and new media (i.e.
Australia,  Germany,  Korea  and  New Zealand) have adopted media content regulation based on age limits and access restrictions  and applying horizontally across all electronic information and communications platforms.75   Content passed on via individual data exchange (e.g.
e-mail attachment, mobile to mobile, file  transfers via instant messenger) is beyond the scope of such media regulation.76 This gap in the  legislative  responses  to  content-related  risks  for  children  appears  to  be  present  in  all  countries  which leaves a question mark as to whether this is justified in the light of the widespread use of  these  technologies  by  children.
Online  content  regulations  and  accompanying  measures  are  always  targeting  the  content  provider but also increasingly so are Internet intermediaries that give access to, host, transmit and  index content originated by third parties such as Internet host service providers, Internet access  providers or search engines.79 In particular, intermediaries are often the only entities capable of  enforcing  local  content  rules  against  illegal  content  when  the  content  originator  is  established  abroad.
Australia, Italy, Japan, Korea and Turkey), competent authorities  can request Internet host service providers under their jurisdiction, which are hosting prohibited   THE PROTECTION OF CHILDREN ONLINE © OECD   64       content pursuant to local standards, to take down online content.80 In many other countries, notice  and take down procedures operate under voluntary agreements adopted by Internet intermediaries  (see below self- and co-regulatory approaches).81 In addition, a few countries have embarked on  mandatory filtering schemes under which Internet service providers are required to block access  to specific illegal content which is hosted abroad (e.g.
Turkey, Italy with respect to child sexual  abuse images and illegal gambling Web sites and in Germany where a law requiring the filtering  of child sexual abuse images exists but is not implemented).
Notice and take down (NTD) policies require the Internet service provider which is hosting  prohibited content, and sometimes links to such material, to remove the content or the links  after notification.
Legislative  prohibitions  and  restrictions  of  online  content  are  generally  not  a  stand-alone  solution to child protection online but are often combined in various ways with access restrictions  through  technical  and  organisational  measures.
For  example,  technical  measures  to  prevent  minors from accessing child inappropriate content are sometimes required by law, such as filters,  age verification systems or identity verification mechanisms (see below technical measures).82 In  addition, some countries (e.g.
Korea and Spain) require operators and service providers to set up  organisational structures to assist online child protection efforts, such as by allocating designated  personnel and establishing information duties.83    Finally,  in  some  countries,  content  legislation  is  limited  as  a  consequence  of  constitutional  requirements vesting highest value in free speech rights.
In the US, for instance, several attempts to  introduce online content regulation with the aim  to protect minors were found unconstitutional.84  The US Children’s Internet Protection Act (CIPA) of 2000 therefore concentrates on schools and  libraries which in order to continue to receive a type of federal funding must certify that they have  an Internet safety policy and technology filtering Internet access and blocking pictures that are  obscene or harmful to minors.
In Canada, the Criminal Code provides for a judicial take-down  system of illegal content.85   Legislation on contact-related risks   There is a very diverse body of legislation pertaining to contact-related risks for children and  loopholes where acts committed using electronic communication and information systems challenge  countries’ legal systems.86 Where children are harmed by others, certain acts of online contact can  be punishable as a criminal offence.
The  implementation  of  similar  criminal  offences  is  planned  in  the  Netherlands  and  Sweden  in  the  course of implementing the Council of Europe Convention on the Protection of Children against  Sexual  Exploitation  and  Sexual  Abuse  of  2007.87  In  Japan,  the  use  of  Internet  dating  sites  to  arrange dates with minors is a criminal offence.88 In the United States the KIDS Act of 200889  requires  convicted  sex  offenders  to  provide  their  “internet  identifiers”  to  the  sex  offender  registries and this bill also establishes a system by which social networking Web sites can cross- check the list of their users against this database.90   Online  harassment  and  cyber-stalking,  depending  on  the  circumstances,  may  meet  the  definition  of  criminal  harassment,  for  example,  in  the  criminal  codes  of  Canada  or  the  United  Kingdom.
For example, legislation enacted in many US States introduces  rules against cyberbullying in the school environment and/or requires school authorities to adopt  prevention policies.92    In order to mitigate contact-related risks for children online, mandatory monitoring of chats  and bulletin boards has been introduced in some countries, for example in Sweden,93 and in Japan  on-site age verification is a legal requirement for online dating Web sites.94 However, countries  more often encourage voluntary commitments with respect to monitoring and moderation, rather  than  imposing  an  obligation  (see  section  below  on  Community  and  acceptable  use  policies).
Finally,  in  Korea,  the  implementation  of  an  identity  verification  system  is  a  legal  requirement  placed  on  Internet  Web  sites  of  a  certain  size  and  although  this  scheme  does  not  herald  child  online protection as an objective, it can help to prevent and where necessary to investigate online  contact-related risks for children.95   Legislation on online consumer risks for children   Three  strands  of  legislation  commonly  apply  to  online  consumer  risks  for  children,  i.e.
Specific  legislative measures against typical child consumer risks apply offline and/or online and are tailored  to  children’s  ability  to  recognise,  understand  and  critically  assess  commercial  communication,  services and offers.
Australia  maintains an interactive gambling  prohibition per se.96   With  respect  to  online  advertising  directed  at  minors,  two  contrasting  models  prevail  with  countries regulating certain aspects of online advertising to children on the one hand and countries’  reliance on industry self-regulatory schemes on the other hand.
The  EU  is  an  example  for  the  first  model,  where  harmonized  rules  for  audiovisual  media  services  provide  a  range  of  advertising  restrictions,  including  specifically  protecting  children.
Apart from the general ban of cigarettes and tobacco advertisements it is prohibited to promote  alcoholic beverages aiming specifically at minors.97 On the premise that commercial communica- tions in the relevant services should not cause physical or moral detriment to minors, practices  which  exploit,  for  instance,  minors’  inexperience  and  credulity  are  prohibited.
Audiovisual  commercial  communications  must  be  readily  recognisable  and  product  placement  in  children’s  programmes,  including  on-demand  audiovisual  content  available  on  the  Internet,  remains  pro- hibited.98   Scandinavian countries have the most elaborate rules on Internet marketing aimed at children  and  minors  residing  in  the  Nordic  markets.
All  marketing  online  has  to  comply  with  legal  standards which require, in particular, that marketing be recognizable by children and correspond  to its target group’s stage of development, that children must not be invited to make purchases or  agreements via the Internet and that “advergaming” is banned, as is the provision of prizes given  if children take part in online activities.99       THE PROTECTION OF CHILDREN ONLINE © OECD   66       Advertising for child inappropriate content to children is banned in Korea.100 The US CAN- SPAM Rules, including the Adult Labeling Rule, requires warning labels on commercial e-mail  containing  sexually  oriented  material  in  order  to  place  a  bumper  between  x-rated  e-mail  and  children.101   Legislation on privacy and information security related risks for children   Information  privacy  and  information  security  risks  for  children  are  with  a  few  exceptions  subject to general data protection rules and criminal law rendering some information security risks  a criminal offence.
In European countries, the collection and processing of personal data must be authorized by  law  or  informed  consent  and  has  to  conform  to  further  data  protection  principles.102  Parents'  informed  consent  is  required  until  the  child has  developed  the  capacity  to  fully  understand  the  extent of such determinations which leaves certain ambiguities with regards to the age until which  parents must give their informed consent on behalf of their children which may vary from child to  child and across scenarios.103 The joint working party of EU Data Protection Commissioners (so  called  Article  29  Working  Party)  acknowledges  the  participative  right  of  a  child  which  would  require him or her to be informed and consulted and even be part of a decision on the processing  of his or her personal information depending on their level of maturity, which is adding further  complexity to the legitimisation of the processing of children’s personal data.104     The  US  provides  an  example  of  a  very  targeted  legislative  response  with  the  Children’s  Online Privacy Protection Act (COPPA) and corresponding Rule.105 COPPA places obligations  on operators of Web sites directed at children under 13 or where personal information of children  under  13  is  knowingly  collected.106  In  order  to  determine  whether  a  Web  site  is  directed  at  children,  the  Federal  Trade  Commission  takes  into  account  a  range  of  criteria,  including  the  subject matter; the audio or visual content found on the site; the age of any models depicted on the  site;  the  language  used  on  the  site;  the  presence  of  advertising  on  the  site;  other  empirical  evidence  regarding  the  age  of  the  actual  or  intended  audience,  such  as  whether  the  site  uses  animated  characters  or  has  other  child-oriented  features.
COPPA  only  applies  to  a  given  general-audience  Web  site  which  is  not  directed  at  children  under  13  where  the  operator  is  knowingly  collecting  personal  information  from  these  children.
COPPA’s  objective  is  to  give  parents control over what information is collected from their children online by requiring parental  consent.
The same problem arises in Europe where parental consent for  the  collection  and  processing  of  children  data  is  required  although  no  easy-to-implement  and  reliable mechanism to establish such parental consent is available.
The overall effectiveness of data protection frameworks when applying to children’s personal   information ought to be questioned (see below Effectiveness of legal measures).
Information  security  risks  stemming  from  spyware  or  malware  are  cybercrimes  and  are  a  criminal offence in countries which have ratified the Council of Europe Cybercrime Convention.107  There is no specific legislation to mitigate information security risks for children.
THE PROTECTION OF CHILDREN ONLINE © OECD    67           Effectiveness of legal measures    Countries report unanimously that legal safeguards are under considerable strain for reasons   that are inherent to the Internet as a global and highly dynamic information space.
For example the video sharing platform YouTube reports  that every minute 20 hours of video is uploaded.108 Consequently, countries have embarked on  various strategies that help uphold local content regulation which involve Internet intermediaries.
In some countries Internet service providers are legally obliged to comply with state authorities’  take-down  notices  (e.g.
Increasingly, Internet intermediaries deploy technical filters which in very few cases is  a legal obligation to block access to specific types of illegal content online (e.g.
Italy, Turkey, and  proposed in Australia) but in the majority of cases on the basis of voluntary commitments by the  industry.
The  main  challenge  for  the  legal  protection  of  minors’  personal  data  lies  in  the  effective  implementation and enforcement of existing rules given the ubiquity of online activities involving  children’s personal data today.
Both legal approaches practiced, i.e.
The role and limits of the consent requirement in privacy protection has been discussed elsewhere  in  OECD109  and  concerns  persist  in  relation  to  the  requirement  of  parental  consent.
The  requirement of parental consent seems to be difficult to implement since so far there are no easy  mechanisms for gathering verifiable parental consent.110 In Canada the Children’s Online Privacy  Working Group has published a discussion paper presenting various regulatory options to enhance  children's online privacy which nevertheless rely on varying consent requirement schemes.111   Websites  targeting  child  audiences  must  make  a  default  assumption  about  their  users  and  make the collection of children’s personal data dependent on obtaining parental consent.
Parental  consent  requirement  would  not  be  effective  if  children  lie  about  their  true  age  either  with  or  without the approval of their parents.
Conversely, general online services are used by adults and  children, however, the age of Internet users is notoriously difficult to assess.
Therefore, the protection of children online is a prolific area of self- and  co-regulatory initiatives which can take various forms and are sometimes referred to as codes of  conduct, industry guidelines and best practices.
Countries deploy various strategies to encourage self-and co-regulation such as by i) making  explicit  reference  to  these  mechanisms  in  legislations;  ii)  giving  a  mandate  to  regulatory  authorities  to  negotiate  with  stakeholders  voluntary  commitments;  iii)  creating  platforms  for  stakeholders to convene; and iv) stirring problematic areas by threatening to resort to “command  and  control”  style  regulation.
The  Children’s  Online  Privacy  Protection  Act  (COPPA)  in  the  United States, for instance contains a statutory safe harbour provision -- if a website participates  in  a  safe  harbour  programme,  it  is  afforded  a  presumption  of  being  COPPA  compliant  if  the  website  is  in  compliance  with  the  requirements  of  the  authorised  safe  harbor.113  Public-private  partnerships  where  voluntary  agreements  have  been  brokered  with  strong  public  sector  involvement  (detailed  below)  led  to  recent  self-regulatory  initiatives  involving  mobile  network  operators and operators of social network sites in the European Union and the United States.114 It  appears  that  in  particular  public-private  partnerships  are  successful  in  delivering  effective  voluntary commitments by industry with the aim to protect children against harm online.
Existing models can be classified according to whether i) it is co-regulation or self-regulation;  ii) it is an industry led commitment or it involves all relevant stakeholders; iii) it applies to one  country or represents a regional agreement; and iv) it is a single group’s standard or collective  agreement.
In  online  services  and  new  media,  self-  and  co-regulation  is  widely  deployed  in  order  to  mitigate risks for children on the  Internet and is often  woven into national policy  frameworks.
When assessing self- and co-regulatory schemes, the quality, impact and the effectiveness can  vary significantly depending on a number of general factors such as i) how inclusive are the rules  that have been developed; ii) if transparency and accountability is achieved; and iii) whether the  rules  are  binding;  iv)  enforceable;  and  v)  subject  to  evaluations.
For  example,  the  EU  Safer  Internet Programme supports industry self-regulation regimes where they are broadly accepted by  stakeholders and provide for effective enforcement.115   THE PROTECTION OF CHILDREN ONLINE © OECD    69        The examples below provide a brief overview of the major self- and co-regulatory initiatives  with respect to mobile communications, social network sites, online games, online advertising and  illegal and child inappropriate content.116   Mobile communications   Adopted in 2007, the European Framework for Safer Mobile Use by Younger Teenagers and  Children  describes  principles  and  measures  to  be  implemented  at  the  national  level,  including  access  control  for  adult  content;  awareness-raising  campaigns  for  parents  and  children;  the  classification  of  commercial  content  according  to  national  standards  of  decency  and  appropriateness;  and  the  fight  against  illegal  content  on  mobiles.117  The  implementation  of  the  framework,  into  national  codes  of  conduct  has  been  independently  monitored  showing  that  in  2009,  two  years  after  its  inception,  22  member  states  have  codes  that  show  a  high  level  of  alignment  with  the  framework,  and  mobile  operators  self-report  a  very  high  or  high  level  of  compliance.118   In the United Kingdom, all of the mobile networks operate an adult bar which is turned on by  default to block access to adult content offered over the mobile phone network.
In order to have  the adult bar removed it is necessary to go through an age verification process with the network  operator.
Similar measures are taken by mobile telephony networks in the US and other countries.
It is however also possible to access child inappropriate content available on the Internet with a  mobile  phone  and  the  practice  varies  as  to  whether  mobile  network  operators  provide  network  level filters and where available also whether filters are turned on by default for all customers or  upon request.
The Australian Mobile Premium Services Code covers inter alia advertising mobile premium  services  to  minors.119  The  Code  forbids  advertisement  for  mobile  premium  services  which  is  specifically targeted at persons below the age of 15 years and where the advertisement of a mobile  premium  services  is  likely  to  attract  minors  to  use  that mobile  premium  service  it  requires  the  warning  “If  you  are  under 18  you  must  ask  the  account  holder before using  this service”.
The  Code  also  contains  provisions  on  mobile  commerce  by  requiring  that  customers  provide  two  confirmations of their purchase.120 The confirmations provided by the content supplier must also  clearly include the name of the subscription service, any sign up cost, the basis for calculating the  charge, instructing the customer how to subscribe and include details of the help line.
Social network sites   In  the  United  States,  public-private  partnerships  that  emphasize  self-regulation  are  often  employed  in  strategies  to  protect  minors  from  online  dangers.
For  example,  the  Attorneys  General Multi-State Working Group on Social Networking and two of the largest social network  sites  issued  joint  statements  committing  these  social  network  sites  to  better  protect  children  through  the  application  of  key  principles.121  Based  on  recommendations  from  the  Attorneys  General and online safety advocates, the services developed more nuanced privacy settings and  information practices about online risks for children.
Major  social  networks  operating  in  the  EU  adopted  Safer  Social  Networking  Principles123  developed in consultation with the European Commission, NGOs and researchers and submitted  self-declarations in which they provide details about how their services relate to the principles.124  The principles aim to limit the potential risks of social networking sites for under 18s.125    Examples of concrete measures taken are the introduction of reporting mechanisms such as an  easy-to-use  and  accessible  “report  abuse”  buttons,  the  improvement  of  default  privacy  settings  and controls for profiles of users under 18, and finally preventing users below the age the service   THE PROTECTION OF CHILDREN ONLINE © OECD   70       is targeting, from registering.126 A first independent assessment of the implementation of the Safer  Social Networking Principles has been conducted where the compliance of social network sites  with  their  respective  self-declaration  has  been  assessed.127  The  compliance  varies  by  provider  with two social network sites excelling, but the findings of the majority is good or fair compliance  leaving scope for improvement.
Online games   The Pan-European Game Information (PEGI) Online Safety Code of 2007 is another example  for  a  European-wide  self-regulation  scheme  which  aims  at  providing  a  minimum  level  of  protection of young people in the online gaming environment.128 Signatories to the code commit  themselves to adhere to a content rating system, to remove inappropriate material from their site  and  to  set  up  community  policies  and  reporting  mechanisms  that  help  to  ensure  appropriate  behavior among users.
Further, the code includes provisions regarding advertising which promote  separation and fairness principles and in particular that all advertising must correspond to the age  of the audience the online gaming website is targeted at.
Online advertising   Self-regulation produced a great number of industry standards to protect children from certain  techniques  and  children’s  personal  data  (e.g.
International  Chamber  of  online  marketing  Commerce’s  (ICC)  Advertising  and  Marketing  Communication  Practice,  the  International  Advertising Bureau UK and US codes, the Federation of European Direct and Interactive Marketing  (FEDMA)  code  and  many  more).129  These  instruments  either  apply  to  all  marketing  practices  or  only  to  online  marketing  and  they  cover  marketing  to  adults  and  children  or  specifically  to  children.130 Schemes vary significantly with respect to the age up to which children are protected  (e.g.
These  instruments  can  apply to audiovisual media and on-demand services or to all Internet services under its scope.132   The contribution of self- and co-regulation to the protection against child-specific consumer  risks online is beyond question.
The landscape of voluntary codes, however, is fragmented along  the boundaries of industries, national borders and through membership of the respective umbrella  organisation  and,  despite  many  parallels  and  overlaps,  gaps  in  protection  remain.
New  online  marketing techniques such as embedded advertising, extensively branded websites and behavioral  targeting  on  websites  directed  to  children,  are  not  yet  sufficiently  taken  up  under  voluntary  schemes.133  The  Article  29  Working  Party  is  of  the  view  that  advertising  network  providers  “should  not  offer  interest  categories  intended  to  serve  behavioural  advertising  or  influence  children” because of the difficulties to obtain consent in accordance with the laws and also taking  into account the vulnerability of children.134    Illegal and child inappropriate content   The  co-regulatory  model  where  legislation  is  supplemented  by  voluntary  agreement  is  favoured in a number of countries especially to address illegal and child inappropriate content.135  Germany champions an approach called ‘regulated self-regulation’ where government recognized  self-regulatory  bodies  implement  content-related  child  protection  standards.136  The  Australian  Content Services Code developed by the Internet Industry Association (IIA) operates under the  authority  of  Australian  Communications  and  Media  Authority  (ACMA),  which  can  ultimately  enforce adherence to it.
Positive content rating is used in Mexico  where AMIPCI, the Mexican Internet Association, issues safety seals to websites without harmful  content.
Examples  include  the  universally  available  ICRA  label  operated  by  the  Family  Online  Security  Initiative  (FOSI)  and  the  RTA  (Restricted  To  Adults)  label  operated  by  the  Association  of  Sites  Advocating  Child  Protection  (ASACP).
Germany recently amended its media regulation on the protection of children in order  to  have  content  providers  voluntarily  label  their  websites  according  to  a  classification  scheme  which would be capable of being interpreted by parental control software.137    Internet intermediaries such as Internet service providers and telecommunications operators  which can technically remove problematic content have adopted self- and co-regulation codes and  practices that help protect children online.
In the Netherlands, for example, the Dutch government  and  leading  host  service  providers  agreed  on  a  notice  to  take  down  code  which  sets  forth  guidelines to respond to unlawful and also undesirable content on the Internet and the way private  parties erase this content.138 German search engine operators developed a code of conduct with  the aim of improving the protection of children and youths when using search engines where, for  example, they commit to filtering indexed content from the search results.139    Community and acceptable use policies   Private policies play an increasingly important role to set rules for responsible and acceptable  use  of  online  services  and  their  adoption  is  promoted  in  some  countries  in  various  ways.140  Operators of IT networks, online platforms, mobile and Internet services can stipulate terms of  use  or  encourage  user  community  standards  to  contribute  to  the  mitigation  of  online  risks  for  children.
Examples can be found in social networks, gaming, or photo and video sharing websites  where they define inappropriate contents or behaviours and establish graduate sanctions against  users who breach these rules.141    There are various scenarios.
For example i) public institutions such as schools and libraries  and other Internet access points implement their own policies; ii) self- and co-regulation agree- ments include the commitment to put community or acceptable use policies in place; iii) providers  of online services and portals take-up community or acceptable use policies; and iv) online service  contracts include terms of use.
For example in many US states, cyberbullying laws require schools  to  adopt  anti-harassment  and  anti-bullying  policies  or  require  school  districts  to  devise  model  policies.142 Similar measures can be taken for other public access points such as public libraries  and also Internet cafes, which in order to be effective also require monitoring of compliance and  reporting mechanisms.
One  example  is  the  PEGI  Online  Safety  Code  that  requires  community  standards  prohibiting illegal or offensive online behaviour and uploading of illegal or harmful content.143   Community  and  acceptable  use  policies  are  often  maintained  by  social  networks  and  other  online  communities.
In  Japan  for  example,  industry groups have developed model contractual provisions to prohibit a number of problematic  issues, including the dissemination of information relating to suicide.144 When receiving notices  of  child  inappropriate  content,  the  Japanese  helpline  informs  the  Internet  host  service  provider  which can then enforce contractual obligations vis-à-vis its customers and take down the contested  material.145   An additional tier for online safety in social networking sites and online communities, is the  voluntary  moderation  by  operators  of  interactive  services  for  children.
The  United  Kingdom  Home Office published Good Practice Guidance for the Moderation of Interactive Services for  Children (2005) and for the Providers of Social Networking and Other User Interactive Services  (2008).146  The  ‘Byron  Review’  recommended  developing  these  guidelines  into  an  independent  voluntary  code  of  practice  for  the  moderation  of  user-generated  content,  however,  the  United  Kingdom Council for Child Internet Safety (UKCCIS) First Child Internet Safety Strategy issued  in 2009 committed to update this guidance and for its members to adhere to it.147   Technical measures    Overview of technologies   Technical measures are an important element in child online protection policies.
Technologies  can  be  used  to  i)  keep  certain  risks  away  from  children  (e.g.
filtering  technologies);  ii)  keep  children out or, the reverse, admit only children to specific websites (e.g.
age or identity verifica- tion systems); and iii) create child safe zones on the Internet (e.g.
This  section  will  discuss  filtering  technologies  and  other  technologies  such  as  children’s  devices, age verification systems, content rating technologies and report abuse mechanisms.
The  following overview lists technical measures in the first column that help protect children online  and illustrates their operationability at the various stages of the value chain of online services.
Filtering technologies   Filtering technologies encompass a whole range of tools that can block users from accessing  content.
They  operate  at  various  levels  such  as  on  the  user's  personal  equipment,  at  Internet  Service Provider (ISP) level or mobile operator level, and at search engine level.
Methods   Filtering is based on whitelists, which block access to all Web content except when listed as  suitable for the user, or on blacklists, which enable access to all Web content except when listed  as inappropriate for the user.
Even though a lot of harmless  content is not accessible, it is generally assumed that a safe environment is more important for  young children than access to a large amount of information.
Even though they might let through  some undesirable content, filters based on blacklists are commonly deemed better for teenagers as  they allow wider exploration of the Internet, thus responding to information and communications  needs which increase with age.
Overview of technical measures   Similar to whitelists, child safe zones, sometimes called “walled gardens”, are Internet portals  through  which  children  can  access  a  range  of  suitable  websites  and  online  services  but  cannot  navigate  away,148  thus  significantly  restricting  access  or  functionality.149  The  German  service  “fragFINN”150 offers a ‘smaller version’ of the Internet where children aged 8 to 12 can navigate  without facing potential threats or the disadvantages of current filter systems.
An easy-to-install  technical solution in the form of an Internet browser add-on ensures that children can only access  websites included in a whitelist put together by a team of editorially independent media pedagogy  experts.
Other examples include video applications designed specifically for children, such as the  Kideo  Player  from  a  US  company  and  Totlol.com  designed  by  an  independent  Canadian  Web  developer.151   Blacklists  can  be  maintained  based  on  some  sort  of  pre-classification  or  generated   dynamically through dynamic analysis techniques applied in real time.
It can be human-based or computer-based and may be performed by vendors of  content control software or by dedicated third parties152 or by the content producers themselves.153  Blacklists of legally prohibited content such as child abuse images are commonly maintained by  law  enforcement  authorities  (e.g.
Internet  Watch  Foundation  (IWF) in the United Kingdom).
Conversely,   THE PROTECTION OF CHILDREN ONLINE © OECD   74       transparency of blacklists can also be conceived as a measure to enhance public confidence in the  legitimacy of ISP-level filtering obligations and accountability of the governments.154   With dynamic analysis techniques, software applications determine in real-time, i.e.
They are potentially more  effective  in  blocking  newly  published  undesired  content  but  the  technology  has  shortcomings,  such as allegedly throttling Internet connectivity speed and the potential to overblock, i.e.
block  uncontested content.155   In  addition  to  blocking  Web  content,  filtering  technologies  can  also  help  address  some  contact-related risks such as child grooming or harassment, with applications that monitor chat or  instant messaging for certain words or through text analysis tools.
Text analysis technologies are  more  sophisticated  than  filters  for  terms  and  character  strings,  since  they  are  designed  to  automatically detect predatory, harassing, or otherwise inappropriate conversations on the Internet  by using statistic-sampling, i.e.
a method where statistically valid samples of representative text is  collected and against which communications will be probed and assessed.156  The technologies are  still early in their development and though promising in many respects, it is unclear whether they  can  handle  the  complexity  of  multilingual,  colloquially  and  conversationally  diverse  online  communication.157   Some information security risks such as phishing scams or malicious spam messages can be  addressed by filtering tools.
Internet browsers’  preferences and security settings can also be adjusted to block pop-up and cookies, which would be  a way to address associated threats.
Levels of deployment    Filters  can  be  deployed  at  various  levels  throughout  the  information  technology  and  communications infrastructure, i.e.
at i) network level (e.g.
Internet Service Provider network or  local area networks); ii) server-level (e.g.
social network site or search engine); and iii) end-user  terminal level (e.g.
Network-level filtering is deemed more effective in blocking access to pre-defined content for  all users of a network.
It can happen at the Internet service or access provider’s network level or at  the user's local area network level (e.g.
Filters  deployed  at  the  Internet  service  providers’  networks  are  often  used  to  filter  all  Internet  traffic with the aim to block foremost illegal content according to local laws.
Some Internet access  providers offer network-based parental controls which can be activated on request of the customer  to filter harmful content, block certain applications, protocols and services.
Parental control for  mobile  Internet  is  usually  network-based,  which  means  that  it  can  be  either  activated  auto- matically when the mobile network operator is aware that the user is a minor or upon parents’  request.158  In  local  networks  and  closed  user  groups,  such  as  a  school  or  a  library  information  technology system, filters operate on behalf of all connected users and enforce technical policies  where certain online content and Internet services are restricted.
Content  filtering  is  also  practiced  at  server  level.
Another server-level type of filtering, more of a  whitelist approach, are child versions of a portal that can be developed by service providers.
Firefox) so that a password is required before a user can  access  the  Internet.
Parents  can  then  establish  a  user  account  for  their  child  that  allows  them  access only to a set of prescreened, child-friendly websites.
Effectiveness   Filter technology is a very efficient means in blocking blacklisted websites and has developed  significantly in the past years.160 Filtering tools are suitable against content-related risks and less  effective in reducing other online risks for children.
For instance, filtering or blocking tools on  the home computer may be circumvented by gaining control of the administrator’s account (user  name and password), or by using a “boot disk”.
Other circumvention methods known to young  users include Web anonymizers, translation software, search engine caching, etc.163   For  filters,  it  is  particularly  challenging  to  address  dynamic  content  posted  on  peer-to-peer  applications and Web 2.0 platforms.164 Currently, risks for children are addressed by site-specific  measures,  and  in  some  cases  by  content  rating  by  the  users  community.165  Peer-rating  and  community-based filtering where dynamic content is also dynamically scored is predicted as vast  potential  because  it  can  react  quickly  to  new  problematic  content  by  involving  users  them- selves.166 Such an example is the new “POWDER” mechanism of ICRA labeling system which  directly involve end-users and enables swift classification through crowd-sourcing.
Word filters and text analysis tools have shortcomings which hamper their effectiveness and  at present the technologies still produce too many false negatives and false positives in order to be  reliable,167  but  it  can  nevertheless  be  put  to  good  use  as  a  complement  to  a  broader  security  scheme, for example for prevention strategies on social communities.
Parental control software   Parental control software is the most widely used technological solution for enhancing child  safety  online.
Based  essentially  on  filtering  technology,  it  includes  i)  services  that  require  an  installation or pre-installation on the end-user's hardware; ii) service operated only on the server  or  network  side;  iii)  a  mix  of  both.
End-user level filtering software provides the maximum degree of control to parents and some  network-level filtering solutions are configurable, for example by selecting categories of contents  that the software should block.
Parental control software tools may perform not only content filtering, but also control of the  use of certain applications (e.g.
webcams, instant messengers), provide detailed reports on children’s  online usage or enable time restrictions of Internet usage.
Thus, parental control software may target  a  wider  scope  of  risks,  beyond  content-related  risks,  such  as  communication  risks  and  over- consumption.
THE PROTECTION OF CHILDREN ONLINE © OECD   76       Recent  US  research  emphasises  that  the  market  offers  a  wide  selection  of  parental  control  solutions.168  Off-the-shelf  software  tools  for  parental  control  are  either  directly  purchased  by  parents or are provided by Internet Service Providers, with or without additional cost for the user.
Commentators  point  out  that  one  of  the  most  significant  advantages  of  parental  control  solutions  is  that  they  are  able  to  operate  independently  and  without  permission  from  content  producers  or  network  service  providers.169    Following  this  opinion,  parental  control  software  empowers  families  to  decide  what  content  to  allow,  when  to  allow  access  or  what  types  of  activities to enable on the basis of their values, children’s age and needs.
According to surveys  made in the US, parental control tools are deemed “effective” and the users of those tools “are  generally pleased with their performance”.170 Potential disadvantages of parental control solutions  discussed  are  their  impact  on  the  children’s  rights  to  privacy  and  to  freely  seek  and  receive  information as part of the right to freedom of expression.
Other technologies to protect children   In  many  countries  industry  offers  children  devices,  especially  mobile  telephony  handsets  configured for children, which either have limited functionality from the outset or where certain  functions  such  as  Internet  access  and  bluetooth  are  disabled.
In  Japan,  each  mobile  phone  company is selling children devices, which cannot access Internet websites as a default setting.
US  mobile  phone  operators  allow  for  parental  controls,  including  the  abilities  to  turn  off  Internet  access,  to  filter  Web  content  and  to  block  unwanted  text  messages  or  phone  calls,  a  solution that also accommodates different parental needs and children's ages.171 It is possible to  create lists of blocked phone numbers to prevent unwanted calls and text messages from being  sent  or  received.
Also,  to  designate  trusted  numbers  that  can  always  communicate  with  your  family member, regardless of other usage controls that are set.172 On the part of parents, there is a  demand  for  mobile  phones  which  provides  an  emergency  call  function  and  can  be  located  for  instance via the Internet.
In Australia all mobile carriage service providers have implemented access control systems  for  mobile  phones  which  restricts  access  to  age  inappropriate  content  (i.e.
content  classified  MA15+ and R18+) to premium SMS and MMS numbers and in addition must be able to offer  their  customers  the  option  of  barring  all  premium  SMS  and  MMS  services  in  order  to  allow  parents to prevent their children from using up their prepaid mobile phone credits  or incurring  large bills for a post paid mobile phone for mobile premium services.173   Age  verification  system  in  the  online  environment  is  used  to  restrict  access  to  classified  content or as an authentication mechanism.
In Korea, the Identity Verification System uses the Resident Registration  Number to verify the age but a recent technical framework implemented by the government, the i- Pin system, prevents the overexposure of this sensitive number (OECD, 2010a).
Age verification in social networking sites is a challenge which some social networks try to  address using peer verification.
It was given up in 2008 due to various problems in particular its  reliance  on  the  Belgian  electronic  national  identity  card  and  also  simply  because  it  was  not  popular with the children.176    Technology-driven  content  rating  and  labelling  schemes  are  used  to  enable  and  to  some  extent  automate  classification  schemes,  which  in  turn  provide  the  essential  input  for  filtering  software’s  interpretation  of  what  is  to  be  blocked.177  For  example  the  ICRA  labels  use  the  Resource Description Framework (RDF)178 where the content is tagged and can be read out by  common parental control systems.
regulators,  governmental  departments,  industry  associations,  NGOs,  groups  of  interests,); iii) rating may be carried out at user community level (e.g.
Industry self-labelling such as the RTA-label potentially operates internationally.
Pan-European  rating  of  computer  games  takes  place  through  the  Pan  European  Game  Information  (PEGI)  system.
The  project  has  developed  a  technological  platform  for  delivery  and  authentication  of  machine- readable content quality labels.181 The labels are interoperable and do not necessarily require a  complete harmonisation of the rating and classification schemes used by labelling authorities in  the EU.
The platform allows end users to agree or disagree with the labels and also enables end  users to create labels themselves.182   A relatively simple measure to enhance online safety which has been deployed in a number of  countries is the “report abuse” mechanisms (also known as “panic button”) on instant messaging  applications  and  social  networking  sites.183  Certain  social  network  sites  for  example  have  implemented  a  technology-driven  mechanism  whereby  users  can  report  abuse  to  the  site’s  operators  dedicated  staff,  and  young  users  can  complain  about  content  or  conduct  encountered  online.184   Such  buttons  are  sometimes  linked  to  “Internet  hotlines”  where  users  can  report  illegal  content.
Internet hotlines have a very specific  remit which is to receive information abuse child sexual abuse images and combat such illegal  material.
Another example is Hector’s World Safety button from New Zealand which helps the  child cover whatever is on the screen and urges them to get an adult to help.185      THE PROTECTION OF CHILDREN ONLINE © OECD   78       Government policies on technical measures    Governments' approaches with respect to technical measures to protect children online vary.
This  section  describes  countries’  strategies  to  promote  the  adoption  of  voluntary  technical  controls, legal obligations requiring the implementation of certain technology for the protection of  children online, and public funding of research and development in such technologies.
Promotion of voluntary technical controls    In  some  countries,  ISP-level  filtering  in  most  instances  with  the  objective  to  block  child  sexual  abuse  images  is  implemented  on  the  basis  of  self-  and  co-regulatory  agreements  (e.g.
In New Zealand  the  Department  of  Internal  Affairs  (DIA)  is  offering  Internet  Service  Providers,  for  use  on  a  voluntary basis, a Digital Child Exploitation Filtering System that blocks websites identified as  hosting child sexual abuse images.186   The Japanese “Action plan for encouraging dissemination of filtering service” promotes the  improvement of filtering service availability.187 In addition, Japanese mobile operators undertook  self-regulatory efforts following up on the Minister’s request to introduce blacklist filtering and  offer more customizable settings for minors.188   The  United  Kingdom  Child  Safety  Online  Kitemark  scheme  is  an  effort  to  build  trust  in  filtering tools and other technical solutions for home use.189 Under this scheme, filtering products  on the market are independently tested by the British Standards Institution to assess whether they  provide simple and effective means of support to parents.
In  2008  Spain  introduced  a  legal  obligation  for  Internet  service  providers  to  inform  users  about i) both technical means and potential security risks; ii) available filtering tools and access  management  software;  and  iii)  about  their  responsibility  when  using  the  Internet  for  illegal  purposes.190   Mandating pre-installed filtering services   Other  countries  oblige  service  providers  not  only  to  provide  information,  but  to  directly  provide filtering services.
Computer  manufacturers  are  required  to  make  filtering  services available in advance.192   Mandatory filtering schemes   Countries  which  require  mandatory  network-based  filtering  from  ISPs  include  Korea,  Italy   and Turkey, where illegal content is filtered according to the national laws.
5651 (2007) regulates the responsibility and the obligations of content,  hosting and access providers, including operators of public Internet access points.
For instance,  cyber  cafes  should  use  filtering  products  approved  by  the  Internet  Regulations  Department,  an  agency which also maintains a blacklist of sites known to host illegal and harmful content.193   Australia announced in late 2009 a plan to amend the Broadcasting Services Act to require  ISPs to filter content rated Refused Classification (RC) and hosted in foreign jurisdictions.194 The  decision followed a live pilot of ISP-level filtering, conducted by the Australian Government and  with  participation  of  several  ISPs,  which  showed  that  “ISP  level-filtering  of  a  defined  list  of  URLs can be delivered with 100% accuracy” (i.e.
blacklist) and that this is done “with negligible  impact on Internet speed”.195    THE PROTECTION OF CHILDREN ONLINE © OECD    79        Public funding of research   Public funds can support research on technologies to protect children online, especially where  market  based  research  and  development  is  difficult  to  achieve,  for  example  in  the  case  of  interoperability across technologies.
The EU’s Safer Internet Programme has been funding research  into technologies, such as earlier mentioned Quatro+ and Safer Chat.196 The Japanese Ministry of  Internal Affairs and Communication supports private sector efforts to develop technology to enable  the semantic analysis of messages containing illegal and harmful information.197 Also the Australian  government  announced  the  set-up  of  a  grants  programme  to  encourage  ISPs  to  offer  additional  filtering services on a commercial and optional basis to its end users.198   Conclusion   A  whole  toolkit  of  technical  measures  supporting  the  protection  of  children  online  is  available.
Yet there is no single technology which would resolve completely the problematic of  content- and conduct-related risks for children and without unintended side effects.
Most national  policies include technologies in their set of measures to protect children online.
The main policy  making challenge is to balance the role of technologies to protect children and their impact on the  risks and opportunities for children and on the wider user community, in particular where these  measures restrict communications freedoms such as the right to freely receive and impart informa- tion and the right to privacy of communications.
Moreover, most countries promote the adoption of voluntary filtering schemes at  the ISP-level and/or in the form of parental controls installed or activated by the users, to filter  child inappropriate content and some contact-risks.
The utility and scope of application of some  technologies such as technology driven content-rating and age verification systems would benefit  from  interoperability  to  help  unleash  the  functions  from  a  given  platform  and  operate  across  various infrastructures and devices.
Awareness raising and educational measures   Many awareness raising and educational initiatives to protect children online are implemented  in most countries with the aim to empower children, parents and other relevant groups.
They  include,  for  example,  outreach  programmes,  websites,  online games and other interactive tools, brochures, press, radio and TV ads.
Types of awareness raising campaigns   Topical campaigns are launched with the aim to inform and educate about an issue of public  concern.
For  example,  the  Netherlands  ran  a  cybersecurity  campaign  throughout  the  summer  2009.
In the United  Kingdom, a large scale campaign around the slogan “Zip it, Block it, Flag it” encourages children in  addition to cybersafety strategies to report any inappropriate behaviour to somebody they trust.199   Awareness material is tailored to suit specific audiences and communication strategies have to  take into account children’s development.
For example, the ITU Child Online Protection (COP)  Initiative includes guidelines for i) children; ii) parents, guardians and educators; iii) industry; and  iv) policy makers.200 Many awareness raising websites provide information for different types of   THE PROTECTION OF CHILDREN ONLINE © OECD   80       visitors.
For example, the Family Safety tool kit produced by the European awareness network (INSAFE)  has been translated to Arabic and adapted to the local context.203 Another good practice example  from  the  private  sector  is  Microsoft’s  “Protect”  sites  (www.microsoft.com/protect/default.aspx)  which have been localised into 35 languages, and the content of which is made freely available for  syndication.
Offline  activities  such  as  workshops,  events  and  presentations  are  as  important  as  online  awareness raising for reaching out to the target groups.
One major event is the Safer Internet Day,  organised  each  year  in  February  in  a  growing  number  of  countries  with  the  aim  to  raise  public  awareness  about  the  issue  of  children’s  safe  Internet  use.
INSAFE,  the  European  network  of  awareness centres, organises and co-ordinates local events, and participation is open to organisations  from  third  countries.
The  motto  for  2010  was  “Think  B4  U  post!”,  highlighting  the  problematic  aspects of children uploading information with regards to information privacy and security.204 Other  dissemination  strategies  involve  training  multipliers.
In  Egypt,  youth  ambassadors  from  youth  Internet safety focus group (“net-aman”) relay Internet ethics and etiquette to peers.
Various organisations contribute to awareness raising and educational initiatives, including i)  public bodies; ii) not-for-profits organisations such as child welfare organisations and consumer  associations; iii) businesses205 and iv) public-private partnerships.
Some countries support NGOs manage- ment of multi-stakeholder input into policy and online safety education development, as with the  New Zealand Government’s relationship with non-profit NetSafe, dating back to 1998.
Industry  accounts  for  many  awareness  raising  websites  and  initiatives,  in  particular  in  the  context  of  a  specific service, but rarely caters for initiatives which train critical abilities of children to engage  more generally with Internet content.
The  funding  of  awareness  campaigns  depends  on  the  type  of  implementing  body:  public  bodies receive public funding, not-for-profits attract funding through grants or charity, and for- profit companies  may invest under the umbrella of corporate social responsibility.
EU member  states  tend  to  be  structurally  similar  due  to  conditions  accompanying  funding  from  the  Safer  Internet Programme (SIP).
Industry  has  an  important  role  to  educate  consumers  about  available  technical  solutions  to  exercise parental control in relation to the offered services.
In order to make this information more  accessible for parents, US leading wireless carriers agreed to present relevant information under  the  common  search  term  “parental  controls”.206As  part  of  their  corporate  social  responsibility,  companies contribute to educational measures and support awareness raising efforts.
”Safe  Internet”,  “Safe  phone”)  to  communications  service  providers which comply with a set of conditions intended to protect children and young users.207   THE PROTECTION OF CHILDREN ONLINE © OECD        Internet literacy education    81   An increasing number of countries include Internet literacy in school curricula and organise  trainings for teachers and educators.
According to a recent European survey, Internet safety has  been recently included in the majority of European countries.208 Where Internet literacy education  is part of the school curricula, a more recent trend is to start with Internet literacy education in  elementary school, for example in Japan the appropriate use of the Internet is taught as of 2009 in  elementary  school  as  well  as  in  Norway,  and  as  of  2011  in  the  United  Kingdom.
In  some  US  states, Internet safety courses are part of the required curriculum and new federal rules require  schools that receive federal funding to educate minors about appropriate online behavior.209 Egypt  is testing a curriculum on digital literacy and Internet safety in secondary schools.210 In 2009, the  Australian Government provided an additional AUD 16.6 million to the Australian Communica- tions  and  Media  Authority  (ACMA)  to  continue  and  expand  their  comprehensive  range  of  Cybersmart cybersafety education activities which includes a national outreach training programme  delivering  cybersafety  presentations  to  students,  parents  and  teachers  as  well  as  accredited  professional development workshops for teachers and trainee teachers.
The scope of Internet literacy education varies across countries and reflects to some extent the  local situations and needs.
Topics range from computer skills, cybersecurity and responsible use  to  fostering  creative  and  critical  capabilities,  participation  and  active  citizenship.211  Digital  citizenship  is  a  modern  concept  of  Internet  literacy  which  incorporates  a  number  of  elements  including digital etiquette, digital literacy and digital security and which emphasizes participatory  and creative opportunities of the Internet for children.212 An additional ramification for successful  Internet literacy education which is gaining importance is the enhancement of children’s capacity  to cope with risks and the communication of coping strategies.
This modern notion of Internet  literacy is only adopted by very few countries so far (e.g.
In order to prepare schoolteachers and other trainers, almost all countries where Internet literacy  is included in their school curricula offer some form of teachers’ training.
The ACMA’s  training  programme  will  be  also  offered  as  an  interactive  e-learning  programme  in  early  2011  to  allow  greater flexibility for teachers and schools to access cybersafety information.
In some cases official reviews monitor the effectiveness of this Internet literacy education for   example in Australia,213 United Kingdom and in New Zealand.
Positive content provision   The Council of Europe and many countries recognise the provision of positive online content  as a way to i) offer child suitable content, ii) promote a beneficial online experience and iii) create  child safe zones on the Internet.214 Services aiming to provide positive online content for children  are websites made for a child audience and Web portals, such as children’s search engines and  walled gardens from where children can access collections of suitable content.
Standards on what  is positive online content for children exist, if at all, for specific services only and those are often  not systematically evaluated.
The characteristics of positive online content for children vary and  include  for  example  age  appropriate,  diverse,  affirmative,  educative,  participatory  and/or  inter-  THE PROTECTION OF CHILDREN ONLINE © OECD   82       active content;215 however, not every website which is targeted at children automatically provides  positive online content.
Directing  children  towards  dedicated  websites protects them from the online risks, creates opportunities for children and can empower  them in terms of learning, participation, creativity, and identity.216 The EU and many countries are  funding  directly  or  indirectly  the  creation  of  positive  online  content  for  children.217  Germany  opened  an  annual  EUR  1.5  million  envelop  which  is  allocated  over  a  period  of  three  years  to  provide financial support for high-quality and innovative Internet content for children.218 Other, in  particular smaller, countries promote local online content also directed at a child audience with a  view to promote online services reflecting local culture and language.
For  example,  “Kids.us” - a dedicated domain for children-was launched in 2002 in the United States as a  safe space for children under 13 on the Internet and is not yet sustainable because the domain is  not sufficiently populated.220   International co-operation   As the Internet is an open medium where information freely flows across borders, many risks  faced  by  minors  online  have  an  international  dimension.
The protection of children online is on the international policy agenda and part of the work  programme  of  several  intergovernmental  organisations  and  international  non-governmental  organisations.
International  co-operation  levels.
Collaboration at the international policy level needs to be inclusive in order to reflect the various  roles of stakeholders.
takes  place  at  policy  and  operational   International co-operation at policy level   Insofar as online content qualifies as mass media, the UN Convention on the Rights of the  Child  requires  that  signatories  encourage  appropriate  guidelines  for  the  protection  of  the  child  from information and material injurious to his or her well-being, while recognising the children’s  fundamental right to freedom of expression and parents' primary responsibilities.221          THE PROTECTION OF CHILDREN ONLINE © OECD    83        ITU’s Child Online Protection (COP) Initiative links an international collaborative network  aiming to promote the online protection of children worldwide.
The COP initiative has produced  awareness material tailored to different audiences222 and has emerged as an international platform  for  dialogue  between  governments  and  other  stakeholders.223  In  the  framework  of  the  Internet  Governance Forum (IGF), the Dynamic Coalition for Child Online Safety is an open platform for  discussion  carrying  forward  the  Tunis  Commitment  on  the  role  of  ICTs  in  the  protection  of  children  and  in  enhancing  the  development  of  children.224  Collaborators  are  child  protection  organisations working towards a safer Internet for children.
The International Conference of Data Protection and Privacy Commissioners in its resolution  on Children’s Online Privacy of 2008 supports the development of education-based approaches to  improving online privacy for children and calls on operators for websites created for children to  demonstrate social responsibility by adopting adequate privacy policies.225    Other important stakeholders for international co-operation at policy level are child welfare  organisations  such  as  Childnet  International,  the  European  Child  Safety  Online  NGO  Network  (ENASCO)  and  the  Family  Online  Safety  Institute    (FOSI)  together  with  many  locally  and  nationally active organisations.
Operational level   Networks  of  national  initiatives  (e.g.
Internet  hotlines,  awareness  centres)  which  collect  reports  of  illegal  online  activities,  have  emerged  as  a  model  of  organisation  for  operational  international  co-operation.
Examples  are  INHOPE,  the  International  Association  of  Internet  Hotlines,  INSAFE,  the  European  network  of  Awareness  Centres,  and  less  visible  INACH,  the  International  Network  Against  Cyberhate.
Some of  these organisations are active stakeholders at the international policy level.
INHOPE  has  become  truly  international  with  thirty  five  members  worldwide,  including  members  from  Europe,  Asia,  North  America  and  Australia.
To this end, INHOPE sets out policies and best practice standards  for  the  effective  operation  of  Internet  hotlines,  it  promotes  the  establishment  of  new  Internet  hotlines and engages in public awareness raising about the illegal content online and the reporting  tool.
Through INHOPE, members can exchange reports about illegal material when the content is  hosted abroad and take action by informing law enforcement agencies and the Internet Service  Providers for removal.
The  INSAFE  co-operation  network  and  its  partners  are  working  towards  the  safe  and  responsible use of the Internet and mobile devices by citizens, in particular children and youths.
Through this network, INSAFE partners share best practice, information and resources, monitor  and  address  emerging  trends,  reach  out  with  Internet  safety-awareness  campaigns  and  promote  Internet literacy.
INSAFE is the central organiser of the Safer Internet Day which is gaining more  international  momentum  each  year.
In  many  countries  the  national  awareness  centres  have  become instrumental to the national co-ordination of stakeholders for the protection of children  online  and  the  European  network  helps  to  increase  the  professionalism  and  feeds  back  into  national policy.
The two existing international networks of national hotlines (INHOPE) and awareness centers  (INSAFE) can be considered as models for successful international co-operation at the operational  level.
Yes, a mobile with no   access to the   Internet   Yes, a mobile with   access to the   Internet   6  7  8  9  10  11  12  13  14  15  16  17   9%  11%  18%  27%  45%  54%  64%  72%  67%  68%  71%  73%  Base: all respondents %, DK/NA not shown  Source: EC, 2008c, p.20.
1%  2%  3%  4%  6%  8%  15%  11%  17%  18%  18%  19%   Yes, but I am not  sure if it has Internet   access option   1%  0%  1%  1%  1%  2%  3%  4%  3%  4%  6%  3%   Total  Yes   11%  13%  22%  32%  52%  64%  82%  87%  87%  90%  95%  95%   Total  No   89%  87%  78%  68%  47%  36%  18%  13%  13%  8%  5%  4%   Box 2.
Change in Unwanted Exposure to Sexual Material   In 2005, a study found that of 12-14 year-olds exposed to nudity, 63% are exposed through TV, 46% movies  and 35% on the Internet.
4.5% of younger Internet users reported both online and  offline exposure, 3.6% reported online-only, and 7.2% offline-only exposure in the past year.
This suggests that  concerns regarding large groups of young children being exposed to online pornography might be overstated.
% of teens who witness behaviour   (n=1064)   Often  Sometimes  Never   16%  33%  51%   Source: Pew Internet and American life project, gaming and civic engagement survey of teens/parents, Nov 2007-Feb 2008.
87      Notes   In 1999, the ICCP issued a background report on “Approaches to content on the Internet” (see OECD, 1999) which  reviewed the existing legislation and practices in member countries concerning Internet content issues including illegal,  harmful, and controversial content.
The study is conducted within the context of the global Project on Cybercrime (www.coe.int/cybercrime) to assess the   measures taken by countries to criminalise conduct related to the sexual exploitation and sexual abuse of children,  including child pornography.
Promote the implementation of common standards and harmonised legislation and a framework for effective and   efficient international co-operation on cybercrime, including offences related to sexual exploitation and sexual abuse  of children.
Serve as a database for substantive law provisions on protecting children to share good practices, encourage the   implementation of these treaties and facilitate technical co-operation activities.
Japanese Statistical Survey Department, Statistics Bureau, Ministry of Internal Affairs and Communications.
Keeping strict rules on explicit content (violent and/or sexual), limit age of  registration and access is essential as new virtual worlds are being created every day and the number of players is on a  constant rise: virtual worlds counted 579 million registered accounts worldwide in the 2nd quarter of 2009, representing an   THE PROTECTION OF CHILDREN ONLINE - © OECD   88         increase of 38.6% in only 3 months, 80% of them being children aged from 5 to 15 years old and with the  number of pre- teen (3-11) users increasing the most significantly.
See also Canadian Media Awareness Network (MNet) at   www.media-awareness.ca/english/issues/online_hate/tactic_recruit_young.cfm.
2009 p.109: “To identify the prevalence of self-injury message boards, five  Internet search engines were used: Yahoo, Google, MSN, AOL, and Gurl.com.
Terms searched included self-injury, self- harm, self-mutilation and cutting”.
Keeping  strict rules on explicit content (violent and/or sexual), limit age of registration and access is essential as new virtual worlds  are being created every day and the number of players is on a constant rise: virtual worlds counted 579 million registered  accounts worldwide in the 2nd quarter of 2009, representing an increase of 38.6% in only 3 months, 80% of them being  children aged from 5 to 15 years old and with the number of pre-teen (3-11) users increasing the most significantly.
Overall, 70% of teens have a cell phone which someone else, usually a parent, pays for; 19% pay part of the costs; and   10% pay all of the costs (Pew Internet & American Life Project, 2009, p. 4).
In the European Union parental consent is required as long as minors are not  capable to fully comprehend the situation and to make an informed choice.
Stross (2010) suggests that some categories of children may not necessarily benefit from the Internet if it diverts them   from education.
See Article 29 Working Party, 2008.
See Children’s Online Privacy Working Group, 2009.
The FTC COPPA Rule is  presently under review; FTC press release of 24 March 2010, “FTC Seeks Comment on Children's Online Privacy  Protections; Questions Whether Changes to Technology Warrant Changes to Agency Rule”,  www.ftc.gov/opa/2010/03/coppa.shtm.
The data controller is the party competent to   decide about the content and use of personal data.
Safer Social Networking Principles for the EU, 2009; United States: In relation to MySpace: ISTTF 2008, Appendix A:   Joint Statement on Key Principles of Social Networking Safety; in relation to Facebook:  www.attorneygeneral.gov/uploadedFiles/Press/Facebook%20agreement.pdf.
2 of the Tokyo Communiqué on Safer Internet Environment for Children as agreed by participants to the ITU/ MIC  Strategic Dialogue on “Safer Internet Environment for Children” on 3 June in Tokyo, Japan, (ITU, 2009b).
The YPRT  toolkit (YPRT, 2009) gives detailed recommendations for improvements of technologies and infrastructures which can be  helpful at the operational level and to feed voluntary commitments.
youth ambassadors from Egypt’s youth Internet safety focus group “net-aman” (Livingston and Haddon, 2009, p. 23)..  42.
Its target group is children  aged 2-9 years and their parents and teachers; www.hectorsworld.com.
Major syntheses of available international and European research on children’s use and online risks have been   accomplished through research projects funded under the Australian cyber-safety plan (the so-called “ECU review”) and  the EU’s Safer Internet Programme (EU Kids Online project).
Australia’s Communications and Media Authority (ACMA) has produced two widely recognised reports reviewing  technical and other measures for promoting online safety (ACMA, 2008a, 2009a).
In the United States the ISTTF, a group of Internet businesses, non-profit organisations, academics and technology  companies, completed a year-long inquiry with the release of its final report on the state of research and technology  (ISTTF, 2008).
ACMA conducted and commissioned studies on ISP-level filtering and published the results of a life-pilot test which also  addresses the economic and network efficiency arguments raised against ISP-level filtering (IIA, 2008; ACMA, 2008a and  2008b).
Parental control technologies are investigated in three successive European studies testing products and services to  voluntarily filter Internet content for children (the Deloitte SIP-Bench studies) (Deloitte Enterprise Risk Services, 2008).
The Technology Advisory Board of the ISTTF reviewed the state of the art of various technologies which could be  deployed in order to protect children online, including identity authentification, age verification, text-analysis filtering and  monitoring technologies (ISTTF, 2008, p. 39 f.).
The European Commission sought the views of stakeholders and collected feedback on the following topics: Child safety  and mobile phone services in 2006; online technologies for children in 2007; and age verification, cross media rating and  social networking in 2008.
The consultation documents are used as background information for discussion and help to  better target the action areas of the Safer Internet Programme.
All consultations, submissions and results are accessible  through the European Commission Portal at  http://ec.europa.eu/information_society/activities/sip/policy/consultations/index_en.htm.
In 2009, the US Federal Communications Commission (FCC) conducted consultations on parental control technologies for  video or audio programming and submitted a final report to the Congress (US FCC Report, 2009).
Stakeholders were also  invited to contribute to the public inquiry of the ISTTF which reviewed 40 submitted technologies for their potential to  mitigate online risks for children.
Independent experts carried out programme evaluations of the previous Safer Internet Programme and its predecessors.
Indicators include: quantitative/qualitative data on reporting points; the  degree of awareness of EU citizens about reporting points, harmful conduct online, and empowerment issues; the number  of children involved; and other outputs.
European Comission Staff Working Document SEC(2008) 242, Accompanying  document – Impact Assessment, Brussels, 27.2.2008, p. 8, 45f, 53.
THE PROTECTION OF CHILDREN ONLINE © OECD   90           The proposal for the current funding programme examined the economic impact of different policy options according to  four criteria: i) deployment and use of ICT; ii) cost of medical and psychological treatment; iii) cost to public  administration, and iv) economic impact on third countries (EC, 2009b) Accompanying measures such as benchmarking,  testing of regulatory and technical tools, opinion surveys and studies can also be useful for programme evaluations.
In addition, the Council for Child Internet Safety’s activities will be subject to an  independent review (UKCCIS, 2009).
See for example the Eurobarometer surveys conducted under the Safer Internet Programme.
Council of Europe, Recommendation Rec (2006)12 of the Committee of Ministers to member states on empowering   children in the new information and communications environment (Adopted by the Committee of Ministers on 27  September 2006 at the 974th meeting of the Ministers’ Deputies).
There is presently no national legislation pursuant to Council of Europe’s Declaration of the Committee of Ministers on   protecting the dignity, security and privacy of children on the Internet (Adopted by the Committee of Ministers on 20  February 2008 at the 1018th meeting of the Ministers’ Deputies).
See also Article 16 paragraph 1 e) of the Directive 2000/31/EC of the European   Parliament and of the Council of 8 June 2000 on certain legal aspects of information society services, in particular  electronic commerce, in the Internal Market ('Directive on electronic commerce').
In the US, under 2008 legislation, the Protecting Children in the 21st Century Act   (Title II of the Broadband Data Services Improvement Act, codified as Public Law No: 110-385 (10 October 2008)), the  National Telecommunications and Information Administration (an agency within the U.S. Department of Commerce),  established the Online Safety and Technology Working Group (OSTWG) to examine industry efforts to promote a safe  online environment for children.
In its June 2010 report to  NTIA and Congress, the OSTWG addressed four areas: 1) educational efforts, filtering controls, and labels; 2) industry  efforts to report online child pornography; 3) record retention in connection with crimes against children; and 4) protection  technologies.
The report contained numerous recommendations, including promoting digital citizenship in pre-K-12  education as a national priority, getting young people involved in risk-prevention education, engaging in awareness  building efforts about protective technologies and promoting transparency for parents as to what sort of content and  information will be accessible to their children while using a given product.
Japan: Act on Development of an Environment that Provides Safe and Secure Internet Use for Young People of 2008,  pursuant to which Web sites encouraging to commit a crime or breach the law or include information that directly and  expressly induces a suicide, obscene content and extremely cruel descriptions are regulated.
Korea: Act on Promotion of Information and Communications Network Utilization and Information Protection of 2007,  which regulates restricted access and advertising of content harmful to minors, requires companies to dedicate personnel in  charge of juvenile protection and also introduced the requirement of an identity verification system for bulletin boards,  portals and online communities of a certain size.
The law can be enforced against content  providers and Internet intermediaries when they are in the position to suppress prohibited content and services.
the use of misleading domain names, words,  or digital images on the Internet with intent to deceive a person into viewing obscenity is forbidden and can be sanctioned.
Sanctions are higher where this behaviour attempts to deceive a minor into viewing material that is harmful to minors on  the Internet.
Penal Code, Article 222-33-3: The deliberate recording or   photographing and the diffusion of certain violent assaults, except when carried out to serve as proof in a court or by  professionals to inform the public, can lead to a maximum of 5 year imprisonment and EUR 75 000 fine.
New Zealand: Department of Internal Affairs   (n.d.).
This gap in the legislative responses to content-related risks for   children appears to be present in all countries which leaves a question mark as to whether this is justified in the light of the  widespread use of these technologies by children.
In Australia for example   the classification MA15+ has been introduced for mobile premium services or other fee-paying services that provide audio  or video content without access restriction systems.
National  classification schemes are challenged by the Internet, where content stemming from abroad and to which different laws  apply is accessible everywhere.
Pursuant to Australia’s new Schedule 7 to the Broadcasting Act 1992, the Australian Communications and Media   Authority (ACMA) can investigate complaints against Internet service providers, which are hosting prohibited content (i.e.
for example adult pornography classified ‘X 18+’ as well as in certain circumstances content classified ‘R 18+’ and  ‘MA15+’), and administer “take down” or “access removal” notices to remove access and also the links to illegal content.
5651 (2007), the Telecommunications Communication Presidency (TIB) has the competence to  request the take down of certain categories of online content from Internet service providers.
For example Swiss telecommunications providers are obliged to bar customers and users known to be under 16 from  accessing value-added services with erotic or pornographic content pursuant to Swiss Ordinance of 9 March 2007 on  Telecommunications Services (OTS), Art.
Another example for accompanying technical measures to complement (or even substitute for) content regulation is the  obligation in Japan to use filtering technologies for under age mobile phone users, with an opt-out possibility left to  parents.
Conversely, pre-installed filtering is not required for Internet access but has to be provided upon parents' request  (opt-in).
In Australia, the Restricted Access Systems Declaration 2007 (made under subclause 14(1) of Schedule 7 of the  Broadcasting Services Act 1992) provides that age inappropriate content made available online, must be subject to an  access control system that verifies the age of those seeking access.
Pursuant to the Act on Promotion of Information and Communications Network Utilization and Information Protection of  2007 mass-audience information and communications service providers in Korea have to designate personnel in charge of  juvenile protection.
Spanish Internet service providers have the statutory duty to inform their customers about online risks  for children and available filtering technologies under Spanish Law 32/2002 on Information Society Services and  Electronic Commerce.
The Convention introduces a new offence concerning the solicitation of children through  information and communication technologies for sexual purposes and more countries are expected to update their criminal  laws accordingly.
S. 431, Keeping the Internet Devoid of Sexual Predators Act of 2008, see www.govtrack.us/congress/bill.xpd?bill=s110-  431   90.
Required under the Korean Act on the Promotion of Information and Communications Network Use and Information   Protection.
Korean Act on Promotion of Information and Communications Network Utilization and Information Protection of 2007.
For example according to national implementations of the EU Data Protection Directive 95/46/EC which is currently   under review.
See Article 29 Working Party (2008), p. 6 and 9.
In March 2010, the FTC requested public comment on its implementation of COPPA and the comment period closed on   30 June 2010.
Specifically, the FTC asked for comments on the costs of benefits of the COPPA Rule (the Rule  implemented pursuant to COPPA), as well as on whether it, or certain sections, should be retained, eliminated, or  modified.
See YouTube Fact Sheet, available at www.youtube.com/t/fact_sheet (accessed 30 January 2010)  109.
Children’s Online Privacy Working Group, 2009.
See European Framework for Safer Mobile Use by Younger Teenagers and Children, February 2007, available at   http://ec.europa.eu/information_society/activities/sip/docs/mobile_2005/europeanframework.pdf; Safer Social Networking  Principles for the European Union, 2009.
Attorneys General Multi-State Working Group, In relation to MySpace: Joint  Statement on Key Principle on Social Network Site Safety, available at  http://cyber.law.harvard.edu/sites/cyber.law.harvard.edu/files/ISTTF_Final_Report-APPENDIX_A_Joint_Statement.pdf;  and in relation to Facebook: www.attorneygeneral.gov/uploadedFiles/Press/Facebook%20agreement.pdf   115.
Clause 3.1.16 of the Mobile Premium Services Code C637:2009 (an industry code of practice registered by the ACMA   under the Telecommunications Act 1997 in accordance with co-regulatory arrangements).
In relation to MySpace: Joint Statement on Key Principle on Social Network Site Safety, available at   http://cyber.law.harvard.edu/sites/cyber.law.harvard.edu/files/ISTTF_Final_Report-APPENDIX_A_Joint_Statement.pdf;  In relation to Facebook: www.attorneygeneral.gov/uploadedFiles/Press/Facebook%20agreement.pdf   122.
In the case of MySpace, see Joint Statement on Key Principle on Social Network Site Safety, available at   http://cyber.law.harvard.edu/sites/cyber.law.harvard.edu/files/ISTTF_Final_Report-APPENDIX_A_Joint_Statement.pdf.
Safer Social Networking Principles for the EU, 2009.
See also Article 29 Working Party (2009), p. 11.
The “Safer Social Networking Principles for the EU” cover seven main areas: 1) awareness raising; 2) age-appropriate   services; 3) user empowerment through technologies; 4) easy-to-use mechanisms to report conduct or content that violates  the terms of service; 5) response to notifications of illegal content or conduct;  6) enable and encourage users to employ a  safe approach to personal information and privacy; 7) assess the means for reviewing illegal or prohibited content/conduct.
Examples for a general scheme is the ICC’s Advertising and Marketing Communication Practice; specific to marketing to  children are the Self-Regulatory Guidelines for Children's Advertising by CARU or the non-binding Ethical Guidelines for  Advertising to Children by European Association of Communication Agencies (EACA, 2006).
The International Chamber of Commerce’s (ICC) Advertising and Marketing Communication Practice for example   contains a section on children requiring special care in marketing directed to or featuring children or young people and  provides guidance on what it entails.
It covers the separation of content and advertising, promotes fair information  principles, the protection of certain social values with respect to , for example, marketing that appeal to children to  persuade their parents or other adults to buy products for them.
ICC’s Advertising and Marketing Communication  Practice, article 18.
European Code of Practice for the Use of Personal Data in Direct Marketing.
the UK Advertising Standards Authority (ASA) now has the possibility to bring companies’ marketing   communications on to their own websites and other non-paid-for online space (such as social networking sites) within the  remit of the Committee of Advertising Practice (CAP) code.
Article 29 Working Party, 2010, p. 17.
For example using the ICRA (Internet Content Rating Association) questionnaire provided by FOSI.
See also the public consultation of the Australian government on measures to improve   accountability and transparency of processes for the placement of material on the RC content list (closed on 12 February  2010), available at www.dbcde.gov.au/funding_and_programs/cybersafety_plan/transparency_measures.
ISTTF, 2008, APPENDIX D: Technology Advisory Board Report, p. 12f.
For example social networking sites or video sharing Web sites, Deloitte Enterprise Risk Services; 2008. p. 5.
ISTTF, 2008, APPENDIX D: Technology Advisory Board Report, p. 12.
It aimed to establish a safer environment for chatting on the Internet through an age verification system based on the use of   a Belgian electronic identity card.
Technical Standards Used, About ICRA, www.fosi.org/icra/   179.
Presentation of Koji Ouchi, Deputy Director, Ministry of Internal Affairs and Communications (MIC), Japan and Koji   Isozumi, Deputy Director, Minisry of Economy, Trade and Industry (METI), Japan: “Workshop on Initiatives in  Promoting Safer Internet Environment for Children”, APEC-OECD Joint Symposium on Initiatives among Member  Economies Promoting Safer Internet Environment for Children, available at  www.oecd.org/document/17/0,3343,en_2649_34255_43301457_1_1_1_1,00.html   189.
Spanish Law 32/2002 on Information Society Services and Electronic Commerce.
Information provided in the APEC   Children Protection Project Questionnaire by the Spanish respondents   191.
Pursuant to the Japanese Law on environment of development for children’s Internet usage.
Information provided in the APEC Children Protection Project Questionnaire by the Japanese respondents.
Information provided in the APEC Children Protection Project Questionnaire by the Turkish respondents; In this context   see Akdeniz, Yaman (2010).
Report of the OSCE Representative on Freedom of the Media on Turkey and Internet  Censorship.
The presentations are tailored to the target audience including age appropriate Internet safety awareness presentations for  school students aged from 9 years.
The tailored presentations are designed to highlight the potential risks faced by that age  group when online and provide them with tips and strategies to stay safe online See  www.cybersmart.gov.au/en/Schools/Book%20school%20seminars.aspx    202.
Available at Cyber Peace Initiative’s Web site http://smwipm.cyberpeaceinitiative.org/page/family_kit  204.
Evaluation of the Implementation of the Safer Social Networking Principles for the EU Part I: General  Report.
In the Matter of Implementation of the Child Safe Viewing Act; Examination of Parental Control   Technologies for Video or Audio Programming, para.
Developments in Internet filtering technologies and other measures for promoting online safety Second   annual report, p. 51.
Developments in Internet filtering technologies and other measures for promoting online safety Second   annual report, p. 51; Livingstone, S., and Haddon, L. (2009).
Under the EU’s Safer Internet Plus Programme.
ITU COP Guidelines for children; parents, guardians, and educators; industry and policy makers are available from   www.itu.int/osg/csd/cybersecurity/gca/cop/guidelines/index.html   223.
Collaborating organisations are UN agencies, children rights organisations, industry associations and companies.
Findings show that there was a very low level of development of  policies and laws around online child protection issues among countries classified under the UN system as “Least  Developed”.
Among countries categorised as “Developing” the picture was more uneven, but in general there was little  evidence of major activity around online child protection.
Among the “Developed” nations there were higher levels of  activity and a more developed legal framework.
However what was striking from the survey was a more or less universal  acknowledgement that each nation could benefit by being connected to information about resources and potential sources  of help and assistance which would assist them domestically.
30th International Conference of Data Protection and Privacy Commissioners (2008).
THE PROTECTION OF CHILDREN ONLINE © OECD         98   Bibliography   30th International Conference of Data Protection and Privacy Commissioners (2008),   Resolution on Children’s Online Privacy.
Available at  www.priv.gc.ca/information/conf2008/res_cop_e.cfm    ACMA (Australian Communications and Media Authority) (2008a), “Developments in  Internet filtering technologies and other measures for promoting online safety”.
Available at  www.acma.gov.au/webwr/_assets/main/lib310554/developments_in_internet_filters_1st report.pdf   ACMA (2008b), “Closed Environment Testing of ISP Level Internet Content Filtering”,   Report to the Minister for Broadband, Communications and the Digital Economy, June  2008, Available at: www.acma.gov.au/webwr/_assets/main/lib310554/isp- level_internet_content_filtering_trial-report.pdf   ACMA (2009a), “Developments in Internet filtering technologies and other measures for   promoting online safety”.
Report of the OSCE Representative on Freedom of the Media on   Turkey and Internet Censorship.
Article 29 Working Party (2008), “Working Document 1/2008 on the protection of   children's personal data” (General guidelines and the special case of schools).
Available  at http://ec.europa.eu/justice_home/fsj/privacy/docs/wpdocs/2008/wp147_en.pdf   Article 29 Working Party (2009), “Opinion 5/2009 on social networking”.
Available at   http://ec.europa.eu/justice_home/fsj/privacy/docs/wpdocs/2009/wp163_en.pdf   Article 29 Working Party (2010), “Opinion 2/2010 on online behavioural advertising”.
International   Review of Law, Computers & Technology, 23(1-2), 35-45.
THE PROTECTION OF CHILDREN ONLINE - © OECD    99        Beantin Webbkommunikation (2010), “Internet usage and young Swedes in Sweden”,   http://beantin.se/post/616872465/internet-use-sweden-young-swedes-children-age- group   Branch Associates (2002), NetSmartz evalulation project: Internet safety training for  children and youth ages 6 to 18.
British Standards Institution (BSI) (n.d), “Kitemark for Child Safety Online”.
(2009), “Children’s Charities’ Coalition on Internet Safety Digital   manifesto”.
Available at  www.deewr.gov.au/Schooling/NationalSafeSchools/Pages/research.aspx   Children’s Online Privacy Working Group (2009).
A discussion paper for Canadians by the  Working Group of Canadian Privacy Commissioners and Child and Youth Advocacies.
Available   at www.connectsafely.org/Commentaries-Staff/online-safety-30-empowering-and- protecting-youth.html   Conroy, Stephen (2009), “Measures to Improve Safety of the Internet for Families”, in:   Minister Speeches, 15 December 2009.
Council of Europe (2006), Recommendation Rec(2006)12 of the Committee of Ministers to   member states on empowering children in the new information and communications  environment (Adopted by the Committee of Ministers on 27 September 2006 at the  974th meeting of the Ministers’ Deputies).
Available at  http://conventions.coe.int/Treaty/Commun/QueVoulezVous.asp?NT=201&CM=8&DF= &CL=ENG   Council of Europe (2008a), Recommendation CM/Rec(2008)6 of the Committee of   Ministers to member states on measures to promote the respect for freedom of  expression and information with regard to Internet filters (Adopted by the Committee of  Ministers on 26 March 2008 at the 1022nd meeting of the Ministers’ Deputies),  Available at  https://wcd.coe.int/ViewDoc.jsp?Ref=CM/Rec(2008)6&Language=lanEnglish&Site=C M&BackColorInternet=DBDCF2&BackColorIntranet=FDC864&BackColorLogged=F DC864   Council of Europe (2008b), The Internet Literacy Handbook.
Available at  www.coe.int/t/dghl/standardsetting/internetliteracy/hbk_EN.asp   Council of Europe (2008c), Declaration of the Committee of Ministers on protecting the   dignity, security and privacy of children on the Internet (Adopted by the Committee of  Ministers on 20 February 2008 at the 1018th meeting of the Ministers’ Deputies).
Available at https://wcd.coe.int/ViewDoc.jsp?id=1252427&Site=CM   Council of Europe (2009), Recommendation CM/Rec(2009)5 of the Committee of   Ministers to member states on measures to protect children against harmful content and  behaviour and to promote their active participation in the new information and  communications environment (Adopted by the Committee of Ministers on 8 July 2009  at the 1063rd meeting of the Ministers’ Deputies).
Available at  www.lse.ac.uk/collections/EUKidsOnline/Reports/D5Recommendations.pdf   Deloitte Enterprise Risk Services (2008), “Test and benchmark of products and services to  voluntarily filter Internet content for children between 6 and 16 years”.
Available at www.sip- bench.org/Reports2008/sip_bench_2008_synthesis_report_en.pdf   Donoso, Veronica, Leen D’haenens, Bieke Zaman, Anna Van Cauwenberge and Katia  Segers (2008), National Report for Belgium, in: Cross-national Comparisons for EU  Kids Online, Available at  www.lse.ac.uk/collections/EUKidsOnline/Reports/WP3NationalReportBelgium.pdf    Dooley, J.J., Cross, D., Hearn, L. and Treyvaud, R. (2009), “Review of existing Australian   and international cyber-safety research”.
Available at  www.dbcde.gov.au/__data/assets/pdf_file/0004/119416/ECU_Review_of_existing_Austr alian_and_international_cyber-safety_research.pdf   eNacso (2009), “Developing a Response to a new breed of location services”.
Available at  www.enacso.eu/index.php?option=com_rokdownloads&view=file&task=download&id =8%3Aenacso-response-to-the-new-breed-of-location-services&Itemid=11   THE PROTECTION OF CHILDREN ONLINE © OECD    101           Enex TestLab (2009), “Internet Service Provider Content Filtering Pilot Report”.
Available   at  www.dbcde.gov.au/__data/assets/pdf_file/0008/123857/Enex_Testlab_report_into_ISP- level_filtering_-_01_Main_report.pdf   ENISA (2007), “Security Issues and Recommendations for Online Social Networks”.
Available at www.enisa.europa.eu/act/res/other- areas/social-networks/security-issues-and-recommendations-for-online-social- networks/at_download/fullReport   ENISA (2008), “Security and Privacy in Massively-Multiplayer Online Games and Social  and Corporate Virtual Worlds.
Safer Internet”.
Available at  http://ec.europa.eu/information_society/activities/sip/docs/eurobarometer/eurobaromete r_2005_25_ms.pdf   EC (2008a), Public Consultation Age Verification, Cross Media Rating and Classification,   Online Social Networking; Belgian Awareness Node; Questionnaire 1; Available at  http://ec.europa.eu/information_society/activities/sip/docs/pub_consult_age_rating_sns/ results/crioc_a531786.pdf   EC (2008b), “Background Report on Cross Media Rating and Classification and Age   Verification Solutions”.
Safer Internet Forum 2008.
Towards a safer use of the Internet for children   in the EU – a parents’ perspective”, analytical report.
Final evaluation of the implementation   of the multiannual Community Programme on promoting safer use of the Internet and  new online technologies.
Available at  http://ec.europa.eu/information_society/activities/sip/docs/mobile_2005/europeanframe work.pdf      THE PROTECTION OF CHILDREN ONLINE © OECD   102       European Parliament and Council (2006), Recommendation 2006/952/EC of the European   Parliament and of the Council of 20 December 2006 on the protection of minors and  human dignity and on the right of reply in relation to the competitiveness of the  European audiovisual and on-line information services industry.
Available at  www.agnesnairn.co.uk/policy_reports/fair_game_final.pdf   Government of Canada (2000), “Illegal and Offensive Content on the Internet.
Canadian  Strategy to Promote Safe, Wise and Responsible Internet Use”.
Study   on Co-Regulation Measures in the Media Sector.
IIA (Internet Industry Association) (2008), Feasibility Study - ISP Level Content Filtering,   February 2008; Main report, Available at  www.dbcde.gov.au/__data/assets/pdf_file/0006/95307/Main_Report_-_Final.pdf   ISTTF (Internet Safety Technical Task Force) (2008), “Enhancing Child Safety and Online  Technologies”: Final Report of the ISTTF to the Multi-State Working Group on Social  Networking of State Attorney Generals of the United States.
Cambridge, MA: Berkman  Center for Internet and Society, Harvard University.
Available at   www.itu.int/osg/csd/cybersecurity/gca/cop/guidelines/policy_makers.pdf         THE PROTECTION OF CHILDREN ONLINE © OECD    103        ITU (2009b), Tokyo Communiqué on Safer Internet Environment for Children as agreed by   participants to the ITU/ MIC Strategic Dialogue on “Safer Internet Environment for  Children” on 3 June 2009 in Tokyo, Japan.
ITU (2010a), Council Working Group on Child Online Protection.
(EC Safer Internet Plus Programme Deliverable D6.5).
Available at  http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1588163    Media Awareness Network (2005), “Young Canadians in a Wired World: Phase II Trends   and Recommendations”.
Report   prepared for the Council of Europe’s Group of Specialists on Human Rights in the  Information Society.
Bangkok, Thailand: ECPAT International.
Available at:  www.agnesnairn.co.uk/policy_reports/watching_wanting_and_wellbeing_july_2007.pdf   New Zealand’s Department of Internal Affairs (n.d.), “Censorship and the Internet”.
Available at   www.samentegencybercrime.nl/UserFiles/File/NTD_Gedragscode_Opmaak_Engels.pdf   Nordic Consumer Affairs Ministers (n.d.), “Internet Marketing Aimed at Children and   Minors”.
Available at:  www.oecd.org/document/18/0,3343,en_2649_34255_1815186_1_1_1_1,00.html  OECD (1999), “Approaches to Content on the Internet”.
OECD (2003), “Policy Coherence: Vital for Global Development”.
OECD Digital Economy Paper 124, Directorate for   Science, Technology and Industry, OECD, Paris.
Available at  www.oecd.org/dataoecd/22/52/38077227.pdf   OECD (2007a), Participative Web and User-Created Content: Web 2.0, Wikis and Social   Networking.
OECD (2007b), Working Party on Regulatory Management and Reform: Methodological   Guidance and Frameworks for RIA, GOV/PGC/REG(2007)8.
OECD (2008), “The Seoul Declaration for the Future of the Internet Economy”.
Available   at www.oecd.org/dataoecd/49/28/40839436.pdf   THE PROTECTION OF CHILDREN ONLINE © OECD    105           OECD (2009a), “Report on the APEC-OECD Joint Symposium on Initiatives among   Member Economies Promoting Safer Internet Environment for Children”.
A Threat to the Internet   Economy.
Available at  www.oecd.org/document/16/0,3343,en_2649_34223_42276816_1_1_1_37441,00.html  OECD (2009c), “The Economic and Social Role of Internet Intermediaries”.
OECD Digital  Economy Papers 171, Directorate for Science, Technology and Industry, OECD, Paris.
“National Strategies and Policies for Digital Identity Management in   OECD Countries”.
OECD Digital Economy Paper 177, Directorate for Science,  Technology and Industry, OECD, Paris    OECD (2010b), The role of Internet Intermediaries in Advancing Public Policy Objectives.
Forging Partnership for Advancing Policy Objectives for the Internet Economy, Part II  and III.
OECD (2010c), “Conference on Empowering E-consumers: Strengthening Consumer   Protection in the Internet Economy- Summary of key points and conclusions”.
Available at www.oecd.org/dataoecd/51/28/45326349.pdf   OECD (2010f), “The role of Internet Intermediaries in Advancing Public Policy  Objectives”.
Available at:  www.ofcom.org.uk/research/telecoms/reports/byron/annex5.pdf   Ofcom (2008a), “Social Networking: A quantitative and qualitative research report into   attitudes, behaviours and use”.
Available at  http://stakeholders.ofcom.org.uk/binaries/research/media-literacy/report1.pdf   Ofcom (2008b), “UK code of practice for the self-regulation of new forms of content on   mobiles”, Review 2008, Available at  www.ofcom.org.uk/advice/media_literacy/medlitpub/ukcode/ukcode.pdf   Ofcom (2008c), “Ofcom’s Response to the Byron Review, Statement 2008”, Available at   http://stakeholders.ofcom.org.uk/binaries/research/telecoms- research/Byron_exec_summary.pdf   Ofcom (2010), “UK children’s media literacy”.
Available at   http://stakeholders.ofcom.org.uk/binaries/research/media-literacy/ukchildrensml1.pdf      THE PROTECTION OF CHILDREN ONLINE © OECD   106       Online Safety and Technology Working Group (OSTWG) (2010), “Youth Safety in a   Living Internet: Report of the Online Safety and Technology Working Group”, 4 June  2010, p. 16.
Available at  www.ntia.doc.gov/reports/2010/OSTWG_Final_Report_060410.pdf   PEGI Online (n.d.), PEGI Online Safety Code (POSC), “A Code of Conduct for the   European Interactive Software Industry”.
Available at  www.pegionline.eu/en/index/id/235/media/pdf/197.pdf   Peter, J., Valkenburg, P. M., and Schouten, A. P. (2006), “Characteristics and Motives of   Adolescents Talking with Strangers on the Internet”.
Pew Internet & American Life Project (2007), “Teens, Privacy & Online Social Networks.
How teens manage their online identities and personal information in the age of  MySpace”.
Available at  www.pewinternet.org/~/media//Files/Reports/2007/PIP_Teens_Privacy_SNS_Report_Fi nal.pdf   Pew Internet & American Life Project (2009), “Teens and Sexting.
Pew Internet & American Life Project (2010), “Reputation Management and Social Media.
Oxford Internet Institute Forum Discussion Paper No.
Available at  www.gsmeurope.org/documents/PwC_Implementation_Report.pdf   Safer Internet Programme (2010), “Assessment Report on the Status on Online Safety   Education in Schools across Europe”.
Available at  http://ec.europa.eu/information_society/activities/sip/docs/forum_oct_2009/assessment_ report.pdf   Safer Social Networking Principles for the EU (2009), Available at   http://ec.europa.eu/information_society/activities/social_networking/docs/sn_principles.
(2002), “Spinning the Web of Hate: Web-based Hate Propagation by   Extremist Organizations”, Journal of Criminal Justice and Popular Culture, 9 (2): 69- 88.
(2007), “The Future of Reputation: Gossip, Rumor, and Privacy on the   Internet”.
Available at  http://docs.law.gwu.edu/facweb/dsolove/Future-of-Reputation/text.htm   Staksrud, Elisabeth and Lobe, Bojana (2010), “Evaluation of the Implementation of the  Safer Social Networking Principles for the EU Part I: General Report”.
(2009a), “Parental Controls & Online Child Protection: A Survey of Tools &   Methods”.
Available at http://ssrn.com/abstract=1433504   TACD (Trans Atlantic Consumer Dialogue) (2009), “Resolution on Marketing to Children   Online”, Available at  http://tacd.org/index2.php?option=com_docman&task=doc_view&gid=207&Itemid  UKCCIS (UK Council for Child Internet Safety) (2009), “Click Clever, Click Safe: The   First Child Internet Safety Strategy.
Available at  http://publications.dcsf.gov.uk/eOrderingDownload/00669-2009DOM-EN.pdf   UK Home Office (2005), “Good Practice Guidance for the Moderation of Interactive   Services for Children”, Available at  http://police.homeoffice.gov.uk/publications/operational-policing/moderation- document-final.pdf   UK Home Office (2008), “Good Practice Guidance for the providers of social networking   and other user interactive services 2008”.
Available at   http://police.homeoffice.gov.uk/publications/operational%2Dpolicing/social%2Dnetwor king%2Dguidance   United Nations (1989), “Convention on the Rights of the Child Adopted and opened for   signature”, ratification and accession by General Assembly resolution 44/25 of 20  November 1989.
Available at www2.ohchr.org/english/law/pdf/crc.pdf   US Department of Justice (2002), Drug, Youth and the Internet.
Available at   www.justice.gov/ndic/pubs2/2161/2161p.pdf   US FCC (Federal Communications Commission) (2009), “In the Matter of Implementation  of the Child Safe Viewing Act; Examination of Parental Control Technologies for Video  or Audio Programming”, MB Docket No.
US FTC (2007), “Implementing the Children’s Online Privacy Protection Act”.
Available at  www.ftc.gov/os/2009/12/oecd-vwrpt.pdf   US FTC (2010), “FTC Seeks Comment on Children's Online Privacy Protections;  Questions Whether Changes to Technology Warrant Changes to Agency Rule”.
Available at www.ftc.gov/opa/2010/03/coppa.shtm   Valkenburg, Patti M., and Peter, Jochen (2008), “Adolescents' Identity Experiments on the   Internet: Consequences for Social Competence and Self-Concept Unity”,  Communication Research, (2008) 35, p. 208.
Available at  http://cyber.law.harvard.edu/sites/cyber.law.harvard.edu/files/1in7Youth.pdf   Woollard, J., Wickens, C., Powell, K. and Russell, T. (2007), “E-safety: evaluation of key   stage 3 materials for initial teacher education: Childnet International”.